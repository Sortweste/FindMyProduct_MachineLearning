{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_YOLOv2_tiny.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrDYVJvjAMzj4qWW+1UEkM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sortweste/FindMyProduct_MachineLearning/blob/develop/Train_YOLOv2_tiny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jRNFbV_PG57",
        "colab_type": "text"
      },
      "source": [
        "**Entrenar modelos personalizados para YOLOv2 Tiny**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS5x3A8rzRRe",
        "colab_type": "text"
      },
      "source": [
        "El Dataset debe estar cargado en Google Drive, en una carpeta que contenga lo siguiente:\n",
        "\n",
        "1.   Una carpeta llamada Images donde se encuentren todas las imagenes.\n",
        "2.   Una carpeta llamada Annotations donde se encuentren los xml.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8WceNjUz2Ls",
        "colab_type": "text"
      },
      "source": [
        "Conectamos con nuestros archivos de Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ5Zfss7yhar",
        "colab_type": "code",
        "outputId": "15f7b5d4-425d-4e0b-e3e7-0640e53a3607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw7vU6CLz-cD",
        "colab_type": "text"
      },
      "source": [
        "Para entrenar nuestro modelo, utilizaremos Darkflow.\n",
        "Al momento de redactar este cuaderno, no existe soporte para Tensorflow 2.0, por tanto, regresaremos a una versión anterior específica:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wriz8QMiO9pG",
        "colab_type": "code",
        "outputId": "cda6ffaf-11e9-4f7d-bbb9-c8b637c9c9d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.15    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.2.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.2.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.2.0\n",
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 43kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.29.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 47.2MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (46.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=6c21453a2bf4ba1ac47ee95d4f8c96ac4bdc774583e49592b44ba949096e22e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDOwMpzo0g1t",
        "colab_type": "text"
      },
      "source": [
        "Aprovecharemos el gpu que nos proporciona Google Colab, instalando para esta versión de Tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zsvDW-gjr3F",
        "colab_type": "code",
        "outputId": "e98f62e3-d138-4fd9-e5ae-b7a1f987a456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "!pip install tensorflow-gpu==1.15"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.18.4)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.34.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.15.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.2.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.9.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.29.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.0.8)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (46.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCJAz_Vp0urH",
        "colab_type": "text"
      },
      "source": [
        "Clonaremos el siguiente repositorio para poder utilizar Darkflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOPggkWCPPkV",
        "colab_type": "code",
        "outputId": "dd7308fe-9cf9-4727-ac24-31668a7a7344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/thtrieu/darkflow.git\n",
        "%cd darkflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'darkflow'...\n",
            "remote: Enumerating objects: 2713, done.\u001b[K\n",
            "remote: Total 2713 (delta 0), reused 0 (delta 0), pack-reused 2713\u001b[K\n",
            "Receiving objects: 100% (2713/2713), 32.98 MiB | 10.06 MiB/s, done.\n",
            "Resolving deltas: 100% (1762/1762), done.\n",
            "/content/darkflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtAvjaRw1GhJ",
        "colab_type": "text"
      },
      "source": [
        "Luego de clonarlo, procedemos a instalarlo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9goIXS3PSKV",
        "colab_type": "code",
        "outputId": "4ab44a50-e68b-4316-cc6b-5f0b97260930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 setup.py build_ext --inplace\n",
        "!pip install ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling darkflow/cython_utils/nms.pyx because it changed.\n",
            "Compiling darkflow/cython_utils/cy_yolo2_findboxes.pyx because it changed.\n",
            "Compiling darkflow/cython_utils/cy_yolo_findboxes.pyx because it changed.\n",
            "[1/3] Cythonizing darkflow/cython_utils/cy_yolo2_findboxes.pyx\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/darkflow/darkflow/cython_utils/cy_yolo2_findboxes.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "[2/3] Cythonizing darkflow/cython_utils/cy_yolo_findboxes.pyx\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/darkflow/darkflow/cython_utils/cy_yolo_findboxes.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "[3/3] Cythonizing darkflow/cython_utils/nms.pyx\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/darkflow/darkflow/cython_utils/nms.pxd\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running build_ext\n",
            "building 'darkflow.cython_utils.nms' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/darkflow\n",
            "creating build/temp.linux-x86_64-3.6/darkflow/cython_utils\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c darkflow/cython_utils/nms.c -o build/temp.linux-x86_64-3.6/darkflow/cython_utils/nms.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdarkflow/cython_utils/nms.c:621\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/darkflow\n",
            "creating build/lib.linux-x86_64-3.6/darkflow/cython_utils\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/darkflow/cython_utils/nms.o -lm -o build/lib.linux-x86_64-3.6/darkflow/cython_utils/nms.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'darkflow.cython_utils.cy_yolo2_findboxes' extension\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c darkflow/cython_utils/cy_yolo2_findboxes.c -o build/temp.linux-x86_64-3.6/darkflow/cython_utils/cy_yolo2_findboxes.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdarkflow/cython_utils/cy_yolo2_findboxes.c:621\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/darkflow/cython_utils/cy_yolo2_findboxes.o -lm -o build/lib.linux-x86_64-3.6/darkflow/cython_utils/cy_yolo2_findboxes.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'darkflow.cython_utils.cy_yolo_findboxes' extension\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c darkflow/cython_utils/cy_yolo_findboxes.c -o build/temp.linux-x86_64-3.6/darkflow/cython_utils/cy_yolo_findboxes.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdarkflow/cython_utils/cy_yolo_findboxes.c:621\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/darkflow/cython_utils/cy_yolo_findboxes.o -lm -o build/lib.linux-x86_64-3.6/darkflow/cython_utils/cy_yolo_findboxes.cpython-36m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.6/darkflow/cython_utils/nms.cpython-36m-x86_64-linux-gnu.so -> darkflow/cython_utils\n",
            "copying build/lib.linux-x86_64-3.6/darkflow/cython_utils/cy_yolo2_findboxes.cpython-36m-x86_64-linux-gnu.so -> darkflow/cython_utils\n",
            "copying build/lib.linux-x86_64-3.6/darkflow/cython_utils/cy_yolo_findboxes.cpython-36m-x86_64-linux-gnu.so -> darkflow/cython_utils\n",
            "Processing /content/darkflow\n",
            "Building wheels for collected packages: darkflow\n",
            "  Building wheel for darkflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for darkflow: filename=darkflow-1.0.0-cp36-cp36m-linux_x86_64.whl size=816517 sha256=e265814da56acfcf09a4e323345f293785053472425e55a8c26f6a3804efea88\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n24bhftq/wheels/2f/3a/c5/e84e79d73d5a73aa1b5129a66a40947d9d77a32ebed501e431\n",
            "Successfully built darkflow\n",
            "Installing collected packages: darkflow\n",
            "Successfully installed darkflow-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i8cDbEN7tye",
        "colab_type": "text"
      },
      "source": [
        "Recordemos que para crear nuestras configuraciones personalizadas, debemos hacer una copia del archivo basado en tiny-yolo-voc.cfg\n",
        "\n",
        "En este archivo debemos realizar los siguientes cambios:\n",
        "\n",
        "\n",
        "\n",
        "*   En la Layer [region], la última Layer, hay que colocar la cantidad de clases que nuestro modelo va a utilizar.\n",
        "\n",
        "*   En la Layer [convolutional], la penúltima Layer, hay que cambiar los filtros siguiendo la fórmula num * (classes + 5), donde num = 5.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhjTUMpF1OI_",
        "colab_type": "text"
      },
      "source": [
        "Procedemos a personalizar las configuraciones para entrenar nuestro modelo.\n",
        "\n",
        "\n",
        "*   Para la opción *dataset* colocaremos la ubicación de nuestras imágenes en Google Drive.\n",
        "*   Para la opción *annotation* colocaremos la ubicación de nuestros xml en Google Drive.\n",
        "*   Reemplazar el archivo labels.txt con otro que contenga las clases que contiene nuestro modelo.\n",
        "\n",
        "*   Los pesos se pueden descargar de\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBWYyhUNsFHo",
        "colab_type": "code",
        "outputId": "530ef507-3c51-4384-b7e2-0bd712efca1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from darkflow.net.build import TFNet\n",
        "options = {\"model\": \"cfg/custom-voc.cfg\", \n",
        "           \"load\": \"bin/tiny-yolo-voc.weights\",\n",
        "           \"batch\": 8,\n",
        "           \"epoch\": 100,\n",
        "           \"gpu\": 1.0,\n",
        "           \"train\": True,\n",
        "           \"trainer\": \"adam\",\n",
        "           \"annotation\": '/content/drive/My Drive/YOLOv2/Dataset/PEPSI/Annotations',\n",
        "           \"dataset\": '/content/drive/My Drive/YOLOv2/Dataset/PEPSI/Images'}\n",
        "\n",
        "tfnet = TFNet(options)      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:15: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:16: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:17: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:18: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:19: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:20: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:21: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:22: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "Parsing ./cfg/tiny-yolo-voc.cfg\n",
            "Parsing cfg/custom-voc.cfg\n",
            "Loading bin/tiny-yolo-voc.weights ...\n",
            "Successfully identified 63471556 bytes\n",
            "Finished in 0.0066225528717041016s\n",
            "\n",
            "Building net ...\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:105: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/ops/baseop.py:70: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/ops/baseop.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/ops/baseop.py:84: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 16)\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/ops/simple.py:106: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 16)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 32)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 64)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 128)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 256)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_1                     | (?, 13, 13, 512)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 30)\n",
            "-------+--------+----------------------------------+---------------\n",
            "GPU mode with 1.0 usage\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:132: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "cfg/custom-voc.cfg loss hyper-parameters:\n",
            "\tH       = 13\n",
            "\tW       = 13\n",
            "\tbox     = 5\n",
            "\tclasses = 1\n",
            "\tscales  = [1.0, 5.0, 1.0, 1.0]\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/yolov2/train.py:87: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "Building cfg/custom-voc.cfg loss\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/yolov2/train.py:107: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "INFO:tensorflow:Summary name cfg/custom-voc.cfg loss is illegal; using cfg/custom-voc.cfg_loss instead.\n",
            "Building cfg/custom-voc.cfg train op\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:145: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:145: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:146: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:149: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:149: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Finished in 4.969379663467407s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl61z4TDw4OX",
        "colab_type": "text"
      },
      "source": [
        "Dentro de la carpeta de Darkflow, creamos la carpeta ./ckpt\n",
        "Aquí se iran almacenando todos nuestros *checkpoints*\n",
        "\n",
        "Comenzamos el entrenamiento.\n",
        "\n",
        "*   **Se tiene que tener configurado un GPU**\n",
        "*   Se recomienda detener el entrenamiento cuando se tenga una avg loss inferior a 0.60\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KypDbmtBsnpk",
        "colab_type": "code",
        "outputId": "ffa5d721-a30e-4869-feb4-284fdd0211a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tfnet.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "cfg/custom-voc.cfg parsing /content/drive/My Drive/YOLOv2/Dataset/PEPSI/Annotations\n",
            "Parsing for ['pepsi'] \n",
            "[====================>]100%  6602.xml\n",
            "Statistics:\n",
            "pepsi: 800\n",
            "Dataset size: 800\n",
            "Dataset of 800 instance(s)\n",
            "Training statistics: \n",
            "\tLearning rate : 1e-05\n",
            "\tBatch size    : 8\n",
            "\tEpoch number  : 100\n",
            "\tBackup every  : 2000\n",
            "step 1 - loss 29.314041137695312 - moving ave loss 29.314041137695312\n",
            "step 2 - loss 29.814346313476562 - moving ave loss 29.364071655273438\n",
            "step 3 - loss 29.540740966796875 - moving ave loss 29.381738586425783\n",
            "step 4 - loss 28.502593994140625 - moving ave loss 29.29382412719727\n",
            "step 5 - loss 27.988941192626953 - moving ave loss 29.163335833740238\n",
            "step 6 - loss 27.47597312927246 - moving ave loss 28.994599563293463\n",
            "step 7 - loss 28.93492317199707 - moving ave loss 28.988631924163826\n",
            "step 8 - loss 30.478946685791016 - moving ave loss 29.137663400326545\n",
            "step 9 - loss 27.424049377441406 - moving ave loss 28.96630199803803\n",
            "step 10 - loss 28.29202651977539 - moving ave loss 28.898874450211768\n",
            "step 11 - loss 26.948257446289062 - moving ave loss 28.703812749819498\n",
            "step 12 - loss 27.304353713989258 - moving ave loss 28.563866846236476\n",
            "step 13 - loss 28.44740867614746 - moving ave loss 28.552221029227574\n",
            "step 14 - loss 27.232383728027344 - moving ave loss 28.420237299107555\n",
            "step 15 - loss 29.612350463867188 - moving ave loss 28.53944861558352\n",
            "step 16 - loss 26.214527130126953 - moving ave loss 28.306956467037864\n",
            "step 17 - loss 27.113672256469727 - moving ave loss 28.187628045981054\n",
            "step 18 - loss 27.829296112060547 - moving ave loss 28.151794852589003\n",
            "step 19 - loss 27.125152587890625 - moving ave loss 28.049130626119165\n",
            "step 20 - loss 28.644878387451172 - moving ave loss 28.108705402252365\n",
            "step 21 - loss 28.12171173095703 - moving ave loss 28.110006035122833\n",
            "step 22 - loss 27.805591583251953 - moving ave loss 28.079564589935746\n",
            "step 23 - loss 26.979799270629883 - moving ave loss 27.96958805800516\n",
            "step 24 - loss 26.667165756225586 - moving ave loss 27.839345827827206\n",
            "step 25 - loss 25.874996185302734 - moving ave loss 27.64291086357476\n",
            "step 26 - loss 25.942501068115234 - moving ave loss 27.47286988402881\n",
            "step 27 - loss 25.69641876220703 - moving ave loss 27.295224771846634\n",
            "step 28 - loss 24.930997848510742 - moving ave loss 27.058802079513047\n",
            "step 29 - loss 24.711055755615234 - moving ave loss 26.824027447123267\n",
            "step 30 - loss 25.181840896606445 - moving ave loss 26.659808792071587\n",
            "step 31 - loss 26.449434280395508 - moving ave loss 26.63877134090398\n",
            "step 32 - loss 26.71974754333496 - moving ave loss 26.646868961147078\n",
            "step 33 - loss 24.741174697875977 - moving ave loss 26.45629953481997\n",
            "step 34 - loss 28.360248565673828 - moving ave loss 26.646694437905357\n",
            "step 35 - loss 26.804946899414062 - moving ave loss 26.662519684056228\n",
            "step 36 - loss 26.284442901611328 - moving ave loss 26.62471200581174\n",
            "step 37 - loss 24.528905868530273 - moving ave loss 26.415131392083595\n",
            "step 38 - loss 30.248794555664062 - moving ave loss 26.79849770844164\n",
            "step 39 - loss 25.119150161743164 - moving ave loss 26.630562953771793\n",
            "step 40 - loss 26.345197677612305 - moving ave loss 26.602026426155845\n",
            "step 41 - loss 26.986026763916016 - moving ave loss 26.640426459931863\n",
            "step 42 - loss 24.27338218688965 - moving ave loss 26.403722032627645\n",
            "step 43 - loss 25.056560516357422 - moving ave loss 26.269005881000624\n",
            "step 44 - loss 28.285343170166016 - moving ave loss 26.470639609917164\n",
            "step 45 - loss 29.13155746459961 - moving ave loss 26.73673139538541\n",
            "step 46 - loss 25.49056625366211 - moving ave loss 26.61211488121308\n",
            "step 47 - loss 25.18320083618164 - moving ave loss 26.46922347670994\n",
            "step 48 - loss 26.500499725341797 - moving ave loss 26.472351101573125\n",
            "step 49 - loss 23.613079071044922 - moving ave loss 26.186423898520307\n",
            "step 50 - loss 25.398326873779297 - moving ave loss 26.107614196046207\n",
            "step 51 - loss 24.636417388916016 - moving ave loss 25.96049451533319\n",
            "step 52 - loss 23.60637092590332 - moving ave loss 25.7250821563902\n",
            "step 53 - loss 24.663673400878906 - moving ave loss 25.618941280839074\n",
            "step 54 - loss 23.321640014648438 - moving ave loss 25.38921115422001\n",
            "step 55 - loss 23.87018585205078 - moving ave loss 25.237308624003088\n",
            "step 56 - loss 23.52857780456543 - moving ave loss 25.06643554205932\n",
            "step 57 - loss 23.617584228515625 - moving ave loss 24.92155041070495\n",
            "step 58 - loss 25.490921020507812 - moving ave loss 24.978487471685238\n",
            "step 59 - loss 22.364839553833008 - moving ave loss 24.717122679900015\n",
            "step 60 - loss 22.6647891998291 - moving ave loss 24.511889331892924\n",
            "step 61 - loss 22.787654876708984 - moving ave loss 24.33946588637453\n",
            "step 62 - loss 25.9454345703125 - moving ave loss 24.500062754768326\n",
            "step 63 - loss 23.591827392578125 - moving ave loss 24.409239218549306\n",
            "step 64 - loss 31.04859733581543 - moving ave loss 25.07317503027592\n",
            "step 65 - loss 25.446361541748047 - moving ave loss 25.110493681423137\n",
            "step 66 - loss 23.214847564697266 - moving ave loss 24.92092906975055\n",
            "step 67 - loss 22.595413208007812 - moving ave loss 24.68837748357628\n",
            "step 68 - loss 24.07244110107422 - moving ave loss 24.626783845326074\n",
            "step 69 - loss 22.19832992553711 - moving ave loss 24.38393845334718\n",
            "step 70 - loss 26.39110565185547 - moving ave loss 24.58465517319801\n",
            "step 71 - loss 23.544818878173828 - moving ave loss 24.48067154369559\n",
            "step 72 - loss 26.289794921875 - moving ave loss 24.661583881513533\n",
            "step 73 - loss 24.968963623046875 - moving ave loss 24.69232185566687\n",
            "step 74 - loss 22.12989616394043 - moving ave loss 24.436079286494227\n",
            "step 75 - loss 22.106664657592773 - moving ave loss 24.203137823604084\n",
            "step 76 - loss 21.6751766204834 - moving ave loss 23.950341703292015\n",
            "step 77 - loss 21.728240966796875 - moving ave loss 23.7281316296425\n",
            "step 78 - loss 21.592287063598633 - moving ave loss 23.514547173038114\n",
            "step 79 - loss 21.075637817382812 - moving ave loss 23.270656237472586\n",
            "step 80 - loss 22.94282341003418 - moving ave loss 23.237872954728743\n",
            "step 81 - loss 22.337997436523438 - moving ave loss 23.147885402908216\n",
            "step 82 - loss 21.540260314941406 - moving ave loss 22.987122894111536\n",
            "step 83 - loss 24.91217803955078 - moving ave loss 23.17962840865546\n",
            "step 84 - loss 22.199234008789062 - moving ave loss 23.08158896866882\n",
            "step 85 - loss 20.989051818847656 - moving ave loss 22.872335253686707\n",
            "step 86 - loss 21.338817596435547 - moving ave loss 22.71898348796159\n",
            "step 87 - loss 20.793596267700195 - moving ave loss 22.52644476593545\n",
            "step 88 - loss 20.517642974853516 - moving ave loss 22.32556458682726\n",
            "step 89 - loss 23.16693878173828 - moving ave loss 22.409702006318362\n",
            "step 90 - loss 21.56995391845703 - moving ave loss 22.32572719753223\n",
            "step 91 - loss 22.993865966796875 - moving ave loss 22.3925410744587\n",
            "step 92 - loss 20.477134704589844 - moving ave loss 22.201000437471812\n",
            "step 93 - loss 20.668746948242188 - moving ave loss 22.04777508854885\n",
            "step 94 - loss 20.975208282470703 - moving ave loss 21.940518407941035\n",
            "step 95 - loss 25.676427841186523 - moving ave loss 22.314109351265586\n",
            "step 96 - loss 21.084409713745117 - moving ave loss 22.19113938751354\n",
            "step 97 - loss 22.068553924560547 - moving ave loss 22.178880841218245\n",
            "step 98 - loss 22.677204132080078 - moving ave loss 22.228713170304427\n",
            "step 99 - loss 21.809057235717773 - moving ave loss 22.18674757684576\n",
            "step 100 - loss 20.231664657592773 - moving ave loss 21.991239284920464\n",
            "Finish 1 epoch(es)\n",
            "step 101 - loss 20.135936737060547 - moving ave loss 21.805709030134473\n",
            "step 102 - loss 19.62118911743164 - moving ave loss 21.58725703886419\n",
            "step 103 - loss 21.833885192871094 - moving ave loss 21.611919854264883\n",
            "step 104 - loss 20.865943908691406 - moving ave loss 21.537322259707537\n",
            "step 105 - loss 23.173725128173828 - moving ave loss 21.700962546554166\n",
            "step 106 - loss 21.093738555908203 - moving ave loss 21.64024014748957\n",
            "step 107 - loss 21.038589477539062 - moving ave loss 21.58007508049452\n",
            "step 108 - loss 21.07630729675293 - moving ave loss 21.529698302120362\n",
            "step 109 - loss 22.515092849731445 - moving ave loss 21.62823775688147\n",
            "step 110 - loss 18.94446563720703 - moving ave loss 21.359860544914028\n",
            "step 111 - loss 19.97244644165039 - moving ave loss 21.221119134587667\n",
            "step 112 - loss 20.214052200317383 - moving ave loss 21.12041244116064\n",
            "step 113 - loss 19.750659942626953 - moving ave loss 20.98343719130727\n",
            "step 114 - loss 19.805198669433594 - moving ave loss 20.865613339119903\n",
            "step 115 - loss 19.36098861694336 - moving ave loss 20.71515086690225\n",
            "step 116 - loss 19.308639526367188 - moving ave loss 20.574499732848746\n",
            "step 117 - loss 20.46160125732422 - moving ave loss 20.563209885296292\n",
            "step 118 - loss 19.615285873413086 - moving ave loss 20.468417484107974\n",
            "step 119 - loss 20.88384246826172 - moving ave loss 20.509959982523352\n",
            "step 120 - loss 19.046489715576172 - moving ave loss 20.363612955828632\n",
            "step 121 - loss 18.978206634521484 - moving ave loss 20.225072323697916\n",
            "step 122 - loss 19.144561767578125 - moving ave loss 20.11702126808594\n",
            "step 123 - loss 18.334678649902344 - moving ave loss 19.938787006267578\n",
            "step 124 - loss 18.343645095825195 - moving ave loss 19.77927281522334\n",
            "step 125 - loss 18.449298858642578 - moving ave loss 19.646275419565264\n",
            "step 126 - loss 19.657060623168945 - moving ave loss 19.647353939925633\n",
            "step 127 - loss 18.127948760986328 - moving ave loss 19.495413422031703\n",
            "step 128 - loss 18.046215057373047 - moving ave loss 19.35049358556584\n",
            "step 129 - loss 18.587352752685547 - moving ave loss 19.27417950227781\n",
            "step 130 - loss 18.167068481445312 - moving ave loss 19.16346840019456\n",
            "step 131 - loss 18.84355354309082 - moving ave loss 19.13147691448419\n",
            "step 132 - loss 19.569908142089844 - moving ave loss 19.175320037244756\n",
            "step 133 - loss 17.43762969970703 - moving ave loss 19.001551003490984\n",
            "step 134 - loss 18.96431541442871 - moving ave loss 18.997827444584757\n",
            "step 135 - loss 18.246448516845703 - moving ave loss 18.922689551810855\n",
            "step 136 - loss 17.939590454101562 - moving ave loss 18.824379642039926\n",
            "step 137 - loss 18.97830581665039 - moving ave loss 18.839772259500975\n",
            "step 138 - loss 20.499103546142578 - moving ave loss 19.005705388165136\n",
            "step 139 - loss 17.953678131103516 - moving ave loss 18.900502662458976\n",
            "step 140 - loss 17.783061981201172 - moving ave loss 18.788758594333196\n",
            "step 141 - loss 20.580215454101562 - moving ave loss 18.967904280310034\n",
            "step 142 - loss 17.476348876953125 - moving ave loss 18.818748739974342\n",
            "step 143 - loss 18.27689552307129 - moving ave loss 18.764563418284038\n",
            "step 144 - loss 18.184967041015625 - moving ave loss 18.706603780557195\n",
            "step 145 - loss 17.391719818115234 - moving ave loss 18.575115384313\n",
            "step 146 - loss 17.929515838623047 - moving ave loss 18.510555429744006\n",
            "step 147 - loss 17.364288330078125 - moving ave loss 18.39592871977742\n",
            "step 148 - loss 16.992326736450195 - moving ave loss 18.255568521444697\n",
            "step 149 - loss 17.480266571044922 - moving ave loss 18.17803832640472\n",
            "step 150 - loss 17.38641357421875 - moving ave loss 18.098875851186126\n",
            "step 151 - loss 17.112995147705078 - moving ave loss 18.000287780838022\n",
            "step 152 - loss 16.843528747558594 - moving ave loss 17.88461187751008\n",
            "step 153 - loss 17.034149169921875 - moving ave loss 17.79956560675126\n",
            "step 154 - loss 18.372844696044922 - moving ave loss 17.856893515680625\n",
            "step 155 - loss 17.129627227783203 - moving ave loss 17.784166886890883\n",
            "step 156 - loss 16.384845733642578 - moving ave loss 17.644234771566055\n",
            "step 157 - loss 16.679580688476562 - moving ave loss 17.547769363257107\n",
            "step 158 - loss 20.377622604370117 - moving ave loss 17.830754687368408\n",
            "step 159 - loss 16.636117935180664 - moving ave loss 17.711291012149633\n",
            "step 160 - loss 18.290851593017578 - moving ave loss 17.76924707023643\n",
            "step 161 - loss 16.992324829101562 - moving ave loss 17.69155484612294\n",
            "step 162 - loss 16.082948684692383 - moving ave loss 17.530694229979886\n",
            "step 163 - loss 16.960098266601562 - moving ave loss 17.473634633642053\n",
            "step 164 - loss 16.358789443969727 - moving ave loss 17.36215011467482\n",
            "step 165 - loss 16.333589553833008 - moving ave loss 17.25929405859064\n",
            "step 166 - loss 17.181228637695312 - moving ave loss 17.251487516501108\n",
            "step 167 - loss 16.40570068359375 - moving ave loss 17.16690883321037\n",
            "step 168 - loss 16.758996963500977 - moving ave loss 17.126117646239432\n",
            "step 169 - loss 19.01506805419922 - moving ave loss 17.31501268703541\n",
            "step 170 - loss 18.48748779296875 - moving ave loss 17.432260197628743\n",
            "step 171 - loss 16.382230758666992 - moving ave loss 17.32725725373257\n",
            "step 172 - loss 16.540613174438477 - moving ave loss 17.24859284580316\n",
            "step 173 - loss 15.763117790222168 - moving ave loss 17.10004534024506\n",
            "step 174 - loss 15.925344467163086 - moving ave loss 16.98257525293686\n",
            "step 175 - loss 16.67688751220703 - moving ave loss 16.95200647886388\n",
            "step 176 - loss 17.03052520751953 - moving ave loss 16.959858351729444\n",
            "step 177 - loss 16.392131805419922 - moving ave loss 16.903085697098494\n",
            "step 178 - loss 15.854981422424316 - moving ave loss 16.798275269631077\n",
            "step 179 - loss 16.114730834960938 - moving ave loss 16.72992082616406\n",
            "step 180 - loss 15.946684837341309 - moving ave loss 16.651597227281787\n",
            "step 181 - loss 16.85638427734375 - moving ave loss 16.67207593228798\n",
            "step 182 - loss 16.002582550048828 - moving ave loss 16.605126594064068\n",
            "step 183 - loss 16.106258392333984 - moving ave loss 16.55523977389106\n",
            "step 184 - loss 17.52947235107422 - moving ave loss 16.652663031609375\n",
            "step 185 - loss 15.529333114624023 - moving ave loss 16.54033003991084\n",
            "step 186 - loss 16.921798706054688 - moving ave loss 16.57847690652523\n",
            "step 187 - loss 15.668289184570312 - moving ave loss 16.48745813432974\n",
            "step 188 - loss 14.979723930358887 - moving ave loss 16.33668471393265\n",
            "step 189 - loss 14.931588172912598 - moving ave loss 16.196175059830647\n",
            "step 190 - loss 15.123689651489258 - moving ave loss 16.08892651899651\n",
            "step 191 - loss 15.287765502929688 - moving ave loss 16.008810417389828\n",
            "step 192 - loss 15.254621505737305 - moving ave loss 15.933391526224575\n",
            "step 193 - loss 15.260690689086914 - moving ave loss 15.86612144251081\n",
            "step 194 - loss 15.391548156738281 - moving ave loss 15.818664113933558\n",
            "step 195 - loss 16.324365615844727 - moving ave loss 15.869234264124676\n",
            "step 196 - loss 14.684171676635742 - moving ave loss 15.750728005375784\n",
            "step 197 - loss 16.604755401611328 - moving ave loss 15.83613074499934\n",
            "step 198 - loss 14.385555267333984 - moving ave loss 15.691073197232805\n",
            "step 199 - loss 16.97970199584961 - moving ave loss 15.819936077094487\n",
            "step 200 - loss 14.576330184936523 - moving ave loss 15.695575487878692\n",
            "Finish 2 epoch(es)\n",
            "step 201 - loss 15.080479621887207 - moving ave loss 15.634065901279545\n",
            "step 202 - loss 14.551324844360352 - moving ave loss 15.525791795587626\n",
            "step 203 - loss 14.489656448364258 - moving ave loss 15.422178260865289\n",
            "step 204 - loss 14.778858184814453 - moving ave loss 15.357846253260206\n",
            "step 205 - loss 14.559571266174316 - moving ave loss 15.278018754551617\n",
            "step 206 - loss 14.24720573425293 - moving ave loss 15.17493745252175\n",
            "step 207 - loss 15.138866424560547 - moving ave loss 15.171330349725629\n",
            "step 208 - loss 14.832796096801758 - moving ave loss 15.137476924433242\n",
            "step 209 - loss 14.53337287902832 - moving ave loss 15.07706651989275\n",
            "step 210 - loss 14.511427879333496 - moving ave loss 15.020502655836825\n",
            "step 211 - loss 15.777181625366211 - moving ave loss 15.096170552789765\n",
            "step 212 - loss 14.168571472167969 - moving ave loss 15.003410644727586\n",
            "step 213 - loss 14.262158393859863 - moving ave loss 14.929285419640813\n",
            "step 214 - loss 13.760725975036621 - moving ave loss 14.812429475180394\n",
            "step 215 - loss 13.997532844543457 - moving ave loss 14.730939812116702\n",
            "step 216 - loss 13.876602172851562 - moving ave loss 14.645506048190189\n",
            "step 217 - loss 13.57577896118164 - moving ave loss 14.538533339489334\n",
            "step 218 - loss 14.784542083740234 - moving ave loss 14.563134213914424\n",
            "step 219 - loss 13.973387718200684 - moving ave loss 14.50415956434305\n",
            "step 220 - loss 13.87187385559082 - moving ave loss 14.440930993467827\n",
            "step 221 - loss 13.932747840881348 - moving ave loss 14.39011267820918\n",
            "step 222 - loss 13.614583969116211 - moving ave loss 14.312559807299882\n",
            "step 223 - loss 15.362937927246094 - moving ave loss 14.417597619294504\n",
            "step 224 - loss 14.621419906616211 - moving ave loss 14.437979848026675\n",
            "step 225 - loss 13.685493469238281 - moving ave loss 14.362731210147835\n",
            "step 226 - loss 15.45120620727539 - moving ave loss 14.47157870986059\n",
            "step 227 - loss 13.383306503295898 - moving ave loss 14.362751489204122\n",
            "step 228 - loss 13.703004837036133 - moving ave loss 14.296776823987322\n",
            "step 229 - loss 14.326597213745117 - moving ave loss 14.299758862963103\n",
            "step 230 - loss 13.093863487243652 - moving ave loss 14.179169325391157\n",
            "step 231 - loss 13.613748550415039 - moving ave loss 14.122627247893545\n",
            "step 232 - loss 13.786287307739258 - moving ave loss 14.088993253878117\n",
            "step 233 - loss 13.51235580444336 - moving ave loss 14.031329508934643\n",
            "step 234 - loss 13.871114730834961 - moving ave loss 14.015308031124675\n",
            "step 235 - loss 13.533310890197754 - moving ave loss 13.967108317031984\n",
            "step 236 - loss 13.521326065063477 - moving ave loss 13.922530091835135\n",
            "step 237 - loss 15.454214096069336 - moving ave loss 14.075698492258557\n",
            "step 238 - loss 13.894285202026367 - moving ave loss 14.057557163235339\n",
            "step 239 - loss 13.86314582824707 - moving ave loss 14.038116029736514\n",
            "step 240 - loss 13.889010429382324 - moving ave loss 14.023205469701097\n",
            "step 241 - loss 13.69023323059082 - moving ave loss 13.989908245790069\n",
            "step 242 - loss 13.115045547485352 - moving ave loss 13.902421975959598\n",
            "step 243 - loss 12.68356704711914 - moving ave loss 13.780536483075553\n",
            "step 244 - loss 13.214073181152344 - moving ave loss 13.723890152883232\n",
            "step 245 - loss 13.491209983825684 - moving ave loss 13.700622135977477\n",
            "step 246 - loss 13.502923965454102 - moving ave loss 13.68085231892514\n",
            "step 247 - loss 12.818187713623047 - moving ave loss 13.594585858394932\n",
            "step 248 - loss 12.549562454223633 - moving ave loss 13.490083517977803\n",
            "step 249 - loss 12.547891616821289 - moving ave loss 13.395864327862153\n",
            "step 250 - loss 13.089080810546875 - moving ave loss 13.365185976130626\n",
            "Checkpoint at step 250\n",
            "step 251 - loss 12.845623970031738 - moving ave loss 13.313229775520737\n",
            "step 252 - loss 12.92348861694336 - moving ave loss 13.274255659663\n",
            "step 253 - loss 12.743806838989258 - moving ave loss 13.221210777595626\n",
            "step 254 - loss 12.878623962402344 - moving ave loss 13.186952096076299\n",
            "step 255 - loss 13.1602144241333 - moving ave loss 13.184278328882\n",
            "step 256 - loss 13.701549530029297 - moving ave loss 13.23600544899673\n",
            "step 257 - loss 12.619000434875488 - moving ave loss 13.174304947584606\n",
            "step 258 - loss 12.50364875793457 - moving ave loss 13.107239328619603\n",
            "step 259 - loss 12.60420036315918 - moving ave loss 13.056935432073562\n",
            "step 260 - loss 12.836122512817383 - moving ave loss 13.034854140147944\n",
            "step 261 - loss 12.868396759033203 - moving ave loss 13.018208402036471\n",
            "step 262 - loss 12.974861145019531 - moving ave loss 13.013873676334779\n",
            "step 263 - loss 13.852317810058594 - moving ave loss 13.097718089707161\n",
            "step 264 - loss 11.917750358581543 - moving ave loss 12.979721316594599\n",
            "step 265 - loss 12.766857147216797 - moving ave loss 12.958434899656819\n",
            "step 266 - loss 11.913467407226562 - moving ave loss 12.853938150413793\n",
            "step 267 - loss 13.29738998413086 - moving ave loss 12.8982833337855\n",
            "step 268 - loss 13.263182640075684 - moving ave loss 12.934773264414519\n",
            "step 269 - loss 12.906917572021484 - moving ave loss 12.931987695175216\n",
            "step 270 - loss 11.752237319946289 - moving ave loss 12.814012657652324\n",
            "step 271 - loss 12.005437850952148 - moving ave loss 12.733155176982306\n",
            "step 272 - loss 12.20250129699707 - moving ave loss 12.680089788983782\n",
            "step 273 - loss 12.495732307434082 - moving ave loss 12.661654040828813\n",
            "step 274 - loss 13.094855308532715 - moving ave loss 12.704974167599202\n",
            "step 275 - loss 12.672651290893555 - moving ave loss 12.701741879928639\n",
            "step 276 - loss 12.176279067993164 - moving ave loss 12.649195598735092\n",
            "step 277 - loss 11.739517211914062 - moving ave loss 12.55822776005299\n",
            "step 278 - loss 12.235557556152344 - moving ave loss 12.525960739662924\n",
            "step 279 - loss 11.47922134399414 - moving ave loss 12.421286800096047\n",
            "step 280 - loss 11.614255905151367 - moving ave loss 12.340583710601578\n",
            "step 281 - loss 12.060372352600098 - moving ave loss 12.31256257480143\n",
            "step 282 - loss 11.884223937988281 - moving ave loss 12.269728711120115\n",
            "step 283 - loss 11.9052734375 - moving ave loss 12.233283183758104\n",
            "step 284 - loss 12.062393188476562 - moving ave loss 12.21619418422995\n",
            "step 285 - loss 12.13444995880127 - moving ave loss 12.208019761687083\n",
            "step 286 - loss 12.260164260864258 - moving ave loss 12.213234211604801\n",
            "step 287 - loss 11.33028793334961 - moving ave loss 12.124939583779282\n",
            "step 288 - loss 11.386587142944336 - moving ave loss 12.051104339695787\n",
            "step 289 - loss 11.14875602722168 - moving ave loss 11.960869508448377\n",
            "step 290 - loss 11.854283332824707 - moving ave loss 11.95021089088601\n",
            "step 291 - loss 12.000188827514648 - moving ave loss 11.955208684548875\n",
            "step 292 - loss 11.66141128540039 - moving ave loss 11.925828944634027\n",
            "step 293 - loss 11.008468627929688 - moving ave loss 11.834092912963593\n",
            "step 294 - loss 11.028698921203613 - moving ave loss 11.753553513787596\n",
            "step 295 - loss 11.171855926513672 - moving ave loss 11.695383755060204\n",
            "step 296 - loss 12.96900749206543 - moving ave loss 11.822746128760727\n",
            "step 297 - loss 11.431768417358398 - moving ave loss 11.783648357620494\n",
            "step 298 - loss 11.058004379272461 - moving ave loss 11.711083959785691\n",
            "step 299 - loss 12.043489456176758 - moving ave loss 11.744324509424798\n",
            "step 300 - loss 12.159146308898926 - moving ave loss 11.785806689372212\n",
            "Finish 3 epoch(es)\n",
            "step 301 - loss 11.099052429199219 - moving ave loss 11.717131263354913\n",
            "step 302 - loss 11.117655754089355 - moving ave loss 11.657183712428356\n",
            "step 303 - loss 11.179792404174805 - moving ave loss 11.609444581603\n",
            "step 304 - loss 11.373909950256348 - moving ave loss 11.585891118468336\n",
            "step 305 - loss 11.658063888549805 - moving ave loss 11.593108395476483\n",
            "step 306 - loss 10.786466598510742 - moving ave loss 11.512444215779908\n",
            "step 307 - loss 11.221832275390625 - moving ave loss 11.48338302174098\n",
            "step 308 - loss 10.811952590942383 - moving ave loss 11.416239978661121\n",
            "step 309 - loss 10.772283554077148 - moving ave loss 11.351844336202724\n",
            "step 310 - loss 10.678326606750488 - moving ave loss 11.2844925632575\n",
            "step 311 - loss 11.558488845825195 - moving ave loss 11.31189219151427\n",
            "step 312 - loss 10.593400001525879 - moving ave loss 11.24004297251543\n",
            "step 313 - loss 11.131630897521973 - moving ave loss 11.229201765016084\n",
            "step 314 - loss 11.050891876220703 - moving ave loss 11.211370776136546\n",
            "step 315 - loss 10.554285049438477 - moving ave loss 11.145662203466738\n",
            "step 316 - loss 10.912527084350586 - moving ave loss 11.122348691555123\n",
            "step 317 - loss 10.799849510192871 - moving ave loss 11.090098773418898\n",
            "step 318 - loss 11.626845359802246 - moving ave loss 11.143773432057232\n",
            "step 319 - loss 10.59957504272461 - moving ave loss 11.08935359312397\n",
            "step 320 - loss 10.56769847869873 - moving ave loss 11.037188081681446\n",
            "step 321 - loss 10.519680976867676 - moving ave loss 10.985437371200069\n",
            "step 322 - loss 11.304612159729004 - moving ave loss 11.017354850052962\n",
            "step 323 - loss 10.389883995056152 - moving ave loss 10.954607764553282\n",
            "step 324 - loss 10.641875267028809 - moving ave loss 10.923334514800835\n",
            "step 325 - loss 10.571514129638672 - moving ave loss 10.888152476284619\n",
            "step 326 - loss 11.226213455200195 - moving ave loss 10.921958574176177\n",
            "step 327 - loss 10.713983535766602 - moving ave loss 10.901161070335219\n",
            "step 328 - loss 11.73458480834961 - moving ave loss 10.984503444136658\n",
            "step 329 - loss 11.367366790771484 - moving ave loss 11.022789778800142\n",
            "step 330 - loss 9.959098815917969 - moving ave loss 10.916420682511925\n",
            "step 331 - loss 10.632455825805664 - moving ave loss 10.8880241968413\n",
            "step 332 - loss 9.976213455200195 - moving ave loss 10.79684312267719\n",
            "step 333 - loss 10.125584602355957 - moving ave loss 10.729717270645066\n",
            "step 334 - loss 10.3804292678833 - moving ave loss 10.69478847036889\n",
            "step 335 - loss 10.143497467041016 - moving ave loss 10.639659370036103\n",
            "step 336 - loss 10.928818702697754 - moving ave loss 10.668575303302267\n",
            "step 337 - loss 10.156557083129883 - moving ave loss 10.617373481285028\n",
            "step 338 - loss 10.06332778930664 - moving ave loss 10.56196891208719\n",
            "step 339 - loss 9.970329284667969 - moving ave loss 10.502804949345268\n",
            "step 340 - loss 10.010815620422363 - moving ave loss 10.453606016452978\n",
            "step 341 - loss 9.93626594543457 - moving ave loss 10.401872009351138\n",
            "step 342 - loss 9.689512252807617 - moving ave loss 10.330636033696786\n",
            "step 343 - loss 9.967145919799805 - moving ave loss 10.294287022307088\n",
            "step 344 - loss 9.716014862060547 - moving ave loss 10.236459806282435\n",
            "step 345 - loss 10.800588607788086 - moving ave loss 10.292872686433\n",
            "step 346 - loss 10.15661907196045 - moving ave loss 10.279247324985745\n",
            "step 347 - loss 10.23288345336914 - moving ave loss 10.274610937824084\n",
            "step 348 - loss 12.164981842041016 - moving ave loss 10.463648028245778\n",
            "step 349 - loss 11.269073486328125 - moving ave loss 10.544190574054014\n",
            "step 350 - loss 10.301021575927734 - moving ave loss 10.519873674241387\n",
            "step 351 - loss 9.463848114013672 - moving ave loss 10.414271118218617\n",
            "step 352 - loss 10.08763313293457 - moving ave loss 10.381607319690213\n",
            "step 353 - loss 9.506258964538574 - moving ave loss 10.294072484175048\n",
            "step 354 - loss 9.611762046813965 - moving ave loss 10.225841440438941\n",
            "step 355 - loss 9.518386840820312 - moving ave loss 10.155095980477078\n",
            "step 356 - loss 10.72542667388916 - moving ave loss 10.212129049818287\n",
            "step 357 - loss 10.094141960144043 - moving ave loss 10.200330340850863\n",
            "step 358 - loss 10.073196411132812 - moving ave loss 10.187616947879057\n",
            "step 359 - loss 9.647783279418945 - moving ave loss 10.133633581033047\n",
            "step 360 - loss 9.913893699645996 - moving ave loss 10.111659592894341\n",
            "step 361 - loss 9.374685287475586 - moving ave loss 10.037962162352466\n",
            "step 362 - loss 9.369926452636719 - moving ave loss 9.971158591380892\n",
            "step 363 - loss 9.505256652832031 - moving ave loss 9.924568397526006\n",
            "step 364 - loss 9.618640899658203 - moving ave loss 9.893975647739225\n",
            "step 365 - loss 9.647676467895508 - moving ave loss 9.869345729754853\n",
            "step 366 - loss 9.433082580566406 - moving ave loss 9.825719414836009\n",
            "step 367 - loss 9.349716186523438 - moving ave loss 9.778119092004752\n",
            "step 368 - loss 9.901329040527344 - moving ave loss 9.79044008685701\n",
            "step 369 - loss 9.214532852172852 - moving ave loss 9.732849363388596\n",
            "step 370 - loss 9.677225112915039 - moving ave loss 9.72728693834124\n",
            "step 371 - loss 9.23444938659668 - moving ave loss 9.678003183166783\n",
            "step 372 - loss 9.822782516479492 - moving ave loss 9.692481116498055\n",
            "step 373 - loss 9.265609741210938 - moving ave loss 9.649793978969344\n",
            "step 374 - loss 9.360128402709961 - moving ave loss 9.620827421343405\n",
            "step 375 - loss 8.957269668579102 - moving ave loss 9.554471646066975\n",
            "step 376 - loss 10.323728561401367 - moving ave loss 9.631397337600415\n",
            "step 377 - loss 8.956185340881348 - moving ave loss 9.563876137928508\n",
            "step 378 - loss 9.214805603027344 - moving ave loss 9.528969084438392\n",
            "step 379 - loss 10.608661651611328 - moving ave loss 9.636938341155687\n",
            "step 380 - loss 9.091196060180664 - moving ave loss 9.582364113058185\n",
            "step 381 - loss 9.77130126953125 - moving ave loss 9.60125782870549\n",
            "step 382 - loss 9.078254699707031 - moving ave loss 9.548957515805645\n",
            "step 383 - loss 9.617624282836914 - moving ave loss 9.555824192508773\n",
            "step 384 - loss 8.623636245727539 - moving ave loss 9.46260539783065\n",
            "step 385 - loss 9.477258682250977 - moving ave loss 9.464070726272682\n",
            "step 386 - loss 9.641050338745117 - moving ave loss 9.481768687519926\n",
            "step 387 - loss 9.533956527709961 - moving ave loss 9.48698747153893\n",
            "step 388 - loss 8.995359420776367 - moving ave loss 9.437824666462674\n",
            "step 389 - loss 8.912464141845703 - moving ave loss 9.385288614000977\n",
            "step 390 - loss 9.53166389465332 - moving ave loss 9.399926142066212\n",
            "step 391 - loss 8.604303359985352 - moving ave loss 9.320363863858125\n",
            "step 392 - loss 9.156064987182617 - moving ave loss 9.303933976190574\n",
            "step 393 - loss 8.692749977111816 - moving ave loss 9.2428155762827\n",
            "step 394 - loss 9.014466285705566 - moving ave loss 9.219980647224988\n",
            "step 395 - loss 9.201620101928711 - moving ave loss 9.218144592695362\n",
            "step 396 - loss 9.004337310791016 - moving ave loss 9.196763864504927\n",
            "step 397 - loss 9.013708114624023 - moving ave loss 9.178458289516838\n",
            "step 398 - loss 8.836593627929688 - moving ave loss 9.144271823358123\n",
            "step 399 - loss 8.433667182922363 - moving ave loss 9.073211359314547\n",
            "step 400 - loss 8.680068016052246 - moving ave loss 9.033897024988317\n",
            "Finish 4 epoch(es)\n",
            "step 401 - loss 10.48793888092041 - moving ave loss 9.179301210581526\n",
            "step 402 - loss 8.472101211547852 - moving ave loss 9.108581210678159\n",
            "step 403 - loss 8.921719551086426 - moving ave loss 9.089895044718984\n",
            "step 404 - loss 8.268762588500977 - moving ave loss 9.007781799097183\n",
            "step 405 - loss 9.193790435791016 - moving ave loss 9.026382662766567\n",
            "step 406 - loss 8.637228965759277 - moving ave loss 8.987467293065837\n",
            "step 407 - loss 8.345714569091797 - moving ave loss 8.923292020668432\n",
            "step 408 - loss 8.809288024902344 - moving ave loss 8.911891621091824\n",
            "step 409 - loss 8.505659103393555 - moving ave loss 8.871268369321998\n",
            "step 410 - loss 8.77961540222168 - moving ave loss 8.862103072611966\n",
            "step 411 - loss 8.268645286560059 - moving ave loss 8.802757294006776\n",
            "step 412 - loss 8.588571548461914 - moving ave loss 8.78133871945229\n",
            "step 413 - loss 8.88256549835205 - moving ave loss 8.791461397342266\n",
            "step 414 - loss 8.482624053955078 - moving ave loss 8.760577663003547\n",
            "step 415 - loss 9.224431991577148 - moving ave loss 8.806963095860908\n",
            "step 416 - loss 8.33485221862793 - moving ave loss 8.75975200813761\n",
            "step 417 - loss 8.926013946533203 - moving ave loss 8.77637820197717\n",
            "step 418 - loss 9.212629318237305 - moving ave loss 8.820003313603184\n",
            "step 419 - loss 8.310101509094238 - moving ave loss 8.76901313315229\n",
            "step 420 - loss 8.47323226928711 - moving ave loss 8.739435046765772\n",
            "step 421 - loss 8.260963439941406 - moving ave loss 8.691587886083337\n",
            "step 422 - loss 8.493470191955566 - moving ave loss 8.671776116670559\n",
            "step 423 - loss 8.00356388092041 - moving ave loss 8.604954893095545\n",
            "step 424 - loss 8.341392517089844 - moving ave loss 8.578598655494975\n",
            "step 425 - loss 8.264036178588867 - moving ave loss 8.547142407804365\n",
            "step 426 - loss 7.888014793395996 - moving ave loss 8.481229646363529\n",
            "step 427 - loss 8.601436614990234 - moving ave loss 8.4932503432262\n",
            "step 428 - loss 8.805492401123047 - moving ave loss 8.524474549015885\n",
            "step 429 - loss 8.210861206054688 - moving ave loss 8.493113214719765\n",
            "step 430 - loss 7.93116569519043 - moving ave loss 8.436918462766831\n",
            "step 431 - loss 8.158047676086426 - moving ave loss 8.40903138409879\n",
            "step 432 - loss 7.805200099945068 - moving ave loss 8.348648255683418\n",
            "step 433 - loss 8.313154220581055 - moving ave loss 8.345098852173182\n",
            "step 434 - loss 8.557165145874023 - moving ave loss 8.366305481543266\n",
            "step 435 - loss 8.922599792480469 - moving ave loss 8.421934912636987\n",
            "step 436 - loss 8.16722297668457 - moving ave loss 8.396463719041746\n",
            "step 437 - loss 8.333532333374023 - moving ave loss 8.390170580474974\n",
            "step 438 - loss 8.204633712768555 - moving ave loss 8.371616893704331\n",
            "step 439 - loss 7.982843399047852 - moving ave loss 8.332739544238684\n",
            "step 440 - loss 8.077101707458496 - moving ave loss 8.307175760560666\n",
            "step 441 - loss 7.883538246154785 - moving ave loss 8.264812009120078\n",
            "step 442 - loss 8.434508323669434 - moving ave loss 8.281781640575014\n",
            "step 443 - loss 9.799569129943848 - moving ave loss 8.433560389511898\n",
            "step 444 - loss 7.608941078186035 - moving ave loss 8.351098458379312\n",
            "step 445 - loss 8.499871253967285 - moving ave loss 8.36597573793811\n",
            "step 446 - loss 8.213319778442383 - moving ave loss 8.350710141988536\n",
            "step 447 - loss 8.512454986572266 - moving ave loss 8.36688462644691\n",
            "step 448 - loss 8.476838111877441 - moving ave loss 8.377879974989963\n",
            "step 449 - loss 7.854250431060791 - moving ave loss 8.325517020597045\n",
            "step 450 - loss 7.702373504638672 - moving ave loss 8.263202669001208\n",
            "step 451 - loss 7.674466609954834 - moving ave loss 8.204329063096571\n",
            "step 452 - loss 7.976335525512695 - moving ave loss 8.181529709338184\n",
            "step 453 - loss 7.735898971557617 - moving ave loss 8.136966635560128\n",
            "step 454 - loss 7.742938041687012 - moving ave loss 8.097563776172816\n",
            "step 455 - loss 7.352452278137207 - moving ave loss 8.023052626369255\n",
            "step 456 - loss 8.466121673583984 - moving ave loss 8.067359531090728\n",
            "step 457 - loss 7.3728718757629395 - moving ave loss 7.99791076555795\n",
            "step 458 - loss 7.451057434082031 - moving ave loss 7.943225432410359\n",
            "step 459 - loss 7.260144233703613 - moving ave loss 7.874917312539685\n",
            "step 460 - loss 7.442183971405029 - moving ave loss 7.831643978426219\n",
            "step 461 - loss 8.19556999206543 - moving ave loss 7.8680365797901395\n",
            "step 462 - loss 7.828260898590088 - moving ave loss 7.864059011670135\n",
            "step 463 - loss 7.6320343017578125 - moving ave loss 7.840856540678903\n",
            "step 464 - loss 8.00069522857666 - moving ave loss 7.8568404094686795\n",
            "step 465 - loss 7.466930866241455 - moving ave loss 7.817849455145957\n",
            "step 466 - loss 8.078336715698242 - moving ave loss 7.843898181201186\n",
            "step 467 - loss 7.175342559814453 - moving ave loss 7.777042619062513\n",
            "step 468 - loss 7.742237567901611 - moving ave loss 7.773562113946423\n",
            "step 469 - loss 7.501720428466797 - moving ave loss 7.746377945398461\n",
            "step 470 - loss 7.930324554443359 - moving ave loss 7.764772606302951\n",
            "step 471 - loss 7.134120464324951 - moving ave loss 7.701707392105151\n",
            "step 472 - loss 7.682961463928223 - moving ave loss 7.699832799287458\n",
            "step 473 - loss 8.266559600830078 - moving ave loss 7.756505479441721\n",
            "step 474 - loss 7.179189682006836 - moving ave loss 7.698773899698233\n",
            "step 475 - loss 7.714135646820068 - moving ave loss 7.700310074410417\n",
            "step 476 - loss 7.250352382659912 - moving ave loss 7.6553143052353665\n",
            "step 477 - loss 7.330492973327637 - moving ave loss 7.622832172044594\n",
            "step 478 - loss 7.217011451721191 - moving ave loss 7.582250100012255\n",
            "step 479 - loss 7.372560501098633 - moving ave loss 7.561281140120893\n",
            "step 480 - loss 7.530189514160156 - moving ave loss 7.55817197752482\n",
            "step 481 - loss 7.36146354675293 - moving ave loss 7.538501134447632\n",
            "step 482 - loss 7.560417175292969 - moving ave loss 7.540692738532166\n",
            "step 483 - loss 6.944666862487793 - moving ave loss 7.481090150927729\n",
            "step 484 - loss 8.454866409301758 - moving ave loss 7.578467776765132\n",
            "step 485 - loss 7.092097282409668 - moving ave loss 7.5298307273295855\n",
            "step 486 - loss 6.935454368591309 - moving ave loss 7.470393091455758\n",
            "step 487 - loss 7.872028350830078 - moving ave loss 7.51055661739319\n",
            "step 488 - loss 7.120568752288818 - moving ave loss 7.4715578308827535\n",
            "step 489 - loss 7.844370365142822 - moving ave loss 7.508839084308761\n",
            "step 490 - loss 6.872371196746826 - moving ave loss 7.445192295552568\n",
            "step 491 - loss 7.482097625732422 - moving ave loss 7.448882828570553\n",
            "step 492 - loss 6.732823371887207 - moving ave loss 7.377276882902218\n",
            "step 493 - loss 6.974466323852539 - moving ave loss 7.33699582699725\n",
            "step 494 - loss 6.953484535217285 - moving ave loss 7.298644697819254\n",
            "step 495 - loss 7.281100749969482 - moving ave loss 7.296890303034277\n",
            "step 496 - loss 7.061340808868408 - moving ave loss 7.27333535361769\n",
            "step 497 - loss 7.098902225494385 - moving ave loss 7.25589204080536\n",
            "step 498 - loss 7.245759963989258 - moving ave loss 7.25487883312375\n",
            "step 499 - loss 7.282320022583008 - moving ave loss 7.257622952069676\n",
            "step 500 - loss 7.172886848449707 - moving ave loss 7.249149341707679\n",
            "Checkpoint at step 500\n",
            "Finish 5 epoch(es)\n",
            "step 501 - loss 7.449965476989746 - moving ave loss 7.269230955235886\n",
            "step 502 - loss 7.441876411437988 - moving ave loss 7.2864955008560965\n",
            "step 503 - loss 6.833086013793945 - moving ave loss 7.241154552149881\n",
            "step 504 - loss 6.806450843811035 - moving ave loss 7.1976841813159975\n",
            "step 505 - loss 7.084686279296875 - moving ave loss 7.1863843911140854\n",
            "step 506 - loss 6.889883518218994 - moving ave loss 7.156734303824577\n",
            "step 507 - loss 7.791320323944092 - moving ave loss 7.220192905836529\n",
            "step 508 - loss 6.856964111328125 - moving ave loss 7.183870026385689\n",
            "step 509 - loss 7.119715690612793 - moving ave loss 7.1774545928084\n",
            "step 510 - loss 6.746720314025879 - moving ave loss 7.134381164930148\n",
            "step 511 - loss 7.080541610717773 - moving ave loss 7.128997209508912\n",
            "step 512 - loss 7.726561546325684 - moving ave loss 7.188753643190589\n",
            "step 513 - loss 6.790184020996094 - moving ave loss 7.14889668097114\n",
            "step 514 - loss 6.4059247970581055 - moving ave loss 7.074599492579837\n",
            "step 515 - loss 6.885658264160156 - moving ave loss 7.055705369737868\n",
            "step 516 - loss 7.623198509216309 - moving ave loss 7.112454683685712\n",
            "step 517 - loss 6.4664692878723145 - moving ave loss 7.047856144104372\n",
            "step 518 - loss 7.307195663452148 - moving ave loss 7.07379009603915\n",
            "step 519 - loss 6.903327465057373 - moving ave loss 7.056743832940972\n",
            "step 520 - loss 6.674360275268555 - moving ave loss 7.018505477173731\n",
            "step 521 - loss 6.583481788635254 - moving ave loss 6.975003108319884\n",
            "step 522 - loss 7.05560302734375 - moving ave loss 6.983063100222271\n",
            "step 523 - loss 7.085659503936768 - moving ave loss 6.993322740593721\n",
            "step 524 - loss 6.6124677658081055 - moving ave loss 6.9552372431151595\n",
            "step 525 - loss 6.869269371032715 - moving ave loss 6.946640455906914\n",
            "step 526 - loss 8.148961067199707 - moving ave loss 7.0668725170361935\n",
            "step 527 - loss 6.726296424865723 - moving ave loss 7.032814907819146\n",
            "step 528 - loss 6.386470794677734 - moving ave loss 6.968180496505005\n",
            "step 529 - loss 6.438379287719727 - moving ave loss 6.915200375626478\n",
            "step 530 - loss 7.863262176513672 - moving ave loss 7.010006555715197\n",
            "step 531 - loss 6.791205406188965 - moving ave loss 6.988126440762574\n",
            "step 532 - loss 6.547351837158203 - moving ave loss 6.944048980402137\n",
            "step 533 - loss 6.4355387687683105 - moving ave loss 6.893197959238755\n",
            "step 534 - loss 6.436663627624512 - moving ave loss 6.84754452607733\n",
            "step 535 - loss 6.667873382568359 - moving ave loss 6.829577411726434\n",
            "step 536 - loss 7.562786102294922 - moving ave loss 6.902898280783283\n",
            "step 537 - loss 6.389990329742432 - moving ave loss 6.851607485679198\n",
            "step 538 - loss 7.574747085571289 - moving ave loss 6.923921445668407\n",
            "step 539 - loss 6.53782844543457 - moving ave loss 6.885312145645024\n",
            "step 540 - loss 6.634060859680176 - moving ave loss 6.860187017048539\n",
            "step 541 - loss 6.478054523468018 - moving ave loss 6.821973767690487\n",
            "step 542 - loss 6.213438987731934 - moving ave loss 6.761120289694632\n",
            "step 543 - loss 6.219861030578613 - moving ave loss 6.70699436378303\n",
            "step 544 - loss 6.402195453643799 - moving ave loss 6.676514472769107\n",
            "step 545 - loss 6.272453308105469 - moving ave loss 6.636108356302743\n",
            "step 546 - loss 6.571328163146973 - moving ave loss 6.629630336987166\n",
            "step 547 - loss 6.677829742431641 - moving ave loss 6.634450277531614\n",
            "step 548 - loss 6.230903148651123 - moving ave loss 6.594095564643565\n",
            "step 549 - loss 6.439509391784668 - moving ave loss 6.578636947357675\n",
            "step 550 - loss 6.12322998046875 - moving ave loss 6.533096250668783\n",
            "step 551 - loss 6.135443687438965 - moving ave loss 6.4933309943458015\n",
            "step 552 - loss 6.576879501342773 - moving ave loss 6.501685845045499\n",
            "step 553 - loss 6.003541946411133 - moving ave loss 6.451871455182062\n",
            "step 554 - loss 6.3018903732299805 - moving ave loss 6.436873346986854\n",
            "step 555 - loss 6.769779682159424 - moving ave loss 6.470163980504111\n",
            "step 556 - loss 5.9625349044799805 - moving ave loss 6.419401072901698\n",
            "step 557 - loss 6.4882283210754395 - moving ave loss 6.426283797719072\n",
            "step 558 - loss 6.3774919509887695 - moving ave loss 6.421404613046041\n",
            "step 559 - loss 5.889711380004883 - moving ave loss 6.368235289741926\n",
            "step 560 - loss 6.241669654846191 - moving ave loss 6.355578726252353\n",
            "step 561 - loss 5.956841945648193 - moving ave loss 6.315705048191937\n",
            "step 562 - loss 6.011026382446289 - moving ave loss 6.285237181617372\n",
            "step 563 - loss 5.747088432312012 - moving ave loss 6.231422306686837\n",
            "step 564 - loss 6.254950523376465 - moving ave loss 6.2337751283558\n",
            "step 565 - loss 7.555171966552734 - moving ave loss 6.365914812175494\n",
            "step 566 - loss 5.985370635986328 - moving ave loss 6.327860394556577\n",
            "step 567 - loss 6.8780717849731445 - moving ave loss 6.382881533598233\n",
            "step 568 - loss 7.006008148193359 - moving ave loss 6.445194195057747\n",
            "step 569 - loss 6.039514541625977 - moving ave loss 6.4046262297145695\n",
            "step 570 - loss 6.077388763427734 - moving ave loss 6.371902483085886\n",
            "step 571 - loss 6.156737327575684 - moving ave loss 6.350385967534867\n",
            "step 572 - loss 6.443521022796631 - moving ave loss 6.359699473061044\n",
            "step 573 - loss 5.914475440979004 - moving ave loss 6.31517706985284\n",
            "step 574 - loss 5.660785675048828 - moving ave loss 6.249737930372439\n",
            "step 575 - loss 5.797046661376953 - moving ave loss 6.204468803472891\n",
            "step 576 - loss 6.10536527633667 - moving ave loss 6.19455845075927\n",
            "step 577 - loss 6.262296676635742 - moving ave loss 6.201332273346917\n",
            "step 578 - loss 6.153189182281494 - moving ave loss 6.196517964240376\n",
            "step 579 - loss 6.270559787750244 - moving ave loss 6.203922146591363\n",
            "step 580 - loss 5.8886260986328125 - moving ave loss 6.172392541795508\n",
            "step 581 - loss 5.826592922210693 - moving ave loss 6.137812579837027\n",
            "step 582 - loss 5.827121734619141 - moving ave loss 6.106743495315238\n",
            "step 583 - loss 6.283226013183594 - moving ave loss 6.124391747102074\n",
            "step 584 - loss 6.049878120422363 - moving ave loss 6.116940384434103\n",
            "step 585 - loss 5.688663482666016 - moving ave loss 6.074112694257294\n",
            "step 586 - loss 6.285699367523193 - moving ave loss 6.095271361583883\n",
            "step 587 - loss 5.805943489074707 - moving ave loss 6.066338574332965\n",
            "step 588 - loss 5.95505428314209 - moving ave loss 6.055210145213878\n",
            "step 589 - loss 5.832757472991943 - moving ave loss 6.0329648779916845\n",
            "step 590 - loss 5.744462966918945 - moving ave loss 6.00411468688441\n",
            "step 591 - loss 5.6231584548950195 - moving ave loss 5.966019063685471\n",
            "step 592 - loss 5.469348430633545 - moving ave loss 5.916352000380279\n",
            "step 593 - loss 5.765515327453613 - moving ave loss 5.901268333087612\n",
            "step 594 - loss 5.822032928466797 - moving ave loss 5.8933447926255305\n",
            "step 595 - loss 5.488473892211914 - moving ave loss 5.852857702584169\n",
            "step 596 - loss 5.598680019378662 - moving ave loss 5.8274399342636185\n",
            "step 597 - loss 5.536266326904297 - moving ave loss 5.798322573527686\n",
            "step 598 - loss 5.745354652404785 - moving ave loss 5.7930257814153965\n",
            "step 599 - loss 5.3306074142456055 - moving ave loss 5.746783944698418\n",
            "step 600 - loss 5.40060567855835 - moving ave loss 5.712166118084411\n",
            "Finish 6 epoch(es)\n",
            "step 601 - loss 5.658296585083008 - moving ave loss 5.706779164784272\n",
            "step 602 - loss 6.673013210296631 - moving ave loss 5.803402569335508\n",
            "step 603 - loss 5.803779125213623 - moving ave loss 5.803440224923319\n",
            "step 604 - loss 5.926641464233398 - moving ave loss 5.815760348854328\n",
            "step 605 - loss 5.853489875793457 - moving ave loss 5.819533301548241\n",
            "step 606 - loss 5.480108261108398 - moving ave loss 5.785590797504257\n",
            "step 607 - loss 5.4179511070251465 - moving ave loss 5.748826828456346\n",
            "step 608 - loss 5.5800886154174805 - moving ave loss 5.73195300715246\n",
            "step 609 - loss 6.208381652832031 - moving ave loss 5.779595871720417\n",
            "step 610 - loss 6.0243425369262695 - moving ave loss 5.804070538241003\n",
            "step 611 - loss 5.668891906738281 - moving ave loss 5.790552675090732\n",
            "step 612 - loss 5.289375305175781 - moving ave loss 5.740434938099237\n",
            "step 613 - loss 5.116204261779785 - moving ave loss 5.678011870467293\n",
            "step 614 - loss 6.098906517028809 - moving ave loss 5.720101335123444\n",
            "step 615 - loss 6.593683242797852 - moving ave loss 5.807459525890885\n",
            "step 616 - loss 5.284579277038574 - moving ave loss 5.755171501005654\n",
            "step 617 - loss 6.442888259887695 - moving ave loss 5.823943176893858\n",
            "step 618 - loss 5.4789509773254395 - moving ave loss 5.789443956937016\n",
            "step 619 - loss 5.805599689483643 - moving ave loss 5.791059530191679\n",
            "step 620 - loss 5.406639099121094 - moving ave loss 5.7526174870846205\n",
            "step 621 - loss 5.187988758087158 - moving ave loss 5.6961546141848745\n",
            "step 622 - loss 5.379541397094727 - moving ave loss 5.66449329247586\n",
            "step 623 - loss 5.576119422912598 - moving ave loss 5.6556559055195335\n",
            "step 624 - loss 5.258657455444336 - moving ave loss 5.615956060512014\n",
            "step 625 - loss 5.945730209350586 - moving ave loss 5.6489334753958715\n",
            "step 626 - loss 5.600699424743652 - moving ave loss 5.64411007033065\n",
            "step 627 - loss 5.543895721435547 - moving ave loss 5.63408863544114\n",
            "step 628 - loss 5.466268062591553 - moving ave loss 5.617306578156182\n",
            "step 629 - loss 5.231338024139404 - moving ave loss 5.578709722754504\n",
            "step 630 - loss 5.4700775146484375 - moving ave loss 5.567846501943897\n",
            "step 631 - loss 5.32780647277832 - moving ave loss 5.54384249902734\n",
            "step 632 - loss 5.199761390686035 - moving ave loss 5.50943438819321\n",
            "step 633 - loss 5.37355899810791 - moving ave loss 5.49584684918468\n",
            "step 634 - loss 6.280145645141602 - moving ave loss 5.574276728780372\n",
            "step 635 - loss 5.316507339477539 - moving ave loss 5.548499789850089\n",
            "step 636 - loss 5.208273887634277 - moving ave loss 5.514477199628508\n",
            "step 637 - loss 5.3761067390441895 - moving ave loss 5.500640153570076\n",
            "step 638 - loss 5.028350830078125 - moving ave loss 5.453411221220882\n",
            "step 639 - loss 5.522419452667236 - moving ave loss 5.4603120443655175\n",
            "step 640 - loss 5.733804225921631 - moving ave loss 5.487661262521129\n",
            "step 641 - loss 5.603877067565918 - moving ave loss 5.499282843025608\n",
            "step 642 - loss 5.390783786773682 - moving ave loss 5.488432937400416\n",
            "step 643 - loss 6.286833763122559 - moving ave loss 5.56827301997263\n",
            "step 644 - loss 4.941045761108398 - moving ave loss 5.505550294086207\n",
            "step 645 - loss 5.645467758178711 - moving ave loss 5.519542040495458\n",
            "step 646 - loss 5.193032741546631 - moving ave loss 5.486891110600576\n",
            "step 647 - loss 5.630703449249268 - moving ave loss 5.501272344465445\n",
            "step 648 - loss 5.359310150146484 - moving ave loss 5.487076125033549\n",
            "step 649 - loss 5.17337703704834 - moving ave loss 5.455706216235028\n",
            "step 650 - loss 5.039026260375977 - moving ave loss 5.4140382206491235\n",
            "step 651 - loss 5.007633209228516 - moving ave loss 5.3733977195070635\n",
            "step 652 - loss 4.945263862609863 - moving ave loss 5.3305843338173435\n",
            "step 653 - loss 4.771469593048096 - moving ave loss 5.274672859740418\n",
            "step 654 - loss 5.08988618850708 - moving ave loss 5.256194192617085\n",
            "step 655 - loss 4.726942539215088 - moving ave loss 5.2032690272768845\n",
            "step 656 - loss 4.961181640625 - moving ave loss 5.179060288611696\n",
            "step 657 - loss 5.560084342956543 - moving ave loss 5.217162694046181\n",
            "step 658 - loss 6.3615217208862305 - moving ave loss 5.331598596730186\n",
            "step 659 - loss 5.10350227355957 - moving ave loss 5.308788964413124\n",
            "step 660 - loss 4.772680282592773 - moving ave loss 5.255178096231089\n",
            "step 661 - loss 6.484466552734375 - moving ave loss 5.378106941881418\n",
            "step 662 - loss 4.959239482879639 - moving ave loss 5.33622019598124\n",
            "step 663 - loss 4.746386528015137 - moving ave loss 5.27723682918463\n",
            "step 664 - loss 4.7692551612854 - moving ave loss 5.226438662394707\n",
            "step 665 - loss 4.880781650543213 - moving ave loss 5.191872961209557\n",
            "step 666 - loss 5.170341491699219 - moving ave loss 5.189719814258523\n",
            "step 667 - loss 4.942813396453857 - moving ave loss 5.165029172478056\n",
            "step 668 - loss 4.789541721343994 - moving ave loss 5.12748042736465\n",
            "step 669 - loss 4.924074649810791 - moving ave loss 5.107139849609264\n",
            "step 670 - loss 4.80394172668457 - moving ave loss 5.076820037316795\n",
            "step 671 - loss 4.850831031799316 - moving ave loss 5.054221136765047\n",
            "step 672 - loss 5.211709499359131 - moving ave loss 5.069969973024455\n",
            "step 673 - loss 4.981734752655029 - moving ave loss 5.061146450987513\n",
            "step 674 - loss 4.832403182983398 - moving ave loss 5.038272124187102\n",
            "step 675 - loss 5.427584171295166 - moving ave loss 5.077203328897908\n",
            "step 676 - loss 4.522787094116211 - moving ave loss 5.021761705419738\n",
            "step 677 - loss 4.89130163192749 - moving ave loss 5.008715698070514\n",
            "step 678 - loss 5.110288143157959 - moving ave loss 5.018872942579258\n",
            "step 679 - loss 4.8489508628845215 - moving ave loss 5.001880734609784\n",
            "step 680 - loss 5.828484058380127 - moving ave loss 5.0845410669868185\n",
            "step 681 - loss 4.657957077026367 - moving ave loss 5.041882667990774\n",
            "step 682 - loss 4.785891056060791 - moving ave loss 5.016283506797776\n",
            "step 683 - loss 5.280622482299805 - moving ave loss 5.042717404347979\n",
            "step 684 - loss 4.593804359436035 - moving ave loss 4.997826099856784\n",
            "step 685 - loss 4.701817512512207 - moving ave loss 4.968225241122326\n",
            "step 686 - loss 4.911294460296631 - moving ave loss 4.962532163039756\n",
            "step 687 - loss 5.000232219696045 - moving ave loss 4.9663021687053845\n",
            "step 688 - loss 4.863147735595703 - moving ave loss 4.955986725394417\n",
            "step 689 - loss 4.812641143798828 - moving ave loss 4.941652167234858\n",
            "step 690 - loss 4.910959720611572 - moving ave loss 4.93858292257253\n",
            "step 691 - loss 4.862332344055176 - moving ave loss 4.930957864720795\n",
            "step 692 - loss 4.79307746887207 - moving ave loss 4.917169825135922\n",
            "step 693 - loss 4.539700508117676 - moving ave loss 4.879422893434097\n",
            "step 694 - loss 4.67763614654541 - moving ave loss 4.8592442187452285\n",
            "step 695 - loss 4.974686622619629 - moving ave loss 4.870788459132669\n",
            "step 696 - loss 5.102181434631348 - moving ave loss 4.893927756682537\n",
            "step 697 - loss 4.633291244506836 - moving ave loss 4.8678641054649665\n",
            "step 698 - loss 4.931746482849121 - moving ave loss 4.8742523432033815\n",
            "step 699 - loss 4.629884719848633 - moving ave loss 4.849815580867906\n",
            "step 700 - loss 4.748557090759277 - moving ave loss 4.839689731857043\n",
            "Finish 7 epoch(es)\n",
            "step 701 - loss 4.739631175994873 - moving ave loss 4.829683876270826\n",
            "step 702 - loss 5.200192928314209 - moving ave loss 4.866734781475165\n",
            "step 703 - loss 5.019809722900391 - moving ave loss 4.882042275617688\n",
            "step 704 - loss 4.731949806213379 - moving ave loss 4.867033028677257\n",
            "step 705 - loss 5.450876235961914 - moving ave loss 4.9254173494057225\n",
            "step 706 - loss 4.987493515014648 - moving ave loss 4.9316249659666145\n",
            "step 707 - loss 4.694452285766602 - moving ave loss 4.907907697946613\n",
            "step 708 - loss 4.447336196899414 - moving ave loss 4.861850547841893\n",
            "step 709 - loss 4.6159348487854 - moving ave loss 4.837258977936243\n",
            "step 710 - loss 4.738886833190918 - moving ave loss 4.827421763461711\n",
            "step 711 - loss 4.979336261749268 - moving ave loss 4.842613213290467\n",
            "step 712 - loss 4.726254463195801 - moving ave loss 4.830977338281\n",
            "step 713 - loss 4.762969017028809 - moving ave loss 4.824176506155782\n",
            "step 714 - loss 4.530550003051758 - moving ave loss 4.794813855845379\n",
            "step 715 - loss 4.548588752746582 - moving ave loss 4.770191345535499\n",
            "step 716 - loss 4.574385166168213 - moving ave loss 4.750610727598771\n",
            "step 717 - loss 4.347699165344238 - moving ave loss 4.710319571373318\n",
            "step 718 - loss 4.474461078643799 - moving ave loss 4.6867337221003655\n",
            "step 719 - loss 4.672738075256348 - moving ave loss 4.685334157415964\n",
            "step 720 - loss 6.444759368896484 - moving ave loss 4.861276678564016\n",
            "step 721 - loss 4.605541229248047 - moving ave loss 4.835703133632419\n",
            "step 722 - loss 4.6416754722595215 - moving ave loss 4.81630036749513\n",
            "step 723 - loss 4.661957740783691 - moving ave loss 4.800866104823987\n",
            "step 724 - loss 4.499322891235352 - moving ave loss 4.770711783465123\n",
            "step 725 - loss 4.782934188842773 - moving ave loss 4.7719340240028885\n",
            "step 726 - loss 4.640069007873535 - moving ave loss 4.758747522389953\n",
            "step 727 - loss 4.81905460357666 - moving ave loss 4.764778230508624\n",
            "step 728 - loss 4.823214530944824 - moving ave loss 4.770621860552245\n",
            "step 729 - loss 4.335867881774902 - moving ave loss 4.7271464626745106\n",
            "step 730 - loss 4.598614692687988 - moving ave loss 4.714293285675859\n",
            "step 731 - loss 4.346308708190918 - moving ave loss 4.677494827927364\n",
            "step 732 - loss 4.284645080566406 - moving ave loss 4.6382098531912686\n",
            "step 733 - loss 4.33837890625 - moving ave loss 4.608226758497142\n",
            "step 734 - loss 4.743915557861328 - moving ave loss 4.62179563843356\n",
            "step 735 - loss 4.420370101928711 - moving ave loss 4.601653084783075\n",
            "step 736 - loss 4.909672260284424 - moving ave loss 4.63245500233321\n",
            "step 737 - loss 4.399193286895752 - moving ave loss 4.609128830789464\n",
            "step 738 - loss 4.713722229003906 - moving ave loss 4.619588170610908\n",
            "step 739 - loss 5.01048469543457 - moving ave loss 4.658677823093274\n",
            "step 740 - loss 4.44301700592041 - moving ave loss 4.637111741375988\n",
            "step 741 - loss 4.244815826416016 - moving ave loss 4.597882149879991\n",
            "step 742 - loss 4.276980400085449 - moving ave loss 4.565791974900538\n",
            "step 743 - loss 4.372710227966309 - moving ave loss 4.546483800207116\n",
            "step 744 - loss 4.5804290771484375 - moving ave loss 4.549878327901248\n",
            "step 745 - loss 4.113070011138916 - moving ave loss 4.506197496225015\n",
            "step 746 - loss 4.326593399047852 - moving ave loss 4.488237086507299\n",
            "step 747 - loss 4.705392837524414 - moving ave loss 4.50995266160901\n",
            "step 748 - loss 4.281166076660156 - moving ave loss 4.487074003114125\n",
            "step 749 - loss 4.467924118041992 - moving ave loss 4.485159014606912\n",
            "step 750 - loss 4.281486511230469 - moving ave loss 4.464791764269267\n",
            "Checkpoint at step 750\n",
            "step 751 - loss 4.259099006652832 - moving ave loss 4.4442224885076245\n",
            "step 752 - loss 4.588315010070801 - moving ave loss 4.458631740663942\n",
            "step 753 - loss 4.229649543762207 - moving ave loss 4.435733520973769\n",
            "step 754 - loss 4.097827434539795 - moving ave loss 4.401942912330371\n",
            "step 755 - loss 4.407750129699707 - moving ave loss 4.402523634067305\n",
            "step 756 - loss 4.018150329589844 - moving ave loss 4.364086303619558\n",
            "step 757 - loss 4.490192413330078 - moving ave loss 4.37669691459061\n",
            "step 758 - loss 4.178653717041016 - moving ave loss 4.356892594835651\n",
            "step 759 - loss 5.304885387420654 - moving ave loss 4.451691874094152\n",
            "step 760 - loss 4.421581268310547 - moving ave loss 4.448680813515792\n",
            "step 761 - loss 4.311382293701172 - moving ave loss 4.43495096153433\n",
            "step 762 - loss 4.954570770263672 - moving ave loss 4.4869129424072645\n",
            "step 763 - loss 3.985353946685791 - moving ave loss 4.436757042835118\n",
            "step 764 - loss 4.174378871917725 - moving ave loss 4.4105192257433785\n",
            "step 765 - loss 4.380666732788086 - moving ave loss 4.40753397644785\n",
            "step 766 - loss 4.018021106719971 - moving ave loss 4.368582689475062\n",
            "step 767 - loss 4.672913551330566 - moving ave loss 4.3990157756606125\n",
            "step 768 - loss 4.321990966796875 - moving ave loss 4.391313294774239\n",
            "step 769 - loss 4.290404319763184 - moving ave loss 4.381222397273134\n",
            "step 770 - loss 4.144707679748535 - moving ave loss 4.357570925520673\n",
            "step 771 - loss 4.285980224609375 - moving ave loss 4.3504118554295435\n",
            "step 772 - loss 4.408682823181152 - moving ave loss 4.356238952204705\n",
            "step 773 - loss 4.175770282745361 - moving ave loss 4.33819208525877\n",
            "step 774 - loss 4.0972490310668945 - moving ave loss 4.3140977798395825\n",
            "step 775 - loss 4.071917533874512 - moving ave loss 4.289879755243076\n",
            "step 776 - loss 3.9513931274414062 - moving ave loss 4.2560310924629094\n",
            "step 777 - loss 4.037590026855469 - moving ave loss 4.2341869859021655\n",
            "step 778 - loss 4.072551727294922 - moving ave loss 4.218023460041441\n",
            "step 779 - loss 4.356754302978516 - moving ave loss 4.231896544335148\n",
            "step 780 - loss 4.053497314453125 - moving ave loss 4.214056621346947\n",
            "step 781 - loss 3.9178504943847656 - moving ave loss 4.184436008650729\n",
            "step 782 - loss 4.0077924728393555 - moving ave loss 4.166771655069592\n",
            "step 783 - loss 4.075362205505371 - moving ave loss 4.15763071011317\n",
            "step 784 - loss 3.7605128288269043 - moving ave loss 4.117918921984543\n",
            "step 785 - loss 3.845625400543213 - moving ave loss 4.090689569840411\n",
            "step 786 - loss 3.9195213317871094 - moving ave loss 4.07357274603508\n",
            "step 787 - loss 4.299698352813721 - moving ave loss 4.096185306712944\n",
            "step 788 - loss 3.892500877380371 - moving ave loss 4.0758168637796865\n",
            "step 789 - loss 3.815031051635742 - moving ave loss 4.049738282565292\n",
            "step 790 - loss 4.333670616149902 - moving ave loss 4.078131515923753\n",
            "step 791 - loss 3.7408151626586914 - moving ave loss 4.044399880597247\n",
            "step 792 - loss 4.914412975311279 - moving ave loss 4.13140119006865\n",
            "step 793 - loss 4.076740741729736 - moving ave loss 4.125935145234759\n",
            "step 794 - loss 3.9609436988830566 - moving ave loss 4.1094360005995885\n",
            "step 795 - loss 3.766829490661621 - moving ave loss 4.075175349605792\n",
            "step 796 - loss 3.654265880584717 - moving ave loss 4.033084402703684\n",
            "step 797 - loss 3.876035213470459 - moving ave loss 4.017379483780362\n",
            "step 798 - loss 4.050159454345703 - moving ave loss 4.020657480836896\n",
            "step 799 - loss 4.411552906036377 - moving ave loss 4.059747023356843\n",
            "step 800 - loss 4.5242919921875 - moving ave loss 4.106201520239909\n",
            "Finish 8 epoch(es)\n",
            "step 801 - loss 3.9959022998809814 - moving ave loss 4.095171598204017\n",
            "step 802 - loss 3.881974220275879 - moving ave loss 4.073851860411203\n",
            "step 803 - loss 3.810932159423828 - moving ave loss 4.047559890312465\n",
            "step 804 - loss 3.695384979248047 - moving ave loss 4.012342399206023\n",
            "step 805 - loss 3.9418792724609375 - moving ave loss 4.005296086531515\n",
            "step 806 - loss 4.007041931152344 - moving ave loss 4.005470670993597\n",
            "step 807 - loss 3.8123221397399902 - moving ave loss 3.986155817868237\n",
            "step 808 - loss 3.69541335105896 - moving ave loss 3.9570815711873095\n",
            "step 809 - loss 3.9516890048980713 - moving ave loss 3.956542314558386\n",
            "step 810 - loss 3.8755528926849365 - moving ave loss 3.948443372371041\n",
            "step 811 - loss 4.171794414520264 - moving ave loss 3.9707784765859633\n",
            "step 812 - loss 4.1246137619018555 - moving ave loss 3.986162005117553\n",
            "step 813 - loss 3.6247477531433105 - moving ave loss 3.9500205799201287\n",
            "step 814 - loss 3.812727928161621 - moving ave loss 3.936291314744278\n",
            "step 815 - loss 3.9083361625671387 - moving ave loss 3.9334957995265643\n",
            "step 816 - loss 3.7960205078125 - moving ave loss 3.919748270355158\n",
            "step 817 - loss 3.750361204147339 - moving ave loss 3.902809563734376\n",
            "step 818 - loss 3.966792106628418 - moving ave loss 3.9092078180237806\n",
            "step 819 - loss 4.398664951324463 - moving ave loss 3.958153531353849\n",
            "step 820 - loss 4.145214557647705 - moving ave loss 3.976859633983235\n",
            "step 821 - loss 3.880173444747925 - moving ave loss 3.9671910150597043\n",
            "step 822 - loss 3.5794169902801514 - moving ave loss 3.9284136125817493\n",
            "step 823 - loss 4.065805912017822 - moving ave loss 3.9421528425253567\n",
            "step 824 - loss 5.1457200050354 - moving ave loss 4.062509558776361\n",
            "step 825 - loss 4.291710376739502 - moving ave loss 4.085429640572674\n",
            "step 826 - loss 3.633986234664917 - moving ave loss 4.040285299981899\n",
            "step 827 - loss 3.888050079345703 - moving ave loss 4.025061777918279\n",
            "step 828 - loss 3.5328211784362793 - moving ave loss 3.9758377179700792\n",
            "step 829 - loss 3.5080342292785645 - moving ave loss 3.929057369100928\n",
            "step 830 - loss 3.6537771224975586 - moving ave loss 3.9015293444405907\n",
            "step 831 - loss 3.5356831550598145 - moving ave loss 3.864944725502513\n",
            "step 832 - loss 3.7238564491271973 - moving ave loss 3.8508358978649815\n",
            "step 833 - loss 3.4894914627075195 - moving ave loss 3.8147014543492355\n",
            "step 834 - loss 3.957200050354004 - moving ave loss 3.8289513139497124\n",
            "step 835 - loss 3.938293695449829 - moving ave loss 3.839885552099724\n",
            "step 836 - loss 3.842440605163574 - moving ave loss 3.8401410574061092\n",
            "step 837 - loss 3.6012463569641113 - moving ave loss 3.8162515873619096\n",
            "step 838 - loss 3.58017635345459 - moving ave loss 3.792644063971178\n",
            "step 839 - loss 3.599891185760498 - moving ave loss 3.77336877615011\n",
            "step 840 - loss 3.817349910736084 - moving ave loss 3.7777668896087073\n",
            "step 841 - loss 4.495129585266113 - moving ave loss 3.849503159174448\n",
            "step 842 - loss 3.9125561714172363 - moving ave loss 3.8558084603987273\n",
            "step 843 - loss 3.5853044986724854 - moving ave loss 3.828758064226103\n",
            "step 844 - loss 4.052059650421143 - moving ave loss 3.851088222845607\n",
            "step 845 - loss 3.5535926818847656 - moving ave loss 3.821338668749523\n",
            "step 846 - loss 3.938206434249878 - moving ave loss 3.8330254452995587\n",
            "step 847 - loss 3.734628915786743 - moving ave loss 3.8231857923482773\n",
            "step 848 - loss 4.140344619750977 - moving ave loss 3.854901675088547\n",
            "step 849 - loss 3.7535574436187744 - moving ave loss 3.84476725194157\n",
            "step 850 - loss 4.094272613525391 - moving ave loss 3.869717788099952\n",
            "step 851 - loss 3.899298667907715 - moving ave loss 3.8726758760807285\n",
            "step 852 - loss 3.85599946975708 - moving ave loss 3.8710082354483637\n",
            "step 853 - loss 4.1545090675354 - moving ave loss 3.8993583186570677\n",
            "step 854 - loss 3.265187978744507 - moving ave loss 3.8359412846658114\n",
            "step 855 - loss 3.5952131748199463 - moving ave loss 3.8118684736812254\n",
            "step 856 - loss 3.7422866821289062 - moving ave loss 3.804910294525994\n",
            "step 857 - loss 3.4914751052856445 - moving ave loss 3.7735667756019593\n",
            "step 858 - loss 3.7629573345184326 - moving ave loss 3.772505831493607\n",
            "step 859 - loss 3.8356709480285645 - moving ave loss 3.778822343147103\n",
            "step 860 - loss 3.397860527038574 - moving ave loss 3.74072616153625\n",
            "step 861 - loss 3.609046697616577 - moving ave loss 3.727558215144283\n",
            "step 862 - loss 3.372012138366699 - moving ave loss 3.692003607466525\n",
            "step 863 - loss 3.404391288757324 - moving ave loss 3.6632423755956047\n",
            "step 864 - loss 3.884394645690918 - moving ave loss 3.6853576026051362\n",
            "step 865 - loss 3.410186290740967 - moving ave loss 3.6578404714187194\n",
            "step 866 - loss 3.53438663482666 - moving ave loss 3.645495087759514\n",
            "step 867 - loss 3.346646547317505 - moving ave loss 3.615610233715313\n",
            "step 868 - loss 4.355258941650391 - moving ave loss 3.6895751045088208\n",
            "step 869 - loss 3.5536792278289795 - moving ave loss 3.6759855168408366\n",
            "step 870 - loss 3.667323589324951 - moving ave loss 3.6751193240892484\n",
            "step 871 - loss 3.476670980453491 - moving ave loss 3.655274489725673\n",
            "step 872 - loss 4.381319046020508 - moving ave loss 3.7278789453551564\n",
            "step 873 - loss 3.60215425491333 - moving ave loss 3.7153064763109738\n",
            "step 874 - loss 3.94954776763916 - moving ave loss 3.7387306054437928\n",
            "step 875 - loss 4.310312747955322 - moving ave loss 3.7958888196949454\n",
            "step 876 - loss 4.274102210998535 - moving ave loss 3.8437101588253046\n",
            "step 877 - loss 3.462270736694336 - moving ave loss 3.805566216612208\n",
            "step 878 - loss 3.574012279510498 - moving ave loss 3.7824108229020372\n",
            "step 879 - loss 3.812258243560791 - moving ave loss 3.7853955649679127\n",
            "step 880 - loss 3.4863362312316895 - moving ave loss 3.7554896315942905\n",
            "step 881 - loss 3.2770681381225586 - moving ave loss 3.7076474822471175\n",
            "step 882 - loss 3.700321912765503 - moving ave loss 3.706914925298956\n",
            "step 883 - loss 3.6654815673828125 - moving ave loss 3.702771589507342\n",
            "step 884 - loss 3.5743072032928467 - moving ave loss 3.6899251508858923\n",
            "step 885 - loss 3.3258605003356934 - moving ave loss 3.6535186858308726\n",
            "step 886 - loss 3.346642255783081 - moving ave loss 3.6228310428260935\n",
            "step 887 - loss 3.246588706970215 - moving ave loss 3.5852068092405056\n",
            "step 888 - loss 3.349663734436035 - moving ave loss 3.561652501760059\n",
            "step 889 - loss 3.8423080444335938 - moving ave loss 3.5897180560274125\n",
            "step 890 - loss 3.673675537109375 - moving ave loss 3.5981138041356084\n",
            "step 891 - loss 3.63480806350708 - moving ave loss 3.6017832300727557\n",
            "step 892 - loss 3.4111733436584473 - moving ave loss 3.582722241431325\n",
            "step 893 - loss 3.5944900512695312 - moving ave loss 3.583899022415146\n",
            "step 894 - loss 3.323606491088867 - moving ave loss 3.557869769282518\n",
            "step 895 - loss 3.5306973457336426 - moving ave loss 3.5551525269276305\n",
            "step 896 - loss 3.335914134979248 - moving ave loss 3.5332286877327923\n",
            "step 897 - loss 3.334803581237793 - moving ave loss 3.5133861770832926\n",
            "step 898 - loss 3.2497825622558594 - moving ave loss 3.4870258156005494\n",
            "step 899 - loss 3.577721118927002 - moving ave loss 3.4960953459331945\n",
            "step 900 - loss 3.2674927711486816 - moving ave loss 3.4732350884547434\n",
            "Finish 9 epoch(es)\n",
            "step 901 - loss 3.3375282287597656 - moving ave loss 3.4596644024852456\n",
            "step 902 - loss 3.2093281745910645 - moving ave loss 3.4346307796958278\n",
            "step 903 - loss 3.8875370025634766 - moving ave loss 3.479921401982593\n",
            "step 904 - loss 3.4082398414611816 - moving ave loss 3.472753245930452\n",
            "step 905 - loss 3.482652187347412 - moving ave loss 3.4737431400721483\n",
            "step 906 - loss 3.3838863372802734 - moving ave loss 3.464757459792961\n",
            "step 907 - loss 3.901092052459717 - moving ave loss 3.5083909190596367\n",
            "step 908 - loss 3.3758530616760254 - moving ave loss 3.495137133321276\n",
            "step 909 - loss 3.304436683654785 - moving ave loss 3.476067088354627\n",
            "step 910 - loss 3.614628314971924 - moving ave loss 3.489923211016357\n",
            "step 911 - loss 3.1519134044647217 - moving ave loss 3.456122230361194\n",
            "step 912 - loss 3.7727980613708496 - moving ave loss 3.487789813462159\n",
            "step 913 - loss 3.1995339393615723 - moving ave loss 3.458964226052101\n",
            "step 914 - loss 3.1834876537323 - moving ave loss 3.431416568820121\n",
            "step 915 - loss 3.051647663116455 - moving ave loss 3.3934396782497545\n",
            "step 916 - loss 3.2133803367614746 - moving ave loss 3.375433744100927\n",
            "step 917 - loss 3.13360595703125 - moving ave loss 3.3512509653939593\n",
            "step 918 - loss 3.2924866676330566 - moving ave loss 3.3453745356178692\n",
            "step 919 - loss 3.26737117767334 - moving ave loss 3.3375741998234165\n",
            "step 920 - loss 3.1612887382507324 - moving ave loss 3.319945653666148\n",
            "step 921 - loss 3.3521132469177246 - moving ave loss 3.323162412991306\n",
            "step 922 - loss 3.0719614028930664 - moving ave loss 3.298042311981482\n",
            "step 923 - loss 3.1785926818847656 - moving ave loss 3.286097348971811\n",
            "step 924 - loss 3.5990424156188965 - moving ave loss 3.3173918556365196\n",
            "step 925 - loss 3.356508493423462 - moving ave loss 3.3213035194152143\n",
            "step 926 - loss 3.511829137802124 - moving ave loss 3.3403560812539053\n",
            "step 927 - loss 3.148151397705078 - moving ave loss 3.3211356128990226\n",
            "step 928 - loss 3.9198718070983887 - moving ave loss 3.3810092323189593\n",
            "step 929 - loss 2.948798894882202 - moving ave loss 3.337788198575284\n",
            "step 930 - loss 3.142503499984741 - moving ave loss 3.31825972871623\n",
            "step 931 - loss 3.3928298950195312 - moving ave loss 3.32571674534656\n",
            "step 932 - loss 3.4609148502349854 - moving ave loss 3.3392365558354027\n",
            "step 933 - loss 3.396364688873291 - moving ave loss 3.3449493691391914\n",
            "step 934 - loss 3.0191550254821777 - moving ave loss 3.31236993477349\n",
            "step 935 - loss 3.299772262573242 - moving ave loss 3.3111101675534655\n",
            "step 936 - loss 3.1986403465270996 - moving ave loss 3.299863185450829\n",
            "step 937 - loss 3.5135037899017334 - moving ave loss 3.32122724589592\n",
            "step 938 - loss 3.0996434688568115 - moving ave loss 3.299068868192009\n",
            "step 939 - loss 3.109835386276245 - moving ave loss 3.2801455200004326\n",
            "step 940 - loss 3.0167651176452637 - moving ave loss 3.253807479764916\n",
            "step 941 - loss 3.40580153465271 - moving ave loss 3.2690068852536953\n",
            "step 942 - loss 2.96686053276062 - moving ave loss 3.238792250004388\n",
            "step 943 - loss 3.718865394592285 - moving ave loss 3.286799564463178\n",
            "step 944 - loss 2.967207670211792 - moving ave loss 3.254840375038039\n",
            "step 945 - loss 3.433412551879883 - moving ave loss 3.2726975927222233\n",
            "step 946 - loss 3.133836030960083 - moving ave loss 3.2588114365460092\n",
            "step 947 - loss 3.231381893157959 - moving ave loss 3.2560684822072044\n",
            "step 948 - loss 3.29379940032959 - moving ave loss 3.259841574019443\n",
            "step 949 - loss 3.3265883922576904 - moving ave loss 3.2665162558432677\n",
            "step 950 - loss 2.925577402114868 - moving ave loss 3.232422370470428\n",
            "step 951 - loss 2.9280848503112793 - moving ave loss 3.201988618454513\n",
            "step 952 - loss 2.8836288452148438 - moving ave loss 3.170152641130546\n",
            "step 953 - loss 3.059307098388672 - moving ave loss 3.1590680868563585\n",
            "step 954 - loss 3.0492939949035645 - moving ave loss 3.148090677661079\n",
            "step 955 - loss 3.5895309448242188 - moving ave loss 3.1922347043773933\n",
            "step 956 - loss 3.429715156555176 - moving ave loss 3.2159827495951716\n",
            "step 957 - loss 2.9844284057617188 - moving ave loss 3.1928273152118263\n",
            "step 958 - loss 2.907750129699707 - moving ave loss 3.1643195966606146\n",
            "step 959 - loss 3.429337501525879 - moving ave loss 3.190821387147141\n",
            "step 960 - loss 3.1828699111938477 - moving ave loss 3.1900262395518117\n",
            "step 961 - loss 3.293992757797241 - moving ave loss 3.2004228913763546\n",
            "step 962 - loss 3.0707952976226807 - moving ave loss 3.187460132000987\n",
            "step 963 - loss 2.9296071529388428 - moving ave loss 3.161674834094773\n",
            "step 964 - loss 2.770294189453125 - moving ave loss 3.122536769630608\n",
            "step 965 - loss 3.6293907165527344 - moving ave loss 3.1732221643228207\n",
            "step 966 - loss 2.884629011154175 - moving ave loss 3.144362849005956\n",
            "step 967 - loss 2.8581275939941406 - moving ave loss 3.115739323504774\n",
            "step 968 - loss 3.1189727783203125 - moving ave loss 3.116062668986328\n",
            "step 969 - loss 3.028599262237549 - moving ave loss 3.10731632831145\n",
            "step 970 - loss 3.3886685371398926 - moving ave loss 3.1354515491942943\n",
            "step 971 - loss 2.9581329822540283 - moving ave loss 3.117719692500268\n",
            "step 972 - loss 3.190359115600586 - moving ave loss 3.1249836348102997\n",
            "step 973 - loss 3.125981330871582 - moving ave loss 3.125083404416428\n",
            "step 974 - loss 3.0510096549987793 - moving ave loss 3.117676029474663\n",
            "step 975 - loss 3.285639762878418 - moving ave loss 3.134472402815039\n",
            "step 976 - loss 3.025918483734131 - moving ave loss 3.1236170109069485\n",
            "step 977 - loss 3.2815818786621094 - moving ave loss 3.1394134976824644\n",
            "step 978 - loss 3.0572822093963623 - moving ave loss 3.1312003688538543\n",
            "step 979 - loss 2.7727489471435547 - moving ave loss 3.095355226682824\n",
            "step 980 - loss 3.2982730865478516 - moving ave loss 3.115647012669327\n",
            "step 981 - loss 3.575132131576538 - moving ave loss 3.161595524560048\n",
            "step 982 - loss 3.5118303298950195 - moving ave loss 3.1966190050935452\n",
            "step 983 - loss 2.780543565750122 - moving ave loss 3.155011461159203\n",
            "step 984 - loss 3.112924575805664 - moving ave loss 3.150802772623849\n",
            "step 985 - loss 2.7511940002441406 - moving ave loss 3.1108418953858785\n",
            "step 986 - loss 3.002101421356201 - moving ave loss 3.099967847982911\n",
            "step 987 - loss 2.9688639640808105 - moving ave loss 3.086857459592701\n",
            "step 988 - loss 3.4683849811553955 - moving ave loss 3.1250102117489704\n",
            "step 989 - loss 3.265164852142334 - moving ave loss 3.139025675788307\n",
            "step 990 - loss 3.5069379806518555 - moving ave loss 3.1758169062746617\n",
            "step 991 - loss 2.790046215057373 - moving ave loss 3.137239837152933\n",
            "step 992 - loss 2.6735098361968994 - moving ave loss 3.09086683705733\n",
            "step 993 - loss 2.8351972103118896 - moving ave loss 3.0652998743827857\n",
            "step 994 - loss 3.0750675201416016 - moving ave loss 3.0662766389586675\n",
            "step 995 - loss 3.224883556365967 - moving ave loss 3.082137330699398\n",
            "step 996 - loss 2.9917972087860107 - moving ave loss 3.073103318508059\n",
            "step 997 - loss 2.8860764503479004 - moving ave loss 3.0544006316920433\n",
            "step 998 - loss 3.111168384552002 - moving ave loss 3.060077406978039\n",
            "step 999 - loss 3.1271424293518066 - moving ave loss 3.066783909215416\n",
            "step 1000 - loss 3.033417224884033 - moving ave loss 3.0634472407822777\n",
            "Checkpoint at step 1000\n",
            "Finish 10 epoch(es)\n",
            "step 1001 - loss 2.7417304515838623 - moving ave loss 3.031275561862436\n",
            "step 1002 - loss 2.9001541137695312 - moving ave loss 3.0181634170531457\n",
            "step 1003 - loss 3.189303398132324 - moving ave loss 3.035277415161064\n",
            "step 1004 - loss 3.4584150314331055 - moving ave loss 3.0775911767882684\n",
            "step 1005 - loss 2.9072325229644775 - moving ave loss 3.0605553114058894\n",
            "step 1006 - loss 2.8632395267486572 - moving ave loss 3.040823732940166\n",
            "step 1007 - loss 2.9513983726501465 - moving ave loss 3.031881196911164\n",
            "step 1008 - loss 3.1057937145233154 - moving ave loss 3.0392724486723797\n",
            "step 1009 - loss 2.9082155227661133 - moving ave loss 3.026166756081753\n",
            "step 1010 - loss 3.0718111991882324 - moving ave loss 3.030731200392401\n",
            "step 1011 - loss 2.848341464996338 - moving ave loss 3.0124922268527947\n",
            "step 1012 - loss 2.5731446743011475 - moving ave loss 2.96855747159763\n",
            "step 1013 - loss 2.652778148651123 - moving ave loss 2.9369795393029796\n",
            "step 1014 - loss 2.8463592529296875 - moving ave loss 2.9279175106656505\n",
            "step 1015 - loss 3.0310139656066895 - moving ave loss 2.9382271561597544\n",
            "step 1016 - loss 3.158534526824951 - moving ave loss 2.960257893226274\n",
            "step 1017 - loss 2.9525623321533203 - moving ave loss 2.959488337118979\n",
            "step 1018 - loss 2.843844413757324 - moving ave loss 2.9479239447828136\n",
            "step 1019 - loss 2.579130172729492 - moving ave loss 2.9110445675774814\n",
            "step 1020 - loss 2.7243072986602783 - moving ave loss 2.8923708406857616\n",
            "step 1021 - loss 2.9666996002197266 - moving ave loss 2.899803716639158\n",
            "step 1022 - loss 2.648070812225342 - moving ave loss 2.874630426197777\n",
            "step 1023 - loss 2.736694097518921 - moving ave loss 2.860836793329891\n",
            "step 1024 - loss 2.6782846450805664 - moving ave loss 2.8425815785049586\n",
            "step 1025 - loss 2.7664918899536133 - moving ave loss 2.8349726096498244\n",
            "step 1026 - loss 2.9585952758789062 - moving ave loss 2.847334876272733\n",
            "step 1027 - loss 2.8589837551116943 - moving ave loss 2.848499764156629\n",
            "step 1028 - loss 2.6994943618774414 - moving ave loss 2.83359922392871\n",
            "step 1029 - loss 3.074735641479492 - moving ave loss 2.8577128656837885\n",
            "step 1030 - loss 3.1151270866394043 - moving ave loss 2.88345428777935\n",
            "step 1031 - loss 2.8462815284729004 - moving ave loss 2.879737011848705\n",
            "step 1032 - loss 2.7339439392089844 - moving ave loss 2.8651577045847327\n",
            "step 1033 - loss 2.5652031898498535 - moving ave loss 2.835162253111245\n",
            "step 1034 - loss 2.837578058242798 - moving ave loss 2.8354038336244\n",
            "step 1035 - loss 2.8676631450653076 - moving ave loss 2.838629764768491\n",
            "step 1036 - loss 2.9033470153808594 - moving ave loss 2.8451014898297275\n",
            "step 1037 - loss 3.1381850242614746 - moving ave loss 2.874409843272902\n",
            "step 1038 - loss 2.571949005126953 - moving ave loss 2.8441637594583074\n",
            "step 1039 - loss 2.568361759185791 - moving ave loss 2.8165835594310558\n",
            "step 1040 - loss 2.620105266571045 - moving ave loss 2.796935730145055\n",
            "step 1041 - loss 3.070075511932373 - moving ave loss 2.8242497083237867\n",
            "step 1042 - loss 2.8248050212860107 - moving ave loss 2.824305239620009\n",
            "step 1043 - loss 2.693674087524414 - moving ave loss 2.81124212441045\n",
            "step 1044 - loss 3.1743621826171875 - moving ave loss 2.847554130231124\n",
            "step 1045 - loss 2.8186662197113037 - moving ave loss 2.844665339179142\n",
            "step 1046 - loss 2.5780553817749023 - moving ave loss 2.8180043434387185\n",
            "step 1047 - loss 3.0037729740142822 - moving ave loss 2.836581206496275\n",
            "step 1048 - loss 2.5853681564331055 - moving ave loss 2.811459901489958\n",
            "step 1049 - loss 3.124286651611328 - moving ave loss 2.8427425765020953\n",
            "step 1050 - loss 2.6837778091430664 - moving ave loss 2.8268460997661924\n",
            "step 1051 - loss 2.91560435295105 - moving ave loss 2.835721925084678\n",
            "step 1052 - loss 2.4983999729156494 - moving ave loss 2.8019897298677754\n",
            "step 1053 - loss 2.7132067680358887 - moving ave loss 2.793111433684587\n",
            "step 1054 - loss 2.4972307682037354 - moving ave loss 2.763523367136502\n",
            "step 1055 - loss 2.5808191299438477 - moving ave loss 2.7452529434172366\n",
            "step 1056 - loss 2.733369827270508 - moving ave loss 2.744064631802564\n",
            "step 1057 - loss 3.239145517349243 - moving ave loss 2.793572720357232\n",
            "step 1058 - loss 2.624445915222168 - moving ave loss 2.776660039843726\n",
            "step 1059 - loss 2.800565242767334 - moving ave loss 2.7790505601360866\n",
            "step 1060 - loss 3.0830485820770264 - moving ave loss 2.809450362330181\n",
            "step 1061 - loss 2.5936760902404785 - moving ave loss 2.787872935121211\n",
            "step 1062 - loss 2.7736501693725586 - moving ave loss 2.7864506585463453\n",
            "step 1063 - loss 2.8010339736938477 - moving ave loss 2.7879089900610956\n",
            "step 1064 - loss 3.0804033279418945 - moving ave loss 2.817158423849176\n",
            "step 1065 - loss 2.44789981842041 - moving ave loss 2.780232563306299\n",
            "step 1066 - loss 2.6362714767456055 - moving ave loss 2.76583645465023\n",
            "step 1067 - loss 2.662458896636963 - moving ave loss 2.7554986988489034\n",
            "step 1068 - loss 2.5900635719299316 - moving ave loss 2.7389551861570065\n",
            "step 1069 - loss 2.8012733459472656 - moving ave loss 2.7451870021360323\n",
            "step 1070 - loss 2.518899917602539 - moving ave loss 2.722558293682683\n",
            "step 1071 - loss 2.8607068061828613 - moving ave loss 2.736373144932701\n",
            "step 1072 - loss 2.7316431999206543 - moving ave loss 2.735900150431496\n",
            "step 1073 - loss 3.030333995819092 - moving ave loss 2.765343534970256\n",
            "step 1074 - loss 2.5400781631469727 - moving ave loss 2.7428169977879278\n",
            "step 1075 - loss 2.5775797367095947 - moving ave loss 2.7262932716800945\n",
            "step 1076 - loss 2.396371603012085 - moving ave loss 2.6933011048132935\n",
            "step 1077 - loss 2.637233257293701 - moving ave loss 2.6876943200613344\n",
            "step 1078 - loss 2.8281760215759277 - moving ave loss 2.701742490212794\n",
            "step 1079 - loss 2.3934872150421143 - moving ave loss 2.670916962695726\n",
            "step 1080 - loss 2.3989996910095215 - moving ave loss 2.6437252355271057\n",
            "step 1081 - loss 2.5636518001556396 - moving ave loss 2.6357178919899593\n",
            "step 1082 - loss 2.429901123046875 - moving ave loss 2.615136215095651\n",
            "step 1083 - loss 2.583890676498413 - moving ave loss 2.6120116612359277\n",
            "step 1084 - loss 2.791738271713257 - moving ave loss 2.6299843222836605\n",
            "step 1085 - loss 2.495809555053711 - moving ave loss 2.6165668455606657\n",
            "step 1086 - loss 2.8127191066741943 - moving ave loss 2.636182071672019\n",
            "step 1087 - loss 2.6838269233703613 - moving ave loss 2.640946556841853\n",
            "step 1088 - loss 2.4430530071258545 - moving ave loss 2.621157201870253\n",
            "step 1089 - loss 2.386368751525879 - moving ave loss 2.5976783568358157\n",
            "step 1090 - loss 2.678140640258789 - moving ave loss 2.605724585178113\n",
            "step 1091 - loss 2.4937987327575684 - moving ave loss 2.5945319999360588\n",
            "step 1092 - loss 2.770198345184326 - moving ave loss 2.6120986344608856\n",
            "step 1093 - loss 2.322484016418457 - moving ave loss 2.583137172656643\n",
            "step 1094 - loss 2.52408504486084 - moving ave loss 2.5772319598770626\n",
            "step 1095 - loss 2.7330565452575684 - moving ave loss 2.5928144184151134\n",
            "step 1096 - loss 2.590634346008301 - moving ave loss 2.592596411174432\n",
            "step 1097 - loss 2.4724550247192383 - moving ave loss 2.580582272528913\n",
            "step 1098 - loss 2.5772435665130615 - moving ave loss 2.580248401927328\n",
            "step 1099 - loss 2.504304885864258 - moving ave loss 2.572654050321021\n",
            "step 1100 - loss 2.520491361618042 - moving ave loss 2.567437781450723\n",
            "Finish 11 epoch(es)\n",
            "step 1101 - loss 2.8530173301696777 - moving ave loss 2.5959957363226187\n",
            "step 1102 - loss 2.439220666885376 - moving ave loss 2.5803182293788947\n",
            "step 1103 - loss 2.5312018394470215 - moving ave loss 2.5754065903857075\n",
            "step 1104 - loss 2.333379030227661 - moving ave loss 2.551203834369903\n",
            "step 1105 - loss 2.5942420959472656 - moving ave loss 2.5555076605276392\n",
            "step 1106 - loss 2.4785842895507812 - moving ave loss 2.5478153234299534\n",
            "step 1107 - loss 2.6384172439575195 - moving ave loss 2.55687551548271\n",
            "step 1108 - loss 2.5876147747039795 - moving ave loss 2.559949441404837\n",
            "step 1109 - loss 2.438659191131592 - moving ave loss 2.5478204163775127\n",
            "step 1110 - loss 2.4946937561035156 - moving ave loss 2.5425077503501132\n",
            "step 1111 - loss 2.242666006088257 - moving ave loss 2.512523575923928\n",
            "step 1112 - loss 2.343803882598877 - moving ave loss 2.495651606591423\n",
            "step 1113 - loss 2.7116193771362305 - moving ave loss 2.517248383645904\n",
            "step 1114 - loss 2.6207079887390137 - moving ave loss 2.5275943441552147\n",
            "step 1115 - loss 2.4469432830810547 - moving ave loss 2.5195292380477987\n",
            "step 1116 - loss 2.3924007415771484 - moving ave loss 2.5068163884007335\n",
            "step 1117 - loss 2.365976095199585 - moving ave loss 2.4927323590806187\n",
            "step 1118 - loss 2.471482038497925 - moving ave loss 2.4906073270223494\n",
            "step 1119 - loss 2.6679561138153076 - moving ave loss 2.5083422057016453\n",
            "step 1120 - loss 2.757148265838623 - moving ave loss 2.5332228117153432\n",
            "step 1121 - loss 2.3404335975646973 - moving ave loss 2.5139438903002786\n",
            "step 1122 - loss 2.6102294921875 - moving ave loss 2.523572450489001\n",
            "step 1123 - loss 2.2845301628112793 - moving ave loss 2.4996682217212287\n",
            "step 1124 - loss 2.5671613216400146 - moving ave loss 2.506417531713107\n",
            "step 1125 - loss 2.2087554931640625 - moving ave loss 2.4766513278582027\n",
            "step 1126 - loss 2.2848947048187256 - moving ave loss 2.4574756655542553\n",
            "step 1127 - loss 2.514596939086914 - moving ave loss 2.4631877929075214\n",
            "step 1128 - loss 2.414797067642212 - moving ave loss 2.458348720380991\n",
            "step 1129 - loss 2.3668904304504395 - moving ave loss 2.449202891387936\n",
            "step 1130 - loss 2.2362051010131836 - moving ave loss 2.427903112350461\n",
            "step 1131 - loss 2.529672622680664 - moving ave loss 2.4380800633834814\n",
            "step 1132 - loss 2.566314220428467 - moving ave loss 2.45090347908798\n",
            "step 1133 - loss 2.3341174125671387 - moving ave loss 2.439224872435896\n",
            "step 1134 - loss 2.725137710571289 - moving ave loss 2.467816156249435\n",
            "step 1135 - loss 2.662797451019287 - moving ave loss 2.4873142857264203\n",
            "step 1136 - loss 2.4024391174316406 - moving ave loss 2.4788267688969423\n",
            "step 1137 - loss 2.597890853881836 - moving ave loss 2.4907331773954318\n",
            "step 1138 - loss 2.247767448425293 - moving ave loss 2.466436604498418\n",
            "step 1139 - loss 2.1769800186157227 - moving ave loss 2.4374909459101484\n",
            "step 1140 - loss 2.5928051471710205 - moving ave loss 2.453022366036236\n",
            "step 1141 - loss 2.434603691101074 - moving ave loss 2.45118049854272\n",
            "step 1142 - loss 2.301379680633545 - moving ave loss 2.4362004167518023\n",
            "step 1143 - loss 2.309813976287842 - moving ave loss 2.423561772705406\n",
            "step 1144 - loss 2.15846848487854 - moving ave loss 2.39705244392272\n",
            "step 1145 - loss 2.8540735244750977 - moving ave loss 2.4427545519779574\n",
            "step 1146 - loss 2.2661685943603516 - moving ave loss 2.425095956216197\n",
            "step 1147 - loss 2.3461878299713135 - moving ave loss 2.417205143591709\n",
            "step 1148 - loss 2.2724266052246094 - moving ave loss 2.402727289754999\n",
            "step 1149 - loss 2.6534171104431152 - moving ave loss 2.427796271823811\n",
            "step 1150 - loss 2.4096646308898926 - moving ave loss 2.425983107730419\n",
            "step 1151 - loss 2.7827157974243164 - moving ave loss 2.4616563766998087\n",
            "step 1152 - loss 2.2639007568359375 - moving ave loss 2.441880814713422\n",
            "step 1153 - loss 2.262051582336426 - moving ave loss 2.4238978914757223\n",
            "step 1154 - loss 2.4667980670928955 - moving ave loss 2.4281879090374394\n",
            "step 1155 - loss 2.592313766479492 - moving ave loss 2.4446004947816444\n",
            "step 1156 - loss 2.5782575607299805 - moving ave loss 2.457966201376478\n",
            "step 1157 - loss 2.244072675704956 - moving ave loss 2.436576848809326\n",
            "step 1158 - loss 2.363236665725708 - moving ave loss 2.4292428305009643\n",
            "step 1159 - loss 2.334864377975464 - moving ave loss 2.4198049852484145\n",
            "step 1160 - loss 2.114893913269043 - moving ave loss 2.3893138780504777\n",
            "step 1161 - loss 2.0440125465393066 - moving ave loss 2.3547837448993607\n",
            "step 1162 - loss 2.11690354347229 - moving ave loss 2.3309957247566535\n",
            "step 1163 - loss 2.2846181392669678 - moving ave loss 2.326357966207685\n",
            "step 1164 - loss 2.6782548427581787 - moving ave loss 2.3615476538627345\n",
            "step 1165 - loss 2.9860572814941406 - moving ave loss 2.423998616625875\n",
            "step 1166 - loss 2.400078296661377 - moving ave loss 2.4216065846294255\n",
            "step 1167 - loss 2.3944544792175293 - moving ave loss 2.418891374088236\n",
            "step 1168 - loss 2.555302619934082 - moving ave loss 2.4325324986728205\n",
            "step 1169 - loss 2.1122820377349854 - moving ave loss 2.400507452579037\n",
            "step 1170 - loss 2.5823118686676025 - moving ave loss 2.4186878941878938\n",
            "step 1171 - loss 2.1397619247436523 - moving ave loss 2.3907952972434696\n",
            "step 1172 - loss 2.1618947982788086 - moving ave loss 2.3679052473470037\n",
            "step 1173 - loss 2.569164752960205 - moving ave loss 2.388031197908324\n",
            "step 1174 - loss 2.339893341064453 - moving ave loss 2.3832174122239373\n",
            "step 1175 - loss 2.3165292739868164 - moving ave loss 2.3765485984002255\n",
            "step 1176 - loss 2.301513195037842 - moving ave loss 2.3690450580639872\n",
            "step 1177 - loss 2.3470380306243896 - moving ave loss 2.3668443553200276\n",
            "step 1178 - loss 2.7434816360473633 - moving ave loss 2.404508083392761\n",
            "step 1179 - loss 2.064570426940918 - moving ave loss 2.3705143177475767\n",
            "step 1180 - loss 2.2575466632843018 - moving ave loss 2.3592175523012493\n",
            "step 1181 - loss 2.1150946617126465 - moving ave loss 2.334805263242389\n",
            "step 1182 - loss 2.9545416831970215 - moving ave loss 2.396778905237852\n",
            "step 1183 - loss 2.3049166202545166 - moving ave loss 2.3875926767395184\n",
            "step 1184 - loss 2.763991355895996 - moving ave loss 2.425232544655166\n",
            "step 1185 - loss 2.0771067142486572 - moving ave loss 2.390419961614515\n",
            "step 1186 - loss 2.636598587036133 - moving ave loss 2.415037824156677\n",
            "step 1187 - loss 2.253087282180786 - moving ave loss 2.398842769959088\n",
            "step 1188 - loss 2.176637887954712 - moving ave loss 2.3766222817586504\n",
            "step 1189 - loss 2.2367746829986572 - moving ave loss 2.362637521882651\n",
            "step 1190 - loss 2.1796927452087402 - moving ave loss 2.34434304421526\n",
            "step 1191 - loss 2.2610228061676025 - moving ave loss 2.3360110204104942\n",
            "step 1192 - loss 2.1928391456604004 - moving ave loss 2.321693832935485\n",
            "step 1193 - loss 2.0027620792388916 - moving ave loss 2.289800657565826\n",
            "step 1194 - loss 2.442889928817749 - moving ave loss 2.3051095846910186\n",
            "step 1195 - loss 2.585930347442627 - moving ave loss 2.33319166096618\n",
            "step 1196 - loss 2.0529303550720215 - moving ave loss 2.305165530376764\n",
            "step 1197 - loss 2.2889013290405273 - moving ave loss 2.3035391102431406\n",
            "step 1198 - loss 2.4294910430908203 - moving ave loss 2.316134303527909\n",
            "step 1199 - loss 2.2955827713012695 - moving ave loss 2.3140791503052447\n",
            "step 1200 - loss 2.899470567703247 - moving ave loss 2.3726182920450447\n",
            "Finish 12 epoch(es)\n",
            "step 1201 - loss 2.066361427307129 - moving ave loss 2.3419926055712534\n",
            "step 1202 - loss 2.275204658508301 - moving ave loss 2.335313810864958\n",
            "step 1203 - loss 2.1255526542663574 - moving ave loss 2.314337695205098\n",
            "step 1204 - loss 2.0471839904785156 - moving ave loss 2.28762232473244\n",
            "step 1205 - loss 2.3254494667053223 - moving ave loss 2.291405038929728\n",
            "step 1206 - loss 2.0221357345581055 - moving ave loss 2.2644781084925656\n",
            "step 1207 - loss 2.0791499614715576 - moving ave loss 2.2459452937904647\n",
            "step 1208 - loss 2.246736526489258 - moving ave loss 2.246024417060344\n",
            "step 1209 - loss 2.3515172004699707 - moving ave loss 2.2565736954013067\n",
            "step 1210 - loss 2.1768336296081543 - moving ave loss 2.2485996888219915\n",
            "step 1211 - loss 2.306087017059326 - moving ave loss 2.254348421645725\n",
            "step 1212 - loss 2.3027946949005127 - moving ave loss 2.2591930489712038\n",
            "step 1213 - loss 2.0092625617980957 - moving ave loss 2.2342000002538933\n",
            "step 1214 - loss 2.1257073879241943 - moving ave loss 2.2233507390209235\n",
            "step 1215 - loss 2.0312461853027344 - moving ave loss 2.204140283649105\n",
            "step 1216 - loss 2.0758793354034424 - moving ave loss 2.1913141888245384\n",
            "step 1217 - loss 2.287426233291626 - moving ave loss 2.2009253932712474\n",
            "step 1218 - loss 2.0333619117736816 - moving ave loss 2.184169045121491\n",
            "step 1219 - loss 2.3512887954711914 - moving ave loss 2.200881020156461\n",
            "step 1220 - loss 2.2252321243286133 - moving ave loss 2.2033161305736764\n",
            "step 1221 - loss 2.3421778678894043 - moving ave loss 2.2172023043052493\n",
            "step 1222 - loss 2.0283446311950684 - moving ave loss 2.1983165369942315\n",
            "step 1223 - loss 2.27842378616333 - moving ave loss 2.206327261911141\n",
            "step 1224 - loss 2.343684673309326 - moving ave loss 2.2200630030509596\n",
            "step 1225 - loss 2.3544938564300537 - moving ave loss 2.2335060883888693\n",
            "step 1226 - loss 1.9357030391693115 - moving ave loss 2.2037257834669135\n",
            "step 1227 - loss 2.194145441055298 - moving ave loss 2.2027677492257522\n",
            "step 1228 - loss 2.256291389465332 - moving ave loss 2.20812011324971\n",
            "step 1229 - loss 2.36208438873291 - moving ave loss 2.2235165407980304\n",
            "step 1230 - loss 1.9810070991516113 - moving ave loss 2.1992655966333885\n",
            "step 1231 - loss 2.2657034397125244 - moving ave loss 2.205909380941302\n",
            "step 1232 - loss 2.1937036514282227 - moving ave loss 2.204688807989994\n",
            "step 1233 - loss 1.9779038429260254 - moving ave loss 2.182010311483597\n",
            "step 1234 - loss 1.9510804414749146 - moving ave loss 2.158917324482729\n",
            "step 1235 - loss 2.4051926136016846 - moving ave loss 2.1835448533946247\n",
            "step 1236 - loss 2.5277390480041504 - moving ave loss 2.2179642728555775\n",
            "step 1237 - loss 1.9590201377868652 - moving ave loss 2.1920698593487065\n",
            "step 1238 - loss 2.336540460586548 - moving ave loss 2.2065169194724907\n",
            "step 1239 - loss 2.453132390975952 - moving ave loss 2.231178466622837\n",
            "step 1240 - loss 2.065821886062622 - moving ave loss 2.2146428085668157\n",
            "step 1241 - loss 2.066540479660034 - moving ave loss 2.1998325756761377\n",
            "step 1242 - loss 2.0278232097625732 - moving ave loss 2.1826316390847813\n",
            "step 1243 - loss 2.158226490020752 - moving ave loss 2.1801911241783785\n",
            "step 1244 - loss 2.0788140296936035 - moving ave loss 2.170053414729901\n",
            "step 1245 - loss 2.2282047271728516 - moving ave loss 2.175868545974196\n",
            "step 1246 - loss 2.1778042316436768 - moving ave loss 2.176062114541144\n",
            "step 1247 - loss 2.163052797317505 - moving ave loss 2.1747611828187803\n",
            "step 1248 - loss 2.1803908348083496 - moving ave loss 2.175324148017737\n",
            "step 1249 - loss 2.14406156539917 - moving ave loss 2.1721978897558802\n",
            "step 1250 - loss 2.2323403358459473 - moving ave loss 2.178212134364887\n",
            "Checkpoint at step 1250\n",
            "step 1251 - loss 2.103407859802246 - moving ave loss 2.1707317069086227\n",
            "step 1252 - loss 1.9851529598236084 - moving ave loss 2.1521738322001216\n",
            "step 1253 - loss 2.1814966201782227 - moving ave loss 2.1551061109979317\n",
            "step 1254 - loss 1.9748473167419434 - moving ave loss 2.137080231572333\n",
            "step 1255 - loss 2.1942219734191895 - moving ave loss 2.1427944057570185\n",
            "step 1256 - loss 2.086092472076416 - moving ave loss 2.1371242123889584\n",
            "step 1257 - loss 2.113736152648926 - moving ave loss 2.134785406414955\n",
            "step 1258 - loss 2.269803762435913 - moving ave loss 2.1482872420170507\n",
            "step 1259 - loss 2.1060733795166016 - moving ave loss 2.1440658557670056\n",
            "step 1260 - loss 2.4610507488250732 - moving ave loss 2.175764345072812\n",
            "step 1261 - loss 2.189547061920166 - moving ave loss 2.1771426167575476\n",
            "step 1262 - loss 2.6028714179992676 - moving ave loss 2.2197154968817197\n",
            "step 1263 - loss 2.561150074005127 - moving ave loss 2.2538589545940604\n",
            "step 1264 - loss 1.9465612173080444 - moving ave loss 2.2231291808654587\n",
            "step 1265 - loss 2.1010022163391113 - moving ave loss 2.2109164844128237\n",
            "step 1266 - loss 1.9816322326660156 - moving ave loss 2.187988059238143\n",
            "step 1267 - loss 2.5432376861572266 - moving ave loss 2.2235130219300516\n",
            "step 1268 - loss 2.099766254425049 - moving ave loss 2.2111383451795517\n",
            "step 1269 - loss 2.094362258911133 - moving ave loss 2.1994607365527097\n",
            "step 1270 - loss 2.3285417556762695 - moving ave loss 2.2123688384650655\n",
            "step 1271 - loss 1.9625381231307983 - moving ave loss 2.187385766931639\n",
            "step 1272 - loss 1.9317665100097656 - moving ave loss 2.161823841239452\n",
            "step 1273 - loss 2.040302038192749 - moving ave loss 2.1496716609347817\n",
            "step 1274 - loss 1.8297443389892578 - moving ave loss 2.1176789287402293\n",
            "step 1275 - loss 2.1958274841308594 - moving ave loss 2.1254937842792923\n",
            "step 1276 - loss 2.1482534408569336 - moving ave loss 2.1277697499370567\n",
            "step 1277 - loss 1.860943078994751 - moving ave loss 2.101087082842826\n",
            "step 1278 - loss 1.8060944080352783 - moving ave loss 2.0715878153620713\n",
            "step 1279 - loss 2.332392930984497 - moving ave loss 2.097668326924314\n",
            "step 1280 - loss 2.320249080657959 - moving ave loss 2.1199264022976783\n",
            "step 1281 - loss 2.1490588188171387 - moving ave loss 2.122839643949624\n",
            "step 1282 - loss 1.845847487449646 - moving ave loss 2.0951404282996267\n",
            "step 1283 - loss 1.9765725135803223 - moving ave loss 2.083283636827696\n",
            "step 1284 - loss 1.827608585357666 - moving ave loss 2.057716131680693\n",
            "step 1285 - loss 1.8208802938461304 - moving ave loss 2.0340325478972368\n",
            "step 1286 - loss 2.14511775970459 - moving ave loss 2.0451410690779723\n",
            "step 1287 - loss 1.9891839027404785 - moving ave loss 2.039545352444223\n",
            "step 1288 - loss 1.8998674154281616 - moving ave loss 2.025577558742617\n",
            "step 1289 - loss 1.87526535987854 - moving ave loss 2.010546338856209\n",
            "step 1290 - loss 1.77644681930542 - moving ave loss 1.98713638690113\n",
            "step 1291 - loss 2.3909215927124023 - moving ave loss 2.0275149074822574\n",
            "step 1292 - loss 2.131965160369873 - moving ave loss 2.037959932771019\n",
            "step 1293 - loss 1.9095566272735596 - moving ave loss 2.025119602221273\n",
            "step 1294 - loss 2.107431173324585 - moving ave loss 2.0333507593316043\n",
            "step 1295 - loss 2.208228349685669 - moving ave loss 2.050838518367011\n",
            "step 1296 - loss 2.004371404647827 - moving ave loss 2.0461918069950924\n",
            "step 1297 - loss 1.873615026473999 - moving ave loss 2.028934128942983\n",
            "step 1298 - loss 2.3890609741210938 - moving ave loss 2.0649468134607942\n",
            "step 1299 - loss 1.7947828769683838 - moving ave loss 2.0379304198115533\n",
            "step 1300 - loss 2.0918056964874268 - moving ave loss 2.0433179474791405\n",
            "Finish 13 epoch(es)\n",
            "step 1301 - loss 1.8172526359558105 - moving ave loss 2.0207114163268076\n",
            "step 1302 - loss 1.7189712524414062 - moving ave loss 1.9905373999382674\n",
            "step 1303 - loss 2.4681077003479004 - moving ave loss 2.0382944299792305\n",
            "step 1304 - loss 1.80666184425354 - moving ave loss 2.0151311714066615\n",
            "step 1305 - loss 1.80234694480896 - moving ave loss 1.9938527487468916\n",
            "step 1306 - loss 1.994478464126587 - moving ave loss 1.9939153202848612\n",
            "step 1307 - loss 1.9108779430389404 - moving ave loss 1.9856115825602692\n",
            "step 1308 - loss 1.8817641735076904 - moving ave loss 1.9752268416550112\n",
            "step 1309 - loss 1.8263189792633057 - moving ave loss 1.9603360554158407\n",
            "step 1310 - loss 1.7897725105285645 - moving ave loss 1.943279700927113\n",
            "step 1311 - loss 1.9316984415054321 - moving ave loss 1.942121574984945\n",
            "step 1312 - loss 1.9134836196899414 - moving ave loss 1.9392577794554446\n",
            "step 1313 - loss 2.6262879371643066 - moving ave loss 2.0079607952263308\n",
            "step 1314 - loss 2.0219826698303223 - moving ave loss 2.0093629826867296\n",
            "step 1315 - loss 1.8260473012924194 - moving ave loss 1.9910314145472987\n",
            "step 1316 - loss 2.068558931350708 - moving ave loss 1.9987841662276398\n",
            "step 1317 - loss 1.9720216989517212 - moving ave loss 1.996107919500048\n",
            "step 1318 - loss 1.8492612838745117 - moving ave loss 1.9814232559374945\n",
            "step 1319 - loss 1.859825611114502 - moving ave loss 1.9692634914551954\n",
            "step 1320 - loss 1.8544747829437256 - moving ave loss 1.9577846206040483\n",
            "step 1321 - loss 1.7307332754135132 - moving ave loss 1.935079486084995\n",
            "step 1322 - loss 2.091707706451416 - moving ave loss 1.950742308121637\n",
            "step 1323 - loss 1.879895567893982 - moving ave loss 1.9436576340988716\n",
            "step 1324 - loss 2.03839373588562 - moving ave loss 1.9531312442775464\n",
            "step 1325 - loss 2.020435333251953 - moving ave loss 1.959861653174987\n",
            "step 1326 - loss 1.957878828048706 - moving ave loss 1.9596633706623592\n",
            "step 1327 - loss 1.8700515031814575 - moving ave loss 1.950702183914269\n",
            "step 1328 - loss 1.9121782779693604 - moving ave loss 1.9468497933197784\n",
            "step 1329 - loss 1.7087829113006592 - moving ave loss 1.9230431051178665\n",
            "step 1330 - loss 1.9027034044265747 - moving ave loss 1.9210091350487375\n",
            "step 1331 - loss 1.830635666847229 - moving ave loss 1.9119717882285867\n",
            "step 1332 - loss 1.9193358421325684 - moving ave loss 1.912708193618985\n",
            "step 1333 - loss 2.229372978210449 - moving ave loss 1.9443746720781314\n",
            "step 1334 - loss 1.9052748680114746 - moving ave loss 1.9404646916714658\n",
            "step 1335 - loss 1.9671003818511963 - moving ave loss 1.943128260689439\n",
            "step 1336 - loss 2.0609002113342285 - moving ave loss 1.9549054557539178\n",
            "step 1337 - loss 2.108799934387207 - moving ave loss 1.9702949036172468\n",
            "step 1338 - loss 2.6620144844055176 - moving ave loss 2.039466861696074\n",
            "step 1339 - loss 1.9138978719711304 - moving ave loss 2.02690996272358\n",
            "step 1340 - loss 1.6661348342895508 - moving ave loss 1.9908324498801768\n",
            "step 1341 - loss 2.052349090576172 - moving ave loss 1.9969841139497766\n",
            "step 1342 - loss 1.8253761529922485 - moving ave loss 1.9798233178540239\n",
            "step 1343 - loss 2.1077494621276855 - moving ave loss 1.9926159322813901\n",
            "step 1344 - loss 2.0440762042999268 - moving ave loss 1.9977619594832439\n",
            "step 1345 - loss 2.122445583343506 - moving ave loss 2.01023032186927\n",
            "step 1346 - loss 1.7177364826202393 - moving ave loss 1.980980937944367\n",
            "step 1347 - loss 1.83268404006958 - moving ave loss 1.9661512481568884\n",
            "step 1348 - loss 2.098756790161133 - moving ave loss 1.9794118023573128\n",
            "step 1349 - loss 1.9479607343673706 - moving ave loss 1.9762666955583188\n",
            "step 1350 - loss 2.0098342895507812 - moving ave loss 1.979623454957565\n",
            "step 1351 - loss 2.312023639678955 - moving ave loss 2.012863473429704\n",
            "step 1352 - loss 1.6189725399017334 - moving ave loss 1.973474380076907\n",
            "step 1353 - loss 1.899921178817749 - moving ave loss 1.9661190599509912\n",
            "step 1354 - loss 1.8871018886566162 - moving ave loss 1.958217342821554\n",
            "step 1355 - loss 2.03261661529541 - moving ave loss 1.9656572700689396\n",
            "step 1356 - loss 1.8261656761169434 - moving ave loss 1.9517081106737402\n",
            "step 1357 - loss 2.057455539703369 - moving ave loss 1.9622828535767032\n",
            "step 1358 - loss 1.7616972923278809 - moving ave loss 1.9422242974518211\n",
            "step 1359 - loss 1.6252107620239258 - moving ave loss 1.9105229439090317\n",
            "step 1360 - loss 1.8855944871902466 - moving ave loss 1.9080300982371532\n",
            "step 1361 - loss 1.857448697090149 - moving ave loss 1.902971958122453\n",
            "step 1362 - loss 1.7117977142333984 - moving ave loss 1.8838545337335475\n",
            "step 1363 - loss 1.9059730768203735 - moving ave loss 1.8860663880422301\n",
            "step 1364 - loss 1.8092362880706787 - moving ave loss 1.8783833780450752\n",
            "step 1365 - loss 2.0093445777893066 - moving ave loss 1.8914794980194984\n",
            "step 1366 - loss 1.9432636499404907 - moving ave loss 1.8966579132115977\n",
            "step 1367 - loss 1.905564785003662 - moving ave loss 1.8975486003908042\n",
            "step 1368 - loss 1.8728306293487549 - moving ave loss 1.8950768032865994\n",
            "step 1369 - loss 1.978231430053711 - moving ave loss 1.9033922659633107\n",
            "step 1370 - loss 1.8634181022644043 - moving ave loss 1.89939484959342\n",
            "step 1371 - loss 1.7371379137039185 - moving ave loss 1.88316915600447\n",
            "step 1372 - loss 1.9031589031219482 - moving ave loss 1.885168130716218\n",
            "step 1373 - loss 1.8608503341674805 - moving ave loss 1.8827363510613444\n",
            "step 1374 - loss 1.600447416305542 - moving ave loss 1.854507457585764\n",
            "step 1375 - loss 1.668647289276123 - moving ave loss 1.8359214407548001\n",
            "step 1376 - loss 1.8885442018508911 - moving ave loss 1.8411837168644092\n",
            "step 1377 - loss 1.8466696739196777 - moving ave loss 1.841732312569936\n",
            "step 1378 - loss 1.6494592428207397 - moving ave loss 1.8225050055950165\n",
            "step 1379 - loss 2.4518179893493652 - moving ave loss 1.8854363039704514\n",
            "step 1380 - loss 2.257080078125 - moving ave loss 1.9226006813859062\n",
            "step 1381 - loss 1.973455786705017 - moving ave loss 1.9276861919178172\n",
            "step 1382 - loss 2.1478309631347656 - moving ave loss 1.9497006690395122\n",
            "step 1383 - loss 1.9759466648101807 - moving ave loss 1.9523252686165793\n",
            "step 1384 - loss 2.0835795402526855 - moving ave loss 1.96545069578019\n",
            "step 1385 - loss 1.707167387008667 - moving ave loss 1.939622364903038\n",
            "step 1386 - loss 2.754146099090576 - moving ave loss 2.0210747383217917\n",
            "step 1387 - loss 1.645010232925415 - moving ave loss 1.9834682877821541\n",
            "step 1388 - loss 2.00736665725708 - moving ave loss 1.985858124729647\n",
            "step 1389 - loss 1.6164860725402832 - moving ave loss 1.9489209195107107\n",
            "step 1390 - loss 2.8937363624572754 - moving ave loss 2.043402463805367\n",
            "step 1391 - loss 1.6017684936523438 - moving ave loss 1.9992390667900648\n",
            "step 1392 - loss 1.9276752471923828 - moving ave loss 1.9920826848302968\n",
            "step 1393 - loss 1.906813621520996 - moving ave loss 1.9835557784993667\n",
            "step 1394 - loss 1.490673542022705 - moving ave loss 1.9342675548517005\n",
            "step 1395 - loss 1.6413768529891968 - moving ave loss 1.9049784846654503\n",
            "step 1396 - loss 1.6217727661132812 - moving ave loss 1.8766579128102334\n",
            "step 1397 - loss 1.906394362449646 - moving ave loss 1.8796315577741747\n",
            "step 1398 - loss 1.723367691040039 - moving ave loss 1.864005171100761\n",
            "step 1399 - loss 1.8106563091278076 - moving ave loss 1.8586702849034658\n",
            "step 1400 - loss 1.8198233842849731 - moving ave loss 1.8547855948416165\n",
            "Finish 14 epoch(es)\n",
            "step 1401 - loss 1.7920279502868652 - moving ave loss 1.8485098303861414\n",
            "step 1402 - loss 1.7244760990142822 - moving ave loss 1.8361064572489556\n",
            "step 1403 - loss 1.6475586891174316 - moving ave loss 1.8172516804358032\n",
            "step 1404 - loss 1.7660375833511353 - moving ave loss 1.8121302707273363\n",
            "step 1405 - loss 2.3367295265197754 - moving ave loss 1.8645901963065803\n",
            "step 1406 - loss 1.6655335426330566 - moving ave loss 1.8446845309392281\n",
            "step 1407 - loss 1.5058199167251587 - moving ave loss 1.8107980695178214\n",
            "step 1408 - loss 1.793982744216919 - moving ave loss 1.8091165369877313\n",
            "step 1409 - loss 1.5690191984176636 - moving ave loss 1.7851068031307245\n",
            "step 1410 - loss 2.377537727355957 - moving ave loss 1.8443498955532478\n",
            "step 1411 - loss 1.630477786064148 - moving ave loss 1.8229626846043379\n",
            "step 1412 - loss 1.7544796466827393 - moving ave loss 1.816114380812178\n",
            "step 1413 - loss 1.5000368356704712 - moving ave loss 1.7845066262980074\n",
            "step 1414 - loss 1.7704439163208008 - moving ave loss 1.7831003553002867\n",
            "step 1415 - loss 1.9603753089904785 - moving ave loss 1.8008278506693058\n",
            "step 1416 - loss 1.9767405986785889 - moving ave loss 1.8184191254702342\n",
            "step 1417 - loss 1.8001437187194824 - moving ave loss 1.816591584795159\n",
            "step 1418 - loss 1.7510552406311035 - moving ave loss 1.8100379503787534\n",
            "step 1419 - loss 1.9694340229034424 - moving ave loss 1.8259775576312223\n",
            "step 1420 - loss 1.6952581405639648 - moving ave loss 1.8129056159244965\n",
            "step 1421 - loss 1.9957994222640991 - moving ave loss 1.8311949965584569\n",
            "step 1422 - loss 1.946810007095337 - moving ave loss 1.8427564976121449\n",
            "step 1423 - loss 1.7275547981262207 - moving ave loss 1.8312363276635526\n",
            "step 1424 - loss 1.6803860664367676 - moving ave loss 1.8161513015408741\n",
            "step 1425 - loss 2.058778762817383 - moving ave loss 1.8404140476685251\n",
            "step 1426 - loss 1.5471669435501099 - moving ave loss 1.8110893372566839\n",
            "step 1427 - loss 2.0591955184936523 - moving ave loss 1.8358999553803808\n",
            "step 1428 - loss 1.6703600883483887 - moving ave loss 1.8193459686771816\n",
            "step 1429 - loss 1.52366042137146 - moving ave loss 1.7897774139466094\n",
            "step 1430 - loss 1.7816603183746338 - moving ave loss 1.7889657043894118\n",
            "step 1431 - loss 1.694014310836792 - moving ave loss 1.77947056503415\n",
            "step 1432 - loss 1.6063928604125977 - moving ave loss 1.7621627945719949\n",
            "step 1433 - loss 2.323209762573242 - moving ave loss 1.8182674913721195\n",
            "step 1434 - loss 1.665978193283081 - moving ave loss 1.8030385615632158\n",
            "step 1435 - loss 1.82952880859375 - moving ave loss 1.8056875862662694\n",
            "step 1436 - loss 1.4943859577178955 - moving ave loss 1.774557423411432\n",
            "step 1437 - loss 1.5671473741531372 - moving ave loss 1.7538164184856027\n",
            "step 1438 - loss 1.6598536968231201 - moving ave loss 1.7444201463193543\n",
            "step 1439 - loss 1.5319900512695312 - moving ave loss 1.723177136814372\n",
            "step 1440 - loss 1.6395986080169678 - moving ave loss 1.7148192839346317\n",
            "step 1441 - loss 1.6710911989212036 - moving ave loss 1.7104464754332889\n",
            "step 1442 - loss 1.545342206954956 - moving ave loss 1.6939360485854555\n",
            "step 1443 - loss 1.6423708200454712 - moving ave loss 1.688779525731457\n",
            "step 1444 - loss 1.6072595119476318 - moving ave loss 1.6806275243530746\n",
            "step 1445 - loss 1.7568676471710205 - moving ave loss 1.6882515366348694\n",
            "step 1446 - loss 1.7255992889404297 - moving ave loss 1.6919863118654255\n",
            "step 1447 - loss 1.8301204442977905 - moving ave loss 1.705799725108662\n",
            "step 1448 - loss 1.8311543464660645 - moving ave loss 1.7183351872444024\n",
            "step 1449 - loss 1.4880375862121582 - moving ave loss 1.695305427141178\n",
            "step 1450 - loss 1.5807416439056396 - moving ave loss 1.683849048817624\n",
            "step 1451 - loss 1.6386666297912598 - moving ave loss 1.679330806914988\n",
            "step 1452 - loss 1.681030035018921 - moving ave loss 1.6795007297253814\n",
            "step 1453 - loss 1.766480565071106 - moving ave loss 1.688198713259954\n",
            "step 1454 - loss 1.5111372470855713 - moving ave loss 1.6704925666425159\n",
            "step 1455 - loss 1.5944005250930786 - moving ave loss 1.662883362487572\n",
            "step 1456 - loss 1.7144778966903687 - moving ave loss 1.6680428159078518\n",
            "step 1457 - loss 1.7123644351959229 - moving ave loss 1.672474977836659\n",
            "step 1458 - loss 2.114985466003418 - moving ave loss 1.716726026653335\n",
            "step 1459 - loss 1.7273839712142944 - moving ave loss 1.7177918211094312\n",
            "step 1460 - loss 1.4432283639907837 - moving ave loss 1.6903354753975663\n",
            "step 1461 - loss 1.8564987182617188 - moving ave loss 1.7069517996839816\n",
            "step 1462 - loss 1.7273964881896973 - moving ave loss 1.7089962685345532\n",
            "step 1463 - loss 1.9898864030838013 - moving ave loss 1.737085281989478\n",
            "step 1464 - loss 1.576941967010498 - moving ave loss 1.7210709504915802\n",
            "step 1465 - loss 2.1351237297058105 - moving ave loss 1.7624762284130033\n",
            "step 1466 - loss 1.8744547367095947 - moving ave loss 1.7736740792426624\n",
            "step 1467 - loss 1.756248950958252 - moving ave loss 1.7719315664142214\n",
            "step 1468 - loss 1.6391959190368652 - moving ave loss 1.7586580016764857\n",
            "step 1469 - loss 1.7740817070007324 - moving ave loss 1.7602003722089103\n",
            "step 1470 - loss 1.6633107662200928 - moving ave loss 1.7505114116100287\n",
            "step 1471 - loss 1.7042741775512695 - moving ave loss 1.745887688204153\n",
            "step 1472 - loss 1.6781889200210571 - moving ave loss 1.7391178113858434\n",
            "step 1473 - loss 1.7862193584442139 - moving ave loss 1.7438279660916804\n",
            "step 1474 - loss 1.750656247138977 - moving ave loss 1.7445107941964102\n",
            "step 1475 - loss 1.586505651473999 - moving ave loss 1.7287102799241691\n",
            "step 1476 - loss 2.197307586669922 - moving ave loss 1.7755700105987446\n",
            "step 1477 - loss 1.6843658685684204 - moving ave loss 1.7664495963957123\n",
            "step 1478 - loss 1.5520241260528564 - moving ave loss 1.7450070493614267\n",
            "step 1479 - loss 1.8764653205871582 - moving ave loss 1.758152876484\n",
            "step 1480 - loss 1.4764971733093262 - moving ave loss 1.7299873061665325\n",
            "step 1481 - loss 1.413241982460022 - moving ave loss 1.6983127737958816\n",
            "step 1482 - loss 1.7446829080581665 - moving ave loss 1.7029497872221102\n",
            "step 1483 - loss 1.4255037307739258 - moving ave loss 1.6752051815772917\n",
            "step 1484 - loss 1.4831511974334717 - moving ave loss 1.6559997831629099\n",
            "step 1485 - loss 1.6238138675689697 - moving ave loss 1.652781191603516\n",
            "step 1486 - loss 1.594871997833252 - moving ave loss 1.6469902722264895\n",
            "step 1487 - loss 1.421238660812378 - moving ave loss 1.6244151110850784\n",
            "step 1488 - loss 1.8368278741836548 - moving ave loss 1.6456563873949361\n",
            "step 1489 - loss 1.632359504699707 - moving ave loss 1.6443266991254133\n",
            "step 1490 - loss 1.569307565689087 - moving ave loss 1.6368247857817806\n",
            "step 1491 - loss 1.520664930343628 - moving ave loss 1.6252088002379654\n",
            "step 1492 - loss 1.849755883216858 - moving ave loss 1.6476635085358549\n",
            "step 1493 - loss 1.3887197971343994 - moving ave loss 1.6217691373957093\n",
            "step 1494 - loss 1.7005376815795898 - moving ave loss 1.6296459918140973\n",
            "step 1495 - loss 1.5389165878295898 - moving ave loss 1.6205730514156467\n",
            "step 1496 - loss 1.3750617504119873 - moving ave loss 1.5960219213152809\n",
            "step 1497 - loss 1.5465549230575562 - moving ave loss 1.5910752214895085\n",
            "step 1498 - loss 1.496412754058838 - moving ave loss 1.5816089747464415\n",
            "step 1499 - loss 1.6867234706878662 - moving ave loss 1.592120424340584\n",
            "step 1500 - loss 1.3929401636123657 - moving ave loss 1.5722023982677622\n",
            "Checkpoint at step 1500\n",
            "Finish 15 epoch(es)\n",
            "step 1501 - loss 1.4514884948730469 - moving ave loss 1.5601310079282908\n",
            "step 1502 - loss 1.7677621841430664 - moving ave loss 1.5808941255497684\n",
            "step 1503 - loss 1.3875494003295898 - moving ave loss 1.5615596530277507\n",
            "step 1504 - loss 1.6811712980270386 - moving ave loss 1.5735208175276796\n",
            "step 1505 - loss 1.545040488243103 - moving ave loss 1.570672784599222\n",
            "step 1506 - loss 2.0934386253356934 - moving ave loss 1.6229493686728693\n",
            "step 1507 - loss 1.3150084018707275 - moving ave loss 1.5921552719926553\n",
            "step 1508 - loss 1.48521089553833 - moving ave loss 1.5814608343472227\n",
            "step 1509 - loss 1.7812018394470215 - moving ave loss 1.6014349348572028\n",
            "step 1510 - loss 1.592203140258789 - moving ave loss 1.6005117553973616\n",
            "step 1511 - loss 1.6199380159378052 - moving ave loss 1.602454381451406\n",
            "step 1512 - loss 1.5299818515777588 - moving ave loss 1.5952071284640414\n",
            "step 1513 - loss 1.8876562118530273 - moving ave loss 1.6244520368029403\n",
            "step 1514 - loss 1.6794829368591309 - moving ave loss 1.6299551268085595\n",
            "step 1515 - loss 1.6224242448806763 - moving ave loss 1.629202038615771\n",
            "step 1516 - loss 1.5189428329467773 - moving ave loss 1.6181761180488716\n",
            "step 1517 - loss 1.7167718410491943 - moving ave loss 1.628035690348904\n",
            "step 1518 - loss 1.452655553817749 - moving ave loss 1.6104976766957886\n",
            "step 1519 - loss 1.6484053134918213 - moving ave loss 1.6142884403753919\n",
            "step 1520 - loss 1.4381928443908691 - moving ave loss 1.5966788807769396\n",
            "step 1521 - loss 1.6362833976745605 - moving ave loss 1.6006393324667019\n",
            "step 1522 - loss 1.4443976879119873 - moving ave loss 1.5850151680112303\n",
            "step 1523 - loss 1.6114614009857178 - moving ave loss 1.5876597913086792\n",
            "step 1524 - loss 1.9283874034881592 - moving ave loss 1.621732552526627\n",
            "step 1525 - loss 1.373879075050354 - moving ave loss 1.5969472047789999\n",
            "step 1526 - loss 1.4389784336090088 - moving ave loss 1.5811503276620007\n",
            "step 1527 - loss 1.4424666166305542 - moving ave loss 1.567281956558856\n",
            "step 1528 - loss 1.4115982055664062 - moving ave loss 1.5517135814596112\n",
            "step 1529 - loss 1.4178757667541504 - moving ave loss 1.5383297999890653\n",
            "step 1530 - loss 1.556699275970459 - moving ave loss 1.5401667475872047\n",
            "step 1531 - loss 1.868800163269043 - moving ave loss 1.5730300891553886\n",
            "step 1532 - loss 1.7562307119369507 - moving ave loss 1.5913501514335449\n",
            "step 1533 - loss 1.903851866722107 - moving ave loss 1.622600322962401\n",
            "step 1534 - loss 1.7146406173706055 - moving ave loss 1.6318043524032217\n",
            "step 1535 - loss 1.6261212825775146 - moving ave loss 1.6312360454206511\n",
            "step 1536 - loss 1.371593713760376 - moving ave loss 1.6052718122546237\n",
            "step 1537 - loss 1.7712006568908691 - moving ave loss 1.6218646967182484\n",
            "step 1538 - loss 1.4879958629608154 - moving ave loss 1.6084778133425053\n",
            "step 1539 - loss 1.4581961631774902 - moving ave loss 1.5934496483260037\n",
            "step 1540 - loss 1.3052575588226318 - moving ave loss 1.5646304393756665\n",
            "step 1541 - loss 1.6794109344482422 - moving ave loss 1.576108488882924\n",
            "step 1542 - loss 1.704185128211975 - moving ave loss 1.588916152815829\n",
            "step 1543 - loss 1.5292524099349976 - moving ave loss 1.582949778527746\n",
            "step 1544 - loss 1.5703141689300537 - moving ave loss 1.581686217567977\n",
            "step 1545 - loss 1.474219560623169 - moving ave loss 1.570939551873496\n",
            "step 1546 - loss 1.5310494899749756 - moving ave loss 1.5669505456836441\n",
            "step 1547 - loss 1.4309585094451904 - moving ave loss 1.5533513420597989\n",
            "step 1548 - loss 1.2462620735168457 - moving ave loss 1.5226424152055036\n",
            "step 1549 - loss 1.6766942739486694 - moving ave loss 1.53804760107982\n",
            "step 1550 - loss 1.6630200147628784 - moving ave loss 1.550544842448126\n",
            "step 1551 - loss 1.5478832721710205 - moving ave loss 1.5502786854204156\n",
            "step 1552 - loss 1.5874028205871582 - moving ave loss 1.55399109893709\n",
            "step 1553 - loss 2.382009744644165 - moving ave loss 1.6367929635077976\n",
            "step 1554 - loss 1.376832127571106 - moving ave loss 1.6107968799141283\n",
            "step 1555 - loss 1.3963630199432373 - moving ave loss 1.5893534939170393\n",
            "step 1556 - loss 1.3987922668457031 - moving ave loss 1.5702973712099058\n",
            "step 1557 - loss 1.4768919944763184 - moving ave loss 1.5609568335365471\n",
            "step 1558 - loss 1.5803744792938232 - moving ave loss 1.562898598112275\n",
            "step 1559 - loss 1.7000141143798828 - moving ave loss 1.576610149739036\n",
            "step 1560 - loss 1.322969913482666 - moving ave loss 1.551246126113399\n",
            "step 1561 - loss 1.4310493469238281 - moving ave loss 1.5392264481944418\n",
            "step 1562 - loss 1.422828197479248 - moving ave loss 1.5275866231229225\n",
            "step 1563 - loss 1.8646154403686523 - moving ave loss 1.5612895048474955\n",
            "step 1564 - loss 1.3876659870147705 - moving ave loss 1.543927153064223\n",
            "step 1565 - loss 1.409332275390625 - moving ave loss 1.5304676652968632\n",
            "step 1566 - loss 1.23384690284729 - moving ave loss 1.500805589051906\n",
            "step 1567 - loss 1.4738614559173584 - moving ave loss 1.4981111757384513\n",
            "step 1568 - loss 1.4912883043289185 - moving ave loss 1.4974288885974982\n",
            "step 1569 - loss 2.036459445953369 - moving ave loss 1.5513319443330853\n",
            "step 1570 - loss 2.350921154022217 - moving ave loss 1.6312908653019984\n",
            "step 1571 - loss 1.9386552572250366 - moving ave loss 1.6620273044943024\n",
            "step 1572 - loss 1.4167466163635254 - moving ave loss 1.6374992356812246\n",
            "step 1573 - loss 1.7689579725265503 - moving ave loss 1.6506451093657573\n",
            "step 1574 - loss 1.7064666748046875 - moving ave loss 1.6562272659096504\n",
            "step 1575 - loss 1.4619593620300293 - moving ave loss 1.6368004755216883\n",
            "step 1576 - loss 1.768484115600586 - moving ave loss 1.6499688395295782\n",
            "step 1577 - loss 1.5399856567382812 - moving ave loss 1.6389705212504484\n",
            "step 1578 - loss 1.4012489318847656 - moving ave loss 1.6151983623138801\n",
            "step 1579 - loss 1.3149784803390503 - moving ave loss 1.5851763741163973\n",
            "step 1580 - loss 1.5402350425720215 - moving ave loss 1.5806822409619599\n",
            "step 1581 - loss 1.7122788429260254 - moving ave loss 1.5938419011583664\n",
            "step 1582 - loss 1.5778917074203491 - moving ave loss 1.5922468817845647\n",
            "step 1583 - loss 1.466604232788086 - moving ave loss 1.579682616884917\n",
            "step 1584 - loss 1.2205991744995117 - moving ave loss 1.5437742726463766\n",
            "step 1585 - loss 1.2681087255477905 - moving ave loss 1.5162077179365179\n",
            "step 1586 - loss 1.4105970859527588 - moving ave loss 1.505646654738142\n",
            "step 1587 - loss 1.419687032699585 - moving ave loss 1.4970506925342864\n",
            "step 1588 - loss 1.5667026042938232 - moving ave loss 1.5040158837102402\n",
            "step 1589 - loss 1.2760376930236816 - moving ave loss 1.4812180646415845\n",
            "step 1590 - loss 1.5162153244018555 - moving ave loss 1.4847177906176114\n",
            "step 1591 - loss 1.218392252922058 - moving ave loss 1.4580852368480561\n",
            "step 1592 - loss 1.3665045499801636 - moving ave loss 1.4489271681612668\n",
            "step 1593 - loss 1.6690632104873657 - moving ave loss 1.4709407723938765\n",
            "step 1594 - loss 1.5210717916488647 - moving ave loss 1.4759538743193754\n",
            "step 1595 - loss 1.730800986289978 - moving ave loss 1.5014385855164356\n",
            "step 1596 - loss 1.420519232749939 - moving ave loss 1.493346650239786\n",
            "step 1597 - loss 1.4371366500854492 - moving ave loss 1.4877256502243523\n",
            "step 1598 - loss 1.4420278072357178 - moving ave loss 1.4831558659254889\n",
            "step 1599 - loss 1.3559819459915161 - moving ave loss 1.4704384739320915\n",
            "step 1600 - loss 1.2522276639938354 - moving ave loss 1.4486173929382657\n",
            "Finish 16 epoch(es)\n",
            "step 1601 - loss 1.544479250907898 - moving ave loss 1.458203578735229\n",
            "step 1602 - loss 1.4866098165512085 - moving ave loss 1.4610442025168269\n",
            "step 1603 - loss 1.5935778617858887 - moving ave loss 1.4742975684437332\n",
            "step 1604 - loss 1.2858670949935913 - moving ave loss 1.455454521098719\n",
            "step 1605 - loss 1.469613790512085 - moving ave loss 1.4568704480400558\n",
            "step 1606 - loss 1.5835102796554565 - moving ave loss 1.469534431201596\n",
            "step 1607 - loss 1.447365403175354 - moving ave loss 1.467317528398972\n",
            "step 1608 - loss 1.6745760440826416 - moving ave loss 1.4880433799673387\n",
            "step 1609 - loss 1.3172900676727295 - moving ave loss 1.4709680487378778\n",
            "step 1610 - loss 1.698018193244934 - moving ave loss 1.4936730631885835\n",
            "step 1611 - loss 1.2582635879516602 - moving ave loss 1.4701321156648912\n",
            "step 1612 - loss 1.2994214296340942 - moving ave loss 1.4530610470618115\n",
            "step 1613 - loss 1.851906657218933 - moving ave loss 1.4929456080775236\n",
            "step 1614 - loss 1.3126013278961182 - moving ave loss 1.4749111800593833\n",
            "step 1615 - loss 1.4050588607788086 - moving ave loss 1.4679259481313258\n",
            "step 1616 - loss 1.4053404331207275 - moving ave loss 1.461667396630266\n",
            "step 1617 - loss 1.934735894203186 - moving ave loss 1.508974246387558\n",
            "step 1618 - loss 1.606346607208252 - moving ave loss 1.5187114824696275\n",
            "step 1619 - loss 1.3681986331939697 - moving ave loss 1.5036601975420616\n",
            "step 1620 - loss 1.518721580505371 - moving ave loss 1.5051663358383927\n",
            "step 1621 - loss 1.5368008613586426 - moving ave loss 1.5083297883904176\n",
            "step 1622 - loss 1.4115527868270874 - moving ave loss 1.4986520882340848\n",
            "step 1623 - loss 1.7647731304168701 - moving ave loss 1.5252641924523633\n",
            "step 1624 - loss 1.305492877960205 - moving ave loss 1.5032870610031477\n",
            "step 1625 - loss 1.245254397392273 - moving ave loss 1.4774837946420603\n",
            "step 1626 - loss 1.2887006998062134 - moving ave loss 1.4586054851584755\n",
            "step 1627 - loss 1.401045560836792 - moving ave loss 1.4528494927263071\n",
            "step 1628 - loss 1.3173699378967285 - moving ave loss 1.4393015372433493\n",
            "step 1629 - loss 1.6115504503250122 - moving ave loss 1.4565264285515156\n",
            "step 1630 - loss 1.5508596897125244 - moving ave loss 1.4659597546676166\n",
            "step 1631 - loss 1.6591535806655884 - moving ave loss 1.485279137267414\n",
            "step 1632 - loss 1.5580832958221436 - moving ave loss 1.4925595531228868\n",
            "step 1633 - loss 1.229540228843689 - moving ave loss 1.466257620694967\n",
            "step 1634 - loss 1.7250659465789795 - moving ave loss 1.4921384532833684\n",
            "step 1635 - loss 1.6140284538269043 - moving ave loss 1.504327453337722\n",
            "step 1636 - loss 1.6232380867004395 - moving ave loss 1.5162185166739939\n",
            "step 1637 - loss 1.2951452732086182 - moving ave loss 1.4941111923274564\n",
            "step 1638 - loss 1.256067156791687 - moving ave loss 1.4703067887738794\n",
            "step 1639 - loss 1.226820468902588 - moving ave loss 1.4459581567867503\n",
            "step 1640 - loss 1.4351087808609009 - moving ave loss 1.4448732191941653\n",
            "step 1641 - loss 1.759172797203064 - moving ave loss 1.4763031769950552\n",
            "step 1642 - loss 1.2811254262924194 - moving ave loss 1.4567854019247917\n",
            "step 1643 - loss 1.29732346534729 - moving ave loss 1.4408392082670416\n",
            "step 1644 - loss 1.4931997060775757 - moving ave loss 1.446075258048095\n",
            "step 1645 - loss 1.3880460262298584 - moving ave loss 1.4402723348662714\n",
            "step 1646 - loss 1.7269405126571655 - moving ave loss 1.468939152645361\n",
            "step 1647 - loss 1.1939157247543335 - moving ave loss 1.4414368098562582\n",
            "step 1648 - loss 1.6587163209915161 - moving ave loss 1.463164760969784\n",
            "step 1649 - loss 1.427541971206665 - moving ave loss 1.459602481993472\n",
            "step 1650 - loss 1.2752864360809326 - moving ave loss 1.4411708774022183\n",
            "step 1651 - loss 1.5233509540557861 - moving ave loss 1.4493888850675751\n",
            "step 1652 - loss 1.48128080368042 - moving ave loss 1.4525780769288597\n",
            "step 1653 - loss 1.2098362445831299 - moving ave loss 1.4283038936942867\n",
            "step 1654 - loss 1.2989330291748047 - moving ave loss 1.4153668072423384\n",
            "step 1655 - loss 1.5189599990844727 - moving ave loss 1.425726126426552\n",
            "step 1656 - loss 1.246140718460083 - moving ave loss 1.407767585629905\n",
            "step 1657 - loss 1.5864934921264648 - moving ave loss 1.4256401762795612\n",
            "step 1658 - loss 1.1787689924240112 - moving ave loss 1.4009530578940061\n",
            "step 1659 - loss 1.388553500175476 - moving ave loss 1.3997131021221532\n",
            "step 1660 - loss 1.2932770252227783 - moving ave loss 1.3890694944322157\n",
            "step 1661 - loss 1.6099406480789185 - moving ave loss 1.411156609796886\n",
            "step 1662 - loss 1.6093004941940308 - moving ave loss 1.4309709982366003\n",
            "step 1663 - loss 1.361467719078064 - moving ave loss 1.4240206703207468\n",
            "step 1664 - loss 1.504758358001709 - moving ave loss 1.432094439088843\n",
            "step 1665 - loss 1.2258894443511963 - moving ave loss 1.4114739396150784\n",
            "step 1666 - loss 1.45721435546875 - moving ave loss 1.4160479812004456\n",
            "step 1667 - loss 1.3870573043823242 - moving ave loss 1.4131489135186335\n",
            "step 1668 - loss 1.3773252964019775 - moving ave loss 1.4095665518069678\n",
            "step 1669 - loss 1.369873046875 - moving ave loss 1.4055972013137712\n",
            "step 1670 - loss 1.4168429374694824 - moving ave loss 1.4067217749293424\n",
            "step 1671 - loss 1.2789251804351807 - moving ave loss 1.393942115479926\n",
            "step 1672 - loss 1.4870953559875488 - moving ave loss 1.4032574395306885\n",
            "step 1673 - loss 1.2216897010803223 - moving ave loss 1.385100665685652\n",
            "step 1674 - loss 1.2836517095565796 - moving ave loss 1.3749557700727446\n",
            "step 1675 - loss 1.826445460319519 - moving ave loss 1.4201047390974222\n",
            "step 1676 - loss 1.3715189695358276 - moving ave loss 1.4152461621412629\n",
            "step 1677 - loss 1.483365774154663 - moving ave loss 1.422058123342603\n",
            "step 1678 - loss 1.3183658123016357 - moving ave loss 1.4116888922385065\n",
            "step 1679 - loss 1.154470682144165 - moving ave loss 1.3859670712290724\n",
            "step 1680 - loss 1.6042300462722778 - moving ave loss 1.407793368733393\n",
            "step 1681 - loss 1.4267783164978027 - moving ave loss 1.409691863509834\n",
            "step 1682 - loss 1.109516978263855 - moving ave loss 1.3796743749852363\n",
            "step 1683 - loss 1.2959587574005127 - moving ave loss 1.371302813226764\n",
            "step 1684 - loss 1.3972342014312744 - moving ave loss 1.373895952047215\n",
            "step 1685 - loss 1.6744163036346436 - moving ave loss 1.403947987205958\n",
            "step 1686 - loss 1.2660832405090332 - moving ave loss 1.3901615125362654\n",
            "step 1687 - loss 1.3621599674224854 - moving ave loss 1.3873613580248874\n",
            "step 1688 - loss 1.4408669471740723 - moving ave loss 1.392711916939806\n",
            "step 1689 - loss 1.2936385869979858 - moving ave loss 1.3828045839456238\n",
            "step 1690 - loss 1.1734180450439453 - moving ave loss 1.361865930055456\n",
            "step 1691 - loss 1.1931051015853882 - moving ave loss 1.3449898472084494\n",
            "step 1692 - loss 1.2009916305541992 - moving ave loss 1.3305900255430245\n",
            "step 1693 - loss 1.3206884860992432 - moving ave loss 1.3295998715986466\n",
            "step 1694 - loss 1.3871216773986816 - moving ave loss 1.3353520521786502\n",
            "step 1695 - loss 1.4999821186065674 - moving ave loss 1.351815058821442\n",
            "step 1696 - loss 1.2694323062896729 - moving ave loss 1.343576783568265\n",
            "step 1697 - loss 1.3738759756088257 - moving ave loss 1.346606702772321\n",
            "step 1698 - loss 1.6292071342468262 - moving ave loss 1.3748667459197714\n",
            "step 1699 - loss 1.2200243473052979 - moving ave loss 1.359382506058324\n",
            "step 1700 - loss 1.4823777675628662 - moving ave loss 1.3716820322087782\n",
            "Finish 17 epoch(es)\n",
            "step 1701 - loss 1.4403207302093506 - moving ave loss 1.3785459020088353\n",
            "step 1702 - loss 1.22035813331604 - moving ave loss 1.3627271251395559\n",
            "step 1703 - loss 1.4411929845809937 - moving ave loss 1.3705737110836997\n",
            "step 1704 - loss 1.2630157470703125 - moving ave loss 1.359817914682361\n",
            "step 1705 - loss 1.4830178022384644 - moving ave loss 1.3721379034379715\n",
            "step 1706 - loss 1.141811490058899 - moving ave loss 1.3491052621000643\n",
            "step 1707 - loss 1.3135756254196167 - moving ave loss 1.3455522984320196\n",
            "step 1708 - loss 1.305529236793518 - moving ave loss 1.3415499922681695\n",
            "step 1709 - loss 1.1631560325622559 - moving ave loss 1.3237105962975781\n",
            "step 1710 - loss 1.3411250114440918 - moving ave loss 1.3254520378122294\n",
            "step 1711 - loss 1.8447774648666382 - moving ave loss 1.3773845805176703\n",
            "step 1712 - loss 1.1785061359405518 - moving ave loss 1.3574967360599584\n",
            "step 1713 - loss 1.3782360553741455 - moving ave loss 1.359570667991377\n",
            "step 1714 - loss 1.2057850360870361 - moving ave loss 1.344192104800943\n",
            "step 1715 - loss 1.3147504329681396 - moving ave loss 1.3412479376176627\n",
            "step 1716 - loss 1.2522528171539307 - moving ave loss 1.3323484255712896\n",
            "step 1717 - loss 1.4242613315582275 - moving ave loss 1.3415397161699834\n",
            "step 1718 - loss 1.4339590072631836 - moving ave loss 1.3507816452793033\n",
            "step 1719 - loss 1.1756991147994995 - moving ave loss 1.3332733922313231\n",
            "step 1720 - loss 1.1669131517410278 - moving ave loss 1.3166373681822936\n",
            "step 1721 - loss 1.1452785730361938 - moving ave loss 1.2995014886676837\n",
            "step 1722 - loss 1.1995441913604736 - moving ave loss 1.2895057589369627\n",
            "step 1723 - loss 1.5945804119110107 - moving ave loss 1.3200132242343676\n",
            "step 1724 - loss 1.5877869129180908 - moving ave loss 1.3467905931027402\n",
            "step 1725 - loss 1.397904634475708 - moving ave loss 1.351901997240037\n",
            "step 1726 - loss 1.2460474967956543 - moving ave loss 1.3413165471955988\n",
            "step 1727 - loss 1.5387694835662842 - moving ave loss 1.3610618408326673\n",
            "step 1728 - loss 1.689895510673523 - moving ave loss 1.393945207816753\n",
            "step 1729 - loss 1.0478012561798096 - moving ave loss 1.3593308126530586\n",
            "step 1730 - loss 1.566776990890503 - moving ave loss 1.380075430476803\n",
            "step 1731 - loss 1.1451852321624756 - moving ave loss 1.3565864106453702\n",
            "step 1732 - loss 1.2723181247711182 - moving ave loss 1.348159582057945\n",
            "step 1733 - loss 1.3020944595336914 - moving ave loss 1.3435530698055198\n",
            "step 1734 - loss 1.1593513488769531 - moving ave loss 1.3251328977126633\n",
            "step 1735 - loss 1.089087724685669 - moving ave loss 1.301528380409964\n",
            "step 1736 - loss 1.3287475109100342 - moving ave loss 1.304250293459971\n",
            "step 1737 - loss 1.5228657722473145 - moving ave loss 1.3261118413387054\n",
            "step 1738 - loss 1.0852893590927124 - moving ave loss 1.3020295931141062\n",
            "step 1739 - loss 1.2172391414642334 - moving ave loss 1.2935505479491187\n",
            "step 1740 - loss 1.3452503681182861 - moving ave loss 1.2987205299660356\n",
            "step 1741 - loss 1.6505810022354126 - moving ave loss 1.3339065771929732\n",
            "step 1742 - loss 1.1870931386947632 - moving ave loss 1.3192252333431522\n",
            "step 1743 - loss 1.4378690719604492 - moving ave loss 1.331089617204882\n",
            "step 1744 - loss 1.3587902784347534 - moving ave loss 1.3338596833278693\n",
            "step 1745 - loss 1.1192893981933594 - moving ave loss 1.3124026548144183\n",
            "step 1746 - loss 1.2921574115753174 - moving ave loss 1.3103781304905082\n",
            "step 1747 - loss 1.0994725227355957 - moving ave loss 1.289287569715017\n",
            "step 1748 - loss 1.5387810468673706 - moving ave loss 1.3142369174302524\n",
            "step 1749 - loss 1.190792441368103 - moving ave loss 1.3018924698240375\n",
            "step 1750 - loss 1.3390401601791382 - moving ave loss 1.3056072388595477\n",
            "Checkpoint at step 1750\n",
            "step 1751 - loss 1.46354079246521 - moving ave loss 1.321400594220114\n",
            "step 1752 - loss 1.106113314628601 - moving ave loss 1.2998718662609625\n",
            "step 1753 - loss 1.516501784324646 - moving ave loss 1.321534858067331\n",
            "step 1754 - loss 1.5845146179199219 - moving ave loss 1.34783283405259\n",
            "step 1755 - loss 1.1577043533325195 - moving ave loss 1.3288199859805832\n",
            "step 1756 - loss 1.4139633178710938 - moving ave loss 1.3373343191696343\n",
            "step 1757 - loss 1.2773158550262451 - moving ave loss 1.3313324727552953\n",
            "step 1758 - loss 1.1519808769226074 - moving ave loss 1.3133973131720265\n",
            "step 1759 - loss 1.433293342590332 - moving ave loss 1.325386916113857\n",
            "step 1760 - loss 1.078163743019104 - moving ave loss 1.3006645988043817\n",
            "step 1761 - loss 1.2419068813323975 - moving ave loss 1.2947888270571832\n",
            "step 1762 - loss 1.252540111541748 - moving ave loss 1.2905639555056398\n",
            "step 1763 - loss 1.19091796875 - moving ave loss 1.280599356830076\n",
            "step 1764 - loss 1.2296773195266724 - moving ave loss 1.2755071530997355\n",
            "step 1765 - loss 1.0363538265228271 - moving ave loss 1.2515918204420446\n",
            "step 1766 - loss 1.5449531078338623 - moving ave loss 1.2809279491812264\n",
            "step 1767 - loss 1.071962594985962 - moving ave loss 1.2600314137617001\n",
            "step 1768 - loss 1.0710943937301636 - moving ave loss 1.2411377117585465\n",
            "step 1769 - loss 1.0860717296600342 - moving ave loss 1.2256311135486953\n",
            "step 1770 - loss 1.3001177310943604 - moving ave loss 1.2330797753032618\n",
            "step 1771 - loss 1.393885612487793 - moving ave loss 1.249160359021715\n",
            "step 1772 - loss 1.168022871017456 - moving ave loss 1.2410466102212891\n",
            "step 1773 - loss 1.4131745100021362 - moving ave loss 1.2582594001993739\n",
            "step 1774 - loss 1.4053235054016113 - moving ave loss 1.2729658107195978\n",
            "step 1775 - loss 1.2744454145431519 - moving ave loss 1.2731137711019533\n",
            "step 1776 - loss 1.155625343322754 - moving ave loss 1.2613649283240336\n",
            "step 1777 - loss 1.18130362033844 - moving ave loss 1.2533587975254743\n",
            "step 1778 - loss 1.3016462326049805 - moving ave loss 1.258187541033425\n",
            "step 1779 - loss 1.4205740690231323 - moving ave loss 1.2744261938323957\n",
            "step 1780 - loss 1.246068000793457 - moving ave loss 1.2715903745285018\n",
            "step 1781 - loss 1.405991792678833 - moving ave loss 1.285030516343535\n",
            "step 1782 - loss 1.235924482345581 - moving ave loss 1.2801199129437395\n",
            "step 1783 - loss 1.5763704776763916 - moving ave loss 1.3097449694170047\n",
            "step 1784 - loss 1.1264346837997437 - moving ave loss 1.2914139408552787\n",
            "step 1785 - loss 1.264768123626709 - moving ave loss 1.2887493591324217\n",
            "step 1786 - loss 1.050689458847046 - moving ave loss 1.264943369103884\n",
            "step 1787 - loss 1.0808316469192505 - moving ave loss 1.2465321968854208\n",
            "step 1788 - loss 1.1616357564926147 - moving ave loss 1.23804255284614\n",
            "step 1789 - loss 1.1364052295684814 - moving ave loss 1.2278788205183744\n",
            "step 1790 - loss 1.375403881072998 - moving ave loss 1.242631326573837\n",
            "step 1791 - loss 1.3928897380828857 - moving ave loss 1.2576571677247417\n",
            "step 1792 - loss 1.3420641422271729 - moving ave loss 1.2660978651749848\n",
            "step 1793 - loss 1.2735806703567505 - moving ave loss 1.2668461456931615\n",
            "step 1794 - loss 1.4927408695220947 - moving ave loss 1.289435618076055\n",
            "step 1795 - loss 1.2036467790603638 - moving ave loss 1.2808567341744859\n",
            "step 1796 - loss 1.0968739986419678 - moving ave loss 1.2624584606212341\n",
            "step 1797 - loss 1.2804510593414307 - moving ave loss 1.2642577204932537\n",
            "step 1798 - loss 1.0258467197418213 - moving ave loss 1.2404166204181104\n",
            "step 1799 - loss 1.1462273597717285 - moving ave loss 1.2309976943534722\n",
            "step 1800 - loss 1.2742670774459839 - moving ave loss 1.2353246326627232\n",
            "Finish 18 epoch(es)\n",
            "step 1801 - loss 1.0458662509918213 - moving ave loss 1.216378794495633\n",
            "step 1802 - loss 1.495002269744873 - moving ave loss 1.2442411420205572\n",
            "step 1803 - loss 1.2149029970169067 - moving ave loss 1.2413073275201922\n",
            "step 1804 - loss 1.046963095664978 - moving ave loss 1.221872904334671\n",
            "step 1805 - loss 1.126573085784912 - moving ave loss 1.212342922479695\n",
            "step 1806 - loss 1.0097241401672363 - moving ave loss 1.1920810442484493\n",
            "step 1807 - loss 1.3144917488098145 - moving ave loss 1.2043221147045857\n",
            "step 1808 - loss 1.3627088069915771 - moving ave loss 1.2201607839332849\n",
            "step 1809 - loss 1.1947771310806274 - moving ave loss 1.2176224186480191\n",
            "step 1810 - loss 1.4427169561386108 - moving ave loss 1.2401318723970782\n",
            "step 1811 - loss 1.0729401111602783 - moving ave loss 1.2234126962733982\n",
            "step 1812 - loss 1.1701939105987549 - moving ave loss 1.218090817705934\n",
            "step 1813 - loss 1.2968032360076904 - moving ave loss 1.2259620595361096\n",
            "step 1814 - loss 1.4853770732879639 - moving ave loss 1.251903560911295\n",
            "step 1815 - loss 1.0497454404830933 - moving ave loss 1.231687748868475\n",
            "step 1816 - loss 1.7107658386230469 - moving ave loss 1.2795955578439322\n",
            "step 1817 - loss 1.159883737564087 - moving ave loss 1.2676243758159478\n",
            "step 1818 - loss 1.1587653160095215 - moving ave loss 1.2567384698353052\n",
            "step 1819 - loss 1.103528380393982 - moving ave loss 1.2414174608911728\n",
            "step 1820 - loss 1.1732559204101562 - moving ave loss 1.2346013068430712\n",
            "step 1821 - loss 1.091597080230713 - moving ave loss 1.2203008841818355\n",
            "step 1822 - loss 1.160128116607666 - moving ave loss 1.2142836074244185\n",
            "step 1823 - loss 1.5659761428833008 - moving ave loss 1.2494528609703068\n",
            "step 1824 - loss 1.242908000946045 - moving ave loss 1.2487983749678808\n",
            "step 1825 - loss 1.3998651504516602 - moving ave loss 1.2639050525162587\n",
            "step 1826 - loss 0.9834331274032593 - moving ave loss 1.2358578600049588\n",
            "step 1827 - loss 1.7644917964935303 - moving ave loss 1.288721253653816\n",
            "step 1828 - loss 1.0239968299865723 - moving ave loss 1.2622488112870918\n",
            "step 1829 - loss 1.3245444297790527 - moving ave loss 1.2684783731362879\n",
            "step 1830 - loss 1.0583826303482056 - moving ave loss 1.2474687988574795\n",
            "step 1831 - loss 1.4409117698669434 - moving ave loss 1.266813095958426\n",
            "step 1832 - loss 1.1178959608078003 - moving ave loss 1.2519213824433635\n",
            "step 1833 - loss 1.0624301433563232 - moving ave loss 1.2329722585346594\n",
            "step 1834 - loss 1.1560993194580078 - moving ave loss 1.2252849646269943\n",
            "step 1835 - loss 2.1329762935638428 - moving ave loss 1.3160540975206794\n",
            "step 1836 - loss 1.336186408996582 - moving ave loss 1.3180673286682698\n",
            "step 1837 - loss 1.1063631772994995 - moving ave loss 1.2968969135313928\n",
            "step 1838 - loss 1.0591304302215576 - moving ave loss 1.2731202652004092\n",
            "step 1839 - loss 1.4136207103729248 - moving ave loss 1.2871703097176608\n",
            "step 1840 - loss 1.429974913597107 - moving ave loss 1.3014507701056055\n",
            "step 1841 - loss 1.2621387243270874 - moving ave loss 1.2975195655277536\n",
            "step 1842 - loss 1.3655273914337158 - moving ave loss 1.3043203481183498\n",
            "step 1843 - loss 1.3295456171035767 - moving ave loss 1.3068428750168726\n",
            "step 1844 - loss 1.1370584964752197 - moving ave loss 1.2898644371627075\n",
            "step 1845 - loss 0.9784368872642517 - moving ave loss 1.258721682172862\n",
            "step 1846 - loss 1.3799035549163818 - moving ave loss 1.270839869447214\n",
            "step 1847 - loss 0.9108548164367676 - moving ave loss 1.2348413641461695\n",
            "step 1848 - loss 1.3281384706497192 - moving ave loss 1.2441710747965247\n",
            "step 1849 - loss 1.09144926071167 - moving ave loss 1.2288988933880391\n",
            "step 1850 - loss 0.92201167345047 - moving ave loss 1.198210171394282\n",
            "step 1851 - loss 1.065582513809204 - moving ave loss 1.1849474056357743\n",
            "step 1852 - loss 0.9814687371253967 - moving ave loss 1.1645995387847365\n",
            "step 1853 - loss 1.6589370965957642 - moving ave loss 1.2140332945658394\n",
            "step 1854 - loss 1.3146580457687378 - moving ave loss 1.2240957696861292\n",
            "step 1855 - loss 1.4096944332122803 - moving ave loss 1.2426556360387444\n",
            "step 1856 - loss 1.1687488555908203 - moving ave loss 1.235264957993952\n",
            "step 1857 - loss 1.2140157222747803 - moving ave loss 1.233140034422035\n",
            "step 1858 - loss 1.2921581268310547 - moving ave loss 1.239041843662937\n",
            "step 1859 - loss 1.2275651693344116 - moving ave loss 1.2378941762300846\n",
            "step 1860 - loss 1.035786509513855 - moving ave loss 1.2176834095584617\n",
            "step 1861 - loss 1.1255964040756226 - moving ave loss 1.2084747090101777\n",
            "step 1862 - loss 1.3036088943481445 - moving ave loss 1.2179881275439746\n",
            "step 1863 - loss 1.325579047203064 - moving ave loss 1.2287472195098836\n",
            "step 1864 - loss 1.0425305366516113 - moving ave loss 1.2101255512240565\n",
            "step 1865 - loss 1.167585015296936 - moving ave loss 1.2058714976313445\n",
            "step 1866 - loss 1.3703176975250244 - moving ave loss 1.2223161176207127\n",
            "step 1867 - loss 0.9156944751739502 - moving ave loss 1.1916539533760364\n",
            "step 1868 - loss 1.0728706121444702 - moving ave loss 1.1797756192528799\n",
            "step 1869 - loss 1.1542799472808838 - moving ave loss 1.1772260520556803\n",
            "step 1870 - loss 1.079298734664917 - moving ave loss 1.167433320316604\n",
            "step 1871 - loss 1.207726240158081 - moving ave loss 1.1714626123007517\n",
            "step 1872 - loss 1.0159412622451782 - moving ave loss 1.1559104772951945\n",
            "step 1873 - loss 0.9939515590667725 - moving ave loss 1.1397145854723523\n",
            "step 1874 - loss 1.4196550846099854 - moving ave loss 1.1677086353861157\n",
            "step 1875 - loss 1.1422667503356934 - moving ave loss 1.1651644468810736\n",
            "step 1876 - loss 0.9993976354598999 - moving ave loss 1.1485877657389563\n",
            "step 1877 - loss 1.1048383712768555 - moving ave loss 1.1442128262927462\n",
            "step 1878 - loss 1.0297895669937134 - moving ave loss 1.132770500362843\n",
            "step 1879 - loss 0.937404453754425 - moving ave loss 1.1132338957020012\n",
            "step 1880 - loss 1.0980981588363647 - moving ave loss 1.1117203220154375\n",
            "step 1881 - loss 1.2231961488723755 - moving ave loss 1.1228679047011314\n",
            "step 1882 - loss 1.0100536346435547 - moving ave loss 1.1115864776953739\n",
            "step 1883 - loss 1.225080966949463 - moving ave loss 1.1229359266207828\n",
            "step 1884 - loss 1.4284656047821045 - moving ave loss 1.153488894436915\n",
            "step 1885 - loss 1.1119868755340576 - moving ave loss 1.1493386925466293\n",
            "step 1886 - loss 1.1867603063583374 - moving ave loss 1.1530808539278001\n",
            "step 1887 - loss 1.3234013319015503 - moving ave loss 1.1701129017251752\n",
            "step 1888 - loss 0.9195047616958618 - moving ave loss 1.1450520877222439\n",
            "step 1889 - loss 1.2654376029968262 - moving ave loss 1.1570906392497022\n",
            "step 1890 - loss 1.1931253671646118 - moving ave loss 1.160694112041193\n",
            "step 1891 - loss 1.0529621839523315 - moving ave loss 1.149920919232307\n",
            "step 1892 - loss 1.6057751178741455 - moving ave loss 1.195506339096491\n",
            "step 1893 - loss 0.9349502325057983 - moving ave loss 1.1694507284374218\n",
            "step 1894 - loss 1.2684025764465332 - moving ave loss 1.1793459132383328\n",
            "step 1895 - loss 1.8603543043136597 - moving ave loss 1.2474467523458657\n",
            "step 1896 - loss 1.239495038986206 - moving ave loss 1.2466515810099\n",
            "step 1897 - loss 1.4150046110153198 - moving ave loss 1.263486884010442\n",
            "step 1898 - loss 1.0463871955871582 - moving ave loss 1.2417769151681137\n",
            "step 1899 - loss 1.2830806970596313 - moving ave loss 1.2459072933572655\n",
            "step 1900 - loss 0.9529534578323364 - moving ave loss 1.2166119098047727\n",
            "Finish 19 epoch(es)\n",
            "step 1901 - loss 1.078802227973938 - moving ave loss 1.2028309416216894\n",
            "step 1902 - loss 1.2425146102905273 - moving ave loss 1.2067993084885733\n",
            "step 1903 - loss 1.3382248878479004 - moving ave loss 1.219941866424506\n",
            "step 1904 - loss 0.9839383363723755 - moving ave loss 1.1963415134192932\n",
            "step 1905 - loss 1.0273946523666382 - moving ave loss 1.1794468273140277\n",
            "step 1906 - loss 1.2966959476470947 - moving ave loss 1.1911717393473344\n",
            "step 1907 - loss 1.031479835510254 - moving ave loss 1.1752025489636264\n",
            "step 1908 - loss 1.158559799194336 - moving ave loss 1.1735382739866975\n",
            "step 1909 - loss 1.1166751384735107 - moving ave loss 1.167851960435379\n",
            "step 1910 - loss 1.1591957807540894 - moving ave loss 1.1669863424672502\n",
            "step 1911 - loss 1.3209455013275146 - moving ave loss 1.1823822583532768\n",
            "step 1912 - loss 1.1722395420074463 - moving ave loss 1.181367986718694\n",
            "step 1913 - loss 1.1750993728637695 - moving ave loss 1.1807411253332016\n",
            "step 1914 - loss 0.9401198625564575 - moving ave loss 1.156678999055527\n",
            "step 1915 - loss 1.242796540260315 - moving ave loss 1.165290753176006\n",
            "step 1916 - loss 0.9721847176551819 - moving ave loss 1.1459801496239237\n",
            "step 1917 - loss 1.1587378978729248 - moving ave loss 1.1472559244488238\n",
            "step 1918 - loss 1.0195223093032837 - moving ave loss 1.1344825629342699\n",
            "step 1919 - loss 0.9953905940055847 - moving ave loss 1.1205733660414015\n",
            "step 1920 - loss 1.4346225261688232 - moving ave loss 1.1519782820541435\n",
            "step 1921 - loss 1.3571850061416626 - moving ave loss 1.1724989544628956\n",
            "step 1922 - loss 1.0172799825668335 - moving ave loss 1.1569770572732896\n",
            "step 1923 - loss 1.7087883949279785 - moving ave loss 1.2121581910387584\n",
            "step 1924 - loss 1.1856777667999268 - moving ave loss 1.2095101486148752\n",
            "step 1925 - loss 1.3913655281066895 - moving ave loss 1.2276956865640567\n",
            "step 1926 - loss 1.2828433513641357 - moving ave loss 1.2332104530440646\n",
            "step 1927 - loss 1.1491559743881226 - moving ave loss 1.2248050051784705\n",
            "step 1928 - loss 0.9232290983200073 - moving ave loss 1.194647414492624\n",
            "step 1929 - loss 1.143481731414795 - moving ave loss 1.189530846184841\n",
            "step 1930 - loss 1.189279556274414 - moving ave loss 1.1895057171937984\n",
            "step 1931 - loss 1.3608880043029785 - moving ave loss 1.2066439459047165\n",
            "step 1932 - loss 1.0576772689819336 - moving ave loss 1.1917472782124383\n",
            "step 1933 - loss 0.987885594367981 - moving ave loss 1.1713611098279926\n",
            "step 1934 - loss 1.0440471172332764 - moving ave loss 1.1586297105685208\n",
            "step 1935 - loss 0.9645898342132568 - moving ave loss 1.1392257229329945\n",
            "step 1936 - loss 0.9810585975646973 - moving ave loss 1.1234090103961647\n",
            "step 1937 - loss 1.1336009502410889 - moving ave loss 1.1244282043806573\n",
            "step 1938 - loss 0.9048644304275513 - moving ave loss 1.1024718269853468\n",
            "step 1939 - loss 0.9528257846832275 - moving ave loss 1.087507222755135\n",
            "step 1940 - loss 1.2460944652557373 - moving ave loss 1.1033659470051953\n",
            "step 1941 - loss 1.1945054531097412 - moving ave loss 1.11247989761565\n",
            "step 1942 - loss 0.848995566368103 - moving ave loss 1.0861314644908953\n",
            "step 1943 - loss 1.1229503154754639 - moving ave loss 1.089813349589352\n",
            "step 1944 - loss 1.1779577732086182 - moving ave loss 1.0986277919512788\n",
            "step 1945 - loss 1.1577997207641602 - moving ave loss 1.104544984832567\n",
            "step 1946 - loss 1.0263020992279053 - moving ave loss 1.0967206962721008\n",
            "step 1947 - loss 1.207326889038086 - moving ave loss 1.1077813155486993\n",
            "step 1948 - loss 1.0815412998199463 - moving ave loss 1.105157313975824\n",
            "step 1949 - loss 0.9750627279281616 - moving ave loss 1.0921478553710577\n",
            "step 1950 - loss 1.0188010931015015 - moving ave loss 1.0848131791441022\n",
            "step 1951 - loss 0.9806792736053467 - moving ave loss 1.0743997885902268\n",
            "step 1952 - loss 1.0495797395706177 - moving ave loss 1.0719177836882658\n",
            "step 1953 - loss 1.0359089374542236 - moving ave loss 1.0683168990648617\n",
            "step 1954 - loss 1.2735333442687988 - moving ave loss 1.0888385435852554\n",
            "step 1955 - loss 0.9250128865242004 - moving ave loss 1.07245597787915\n",
            "step 1956 - loss 1.0266797542572021 - moving ave loss 1.0678783555169553\n",
            "step 1957 - loss 1.16121506690979 - moving ave loss 1.0772120266562388\n",
            "step 1958 - loss 0.9565758109092712 - moving ave loss 1.065148405081542\n",
            "step 1959 - loss 0.913412868976593 - moving ave loss 1.0499748514710472\n",
            "step 1960 - loss 0.8257110118865967 - moving ave loss 1.027548467512602\n",
            "step 1961 - loss 1.2363901138305664 - moving ave loss 1.0484326321443984\n",
            "step 1962 - loss 1.3662848472595215 - moving ave loss 1.0802178536559108\n",
            "step 1963 - loss 0.9134477972984314 - moving ave loss 1.063540848020163\n",
            "step 1964 - loss 0.8497142791748047 - moving ave loss 1.042158191135627\n",
            "step 1965 - loss 0.9186731576919556 - moving ave loss 1.02980968779126\n",
            "step 1966 - loss 1.038203239440918 - moving ave loss 1.0306490429562256\n",
            "step 1967 - loss 1.4609475135803223 - moving ave loss 1.0736788900186354\n",
            "step 1968 - loss 1.1582951545715332 - moving ave loss 1.082140516473925\n",
            "step 1969 - loss 1.1593270301818848 - moving ave loss 1.089859167844721\n",
            "step 1970 - loss 0.9424532055854797 - moving ave loss 1.0751185716187968\n",
            "step 1971 - loss 1.0225505828857422 - moving ave loss 1.0698617727454913\n",
            "step 1972 - loss 1.0683408975601196 - moving ave loss 1.0697096852269543\n",
            "step 1973 - loss 1.626593828201294 - moving ave loss 1.1253980995243884\n",
            "step 1974 - loss 0.9584274291992188 - moving ave loss 1.1087010324918714\n",
            "step 1975 - loss 1.1013424396514893 - moving ave loss 1.107965173207833\n",
            "step 1976 - loss 1.3159619569778442 - moving ave loss 1.128764851584834\n",
            "step 1977 - loss 1.4920063018798828 - moving ave loss 1.165088996614339\n",
            "step 1978 - loss 0.9775656461715698 - moving ave loss 1.146336661570062\n",
            "step 1979 - loss 0.9428044557571411 - moving ave loss 1.12598344098877\n",
            "step 1980 - loss 1.2607550621032715 - moving ave loss 1.1394606031002201\n",
            "step 1981 - loss 1.249643325805664 - moving ave loss 1.1504788753707647\n",
            "step 1982 - loss 1.1560235023498535 - moving ave loss 1.1510333380686737\n",
            "step 1983 - loss 1.1528040170669556 - moving ave loss 1.1512104059685018\n",
            "step 1984 - loss 0.9290177822113037 - moving ave loss 1.128991143592782\n",
            "step 1985 - loss 0.9519517421722412 - moving ave loss 1.111287203450728\n",
            "step 1986 - loss 1.0583446025848389 - moving ave loss 1.1059929433641391\n",
            "step 1987 - loss 1.0357639789581299 - moving ave loss 1.0989700469235382\n",
            "step 1988 - loss 1.2558093070983887 - moving ave loss 1.1146539729410232\n",
            "step 1989 - loss 0.9252488613128662 - moving ave loss 1.0957134617782076\n",
            "step 1990 - loss 1.0071616172790527 - moving ave loss 1.0868582773282922\n",
            "step 1991 - loss 0.8747724294662476 - moving ave loss 1.0656496925420877\n",
            "step 1992 - loss 0.9592632055282593 - moving ave loss 1.055011043840705\n",
            "step 1993 - loss 1.0435078144073486 - moving ave loss 1.0538607208973694\n",
            "step 1994 - loss 0.902589738368988 - moving ave loss 1.0387336226445312\n",
            "step 1995 - loss 1.0790752172470093 - moving ave loss 1.042767782104779\n",
            "step 1996 - loss 1.1889309883117676 - moving ave loss 1.0573841027254778\n",
            "step 1997 - loss 1.0641427040100098 - moving ave loss 1.0580599628539311\n",
            "step 1998 - loss 2.0034701824188232 - moving ave loss 1.1526009848104204\n",
            "step 1999 - loss 1.345775842666626 - moving ave loss 1.171918470596041\n",
            "step 2000 - loss 0.8934586048126221 - moving ave loss 1.1440724840176992\n",
            "Checkpoint at step 2000\n",
            "Finish 20 epoch(es)\n",
            "step 2001 - loss 1.022320032119751 - moving ave loss 1.1318972388279043\n",
            "step 2002 - loss 0.9652701616287231 - moving ave loss 1.1152345311079863\n",
            "step 2003 - loss 0.775115966796875 - moving ave loss 1.0812226746768752\n",
            "step 2004 - loss 1.3168067932128906 - moving ave loss 1.1047810865304768\n",
            "step 2005 - loss 1.5562341213226318 - moving ave loss 1.1499263900096923\n",
            "step 2006 - loss 1.0753780603408813 - moving ave loss 1.1424715570428112\n",
            "step 2007 - loss 0.8780012130737305 - moving ave loss 1.1160245226459033\n",
            "step 2008 - loss 1.5932422876358032 - moving ave loss 1.1637462991448935\n",
            "step 2009 - loss 0.9000606536865234 - moving ave loss 1.1373777345990566\n",
            "step 2010 - loss 1.1941845417022705 - moving ave loss 1.143058415309378\n",
            "step 2011 - loss 0.956640899181366 - moving ave loss 1.124416663696577\n",
            "step 2012 - loss 1.1310948133468628 - moving ave loss 1.1250844786616054\n",
            "step 2013 - loss 1.4115469455718994 - moving ave loss 1.153730725352635\n",
            "step 2014 - loss 0.9495084285736084 - moving ave loss 1.1333084956747324\n",
            "step 2015 - loss 0.91246497631073 - moving ave loss 1.1112241437383321\n",
            "step 2016 - loss 0.8734049201011658 - moving ave loss 1.0874422213746155\n",
            "step 2017 - loss 1.176085352897644 - moving ave loss 1.0963065345269185\n",
            "step 2018 - loss 1.0276533365249634 - moving ave loss 1.089441214726723\n",
            "step 2019 - loss 1.0969879627227783 - moving ave loss 1.0901958895263284\n",
            "step 2020 - loss 0.9623969197273254 - moving ave loss 1.0774159925464282\n",
            "step 2021 - loss 1.150197148323059 - moving ave loss 1.0846941081240913\n",
            "step 2022 - loss 1.160654067993164 - moving ave loss 1.0922901041109985\n",
            "step 2023 - loss 1.3109530210494995 - moving ave loss 1.1141563958048486\n",
            "step 2024 - loss 1.1083544492721558 - moving ave loss 1.1135762011515793\n",
            "step 2025 - loss 0.9216166734695435 - moving ave loss 1.0943802483833758\n",
            "step 2026 - loss 0.8350656032562256 - moving ave loss 1.068448783870661\n",
            "step 2027 - loss 0.7774121761322021 - moving ave loss 1.0393451230968151\n",
            "step 2028 - loss 1.220487117767334 - moving ave loss 1.057459322563867\n",
            "step 2029 - loss 0.8704645037651062 - moving ave loss 1.038759840683991\n",
            "step 2030 - loss 0.8111745119094849 - moving ave loss 1.0160013078065404\n",
            "step 2031 - loss 0.9860885143280029 - moving ave loss 1.0130100284586867\n",
            "step 2032 - loss 1.5485343933105469 - moving ave loss 1.0665624649438727\n",
            "step 2033 - loss 0.8925354480743408 - moving ave loss 1.0491597632569196\n",
            "step 2034 - loss 1.745044469833374 - moving ave loss 1.1187482339145651\n",
            "step 2035 - loss 0.7815221548080444 - moving ave loss 1.0850256260039133\n",
            "step 2036 - loss 1.1876163482666016 - moving ave loss 1.0952846982301823\n",
            "step 2037 - loss 1.105786681175232 - moving ave loss 1.0963348965246873\n",
            "step 2038 - loss 0.8418552279472351 - moving ave loss 1.070886929666942\n",
            "step 2039 - loss 0.8393904566764832 - moving ave loss 1.0477372823678963\n",
            "step 2040 - loss 1.092651128768921 - moving ave loss 1.0522286670079988\n",
            "step 2041 - loss 1.044081211090088 - moving ave loss 1.0514139214162077\n",
            "step 2042 - loss 0.7820925712585449 - moving ave loss 1.0244817864004414\n",
            "step 2043 - loss 1.07973313331604 - moving ave loss 1.0300069210920013\n",
            "step 2044 - loss 1.0506889820098877 - moving ave loss 1.03207512718379\n",
            "step 2045 - loss 1.2054297924041748 - moving ave loss 1.0494105937058285\n",
            "step 2046 - loss 1.0686638355255127 - moving ave loss 1.0513359178877968\n",
            "step 2047 - loss 0.8183209896087646 - moving ave loss 1.0280344250598936\n",
            "step 2048 - loss 0.8852358460426331 - moving ave loss 1.0137545671581676\n",
            "step 2049 - loss 0.8265001773834229 - moving ave loss 0.9950291281806931\n",
            "step 2050 - loss 0.8300974369049072 - moving ave loss 0.9785359590531145\n",
            "step 2051 - loss 0.9492164850234985 - moving ave loss 0.975604011650153\n",
            "step 2052 - loss 0.864747166633606 - moving ave loss 0.9645183271484983\n",
            "step 2053 - loss 1.1397783756256104 - moving ave loss 0.9820443319962096\n",
            "step 2054 - loss 0.9173794388771057 - moving ave loss 0.9755778426842993\n",
            "step 2055 - loss 0.9479357004165649 - moving ave loss 0.972813628457526\n",
            "step 2056 - loss 0.8831027746200562 - moving ave loss 0.9638425430737789\n",
            "step 2057 - loss 0.975597620010376 - moving ave loss 0.9650180507674386\n",
            "step 2058 - loss 0.7709721326828003 - moving ave loss 0.9456134589589748\n",
            "step 2059 - loss 1.2202105522155762 - moving ave loss 0.9730731682846349\n",
            "step 2060 - loss 0.9898350238800049 - moving ave loss 0.9747493538441718\n",
            "step 2061 - loss 0.9538770914077759 - moving ave loss 0.9726621276005323\n",
            "step 2062 - loss 1.0575900077819824 - moving ave loss 0.9811549156186773\n",
            "step 2063 - loss 1.230323314666748 - moving ave loss 1.0060717555234844\n",
            "step 2064 - loss 0.9342020750045776 - moving ave loss 0.9988847874715937\n",
            "step 2065 - loss 0.8523823618888855 - moving ave loss 0.984234544913323\n",
            "step 2066 - loss 1.3939324617385864 - moving ave loss 1.0252043365958494\n",
            "step 2067 - loss 0.9526458978652954 - moving ave loss 1.017948492722794\n",
            "step 2068 - loss 0.8526110649108887 - moving ave loss 1.0014147499416035\n",
            "step 2069 - loss 1.1987261772155762 - moving ave loss 1.0211458926690007\n",
            "step 2070 - loss 1.3048770427703857 - moving ave loss 1.0495190076791392\n",
            "step 2071 - loss 0.9615113139152527 - moving ave loss 1.0407182383027505\n",
            "step 2072 - loss 1.035476565361023 - moving ave loss 1.0401940710085777\n",
            "step 2073 - loss 1.159379482269287 - moving ave loss 1.0521126121346487\n",
            "step 2074 - loss 0.7640690803527832 - moving ave loss 1.0233082589564622\n",
            "step 2075 - loss 1.1596174240112305 - moving ave loss 1.036939175461939\n",
            "step 2076 - loss 1.204253911972046 - moving ave loss 1.0536706491129497\n",
            "step 2077 - loss 0.9985777139663696 - moving ave loss 1.0481613555982916\n",
            "step 2078 - loss 0.9917953014373779 - moving ave loss 1.0425247501822001\n",
            "step 2079 - loss 0.9340758919715881 - moving ave loss 1.031679864361139\n",
            "step 2080 - loss 0.9378443360328674 - moving ave loss 1.0222963115283117\n",
            "step 2081 - loss 1.1866472959518433 - moving ave loss 1.0387314099706648\n",
            "step 2082 - loss 0.9486848711967468 - moving ave loss 1.029726756093273\n",
            "step 2083 - loss 0.8168375492095947 - moving ave loss 1.008437835404905\n",
            "step 2084 - loss 1.1640079021453857 - moving ave loss 1.023994842078953\n",
            "step 2085 - loss 0.910041332244873 - moving ave loss 1.0125994910955451\n",
            "step 2086 - loss 1.1518642902374268 - moving ave loss 1.0265259710097334\n",
            "step 2087 - loss 0.9838262796401978 - moving ave loss 1.02225600187278\n",
            "step 2088 - loss 1.0442774295806885 - moving ave loss 1.0244581446435708\n",
            "step 2089 - loss 0.7667379379272461 - moving ave loss 0.9986861239719383\n",
            "step 2090 - loss 1.0770370960235596 - moving ave loss 1.0065212211771004\n",
            "step 2091 - loss 1.035726547241211 - moving ave loss 1.0094417537835114\n",
            "step 2092 - loss 0.9772603511810303 - moving ave loss 1.0062236135232634\n",
            "step 2093 - loss 0.9680300951004028 - moving ave loss 1.0024042616809774\n",
            "step 2094 - loss 1.0482797622680664 - moving ave loss 1.0069918117396863\n",
            "step 2095 - loss 1.0762522220611572 - moving ave loss 1.0139178527718335\n",
            "step 2096 - loss 0.9624437093734741 - moving ave loss 1.0087704384319978\n",
            "step 2097 - loss 0.9553981423377991 - moving ave loss 1.003433208822578\n",
            "step 2098 - loss 0.8175816535949707 - moving ave loss 0.9848480532998173\n",
            "step 2099 - loss 1.0523974895477295 - moving ave loss 0.9916029969246085\n",
            "step 2100 - loss 0.9807405471801758 - moving ave loss 0.9905167519501652\n",
            "Finish 21 epoch(es)\n",
            "step 2101 - loss 0.8222247362136841 - moving ave loss 0.9736875503765172\n",
            "step 2102 - loss 0.8646607398986816 - moving ave loss 0.9627848693287336\n",
            "step 2103 - loss 0.9282617568969727 - moving ave loss 0.9593325580855576\n",
            "step 2104 - loss 0.8041790723800659 - moving ave loss 0.9438172095150085\n",
            "step 2105 - loss 1.2475159168243408 - moving ave loss 0.9741870802459417\n",
            "step 2106 - loss 0.9619746208190918 - moving ave loss 0.9729658343032567\n",
            "step 2107 - loss 0.9412572979927063 - moving ave loss 0.9697949806722017\n",
            "step 2108 - loss 1.1955901384353638 - moving ave loss 0.9923744964485179\n",
            "step 2109 - loss 0.8778700232505798 - moving ave loss 0.9809240491287241\n",
            "step 2110 - loss 1.182774543762207 - moving ave loss 1.0011090985920723\n",
            "step 2111 - loss 0.7643262147903442 - moving ave loss 0.9774308102118995\n",
            "step 2112 - loss 0.9934282898902893 - moving ave loss 0.9790305581797385\n",
            "step 2113 - loss 1.038344144821167 - moving ave loss 0.9849619168438813\n",
            "step 2114 - loss 0.8194929957389832 - moving ave loss 0.9684150247333915\n",
            "step 2115 - loss 1.1754419803619385 - moving ave loss 0.9891177202962462\n",
            "step 2116 - loss 0.9067776203155518 - moving ave loss 0.9808837102981768\n",
            "step 2117 - loss 0.7625232338905334 - moving ave loss 0.9590476626574125\n",
            "step 2118 - loss 0.7657225131988525 - moving ave loss 0.9397151477115566\n",
            "step 2119 - loss 0.7688944339752197 - moving ave loss 0.922633076337923\n",
            "step 2120 - loss 0.8616933822631836 - moving ave loss 0.916539106930449\n",
            "step 2121 - loss 0.8791640996932983 - moving ave loss 0.912801606206734\n",
            "step 2122 - loss 0.87679523229599 - moving ave loss 0.9092009688156597\n",
            "step 2123 - loss 0.8344131708145142 - moving ave loss 0.9017221890155451\n",
            "step 2124 - loss 0.7104251384735107 - moving ave loss 0.8825924839613417\n",
            "step 2125 - loss 1.1709742546081543 - moving ave loss 0.911430661026023\n",
            "step 2126 - loss 0.9943395256996155 - moving ave loss 0.9197215474933823\n",
            "step 2127 - loss 0.8334911465644836 - moving ave loss 0.9110985074004925\n",
            "step 2128 - loss 0.9763302803039551 - moving ave loss 0.9176216846908388\n",
            "step 2129 - loss 0.7180427312850952 - moving ave loss 0.8976637893502645\n",
            "step 2130 - loss 1.0003318786621094 - moving ave loss 0.907930598281449\n",
            "step 2131 - loss 0.8173965215682983 - moving ave loss 0.8988771906101339\n",
            "step 2132 - loss 0.8975927829742432 - moving ave loss 0.898748749846545\n",
            "step 2133 - loss 0.9444662928581238 - moving ave loss 0.9033205041477028\n",
            "step 2134 - loss 0.7990399599075317 - moving ave loss 0.8928924497236858\n",
            "step 2135 - loss 1.370793342590332 - moving ave loss 0.9406825390103504\n",
            "step 2136 - loss 1.105170726776123 - moving ave loss 0.9571313577869277\n",
            "step 2137 - loss 0.9969180226325989 - moving ave loss 0.9611100242714948\n",
            "step 2138 - loss 0.8304356336593628 - moving ave loss 0.9480425852102817\n",
            "step 2139 - loss 0.9571473598480225 - moving ave loss 0.9489530626740559\n",
            "step 2140 - loss 0.7309370040893555 - moving ave loss 0.9271514568155859\n",
            "step 2141 - loss 0.7888303995132446 - moving ave loss 0.9133193510853518\n",
            "step 2142 - loss 0.8355181813240051 - moving ave loss 0.9055392341092171\n",
            "step 2143 - loss 0.9989091157913208 - moving ave loss 0.9148762222774275\n",
            "step 2144 - loss 2.230419874191284 - moving ave loss 1.0464305874688131\n",
            "step 2145 - loss 0.8208155632019043 - moving ave loss 1.0238690850421222\n",
            "step 2146 - loss 1.4603116512298584 - moving ave loss 1.0675133416608957\n",
            "step 2147 - loss 0.7945699691772461 - moving ave loss 1.0402190044125308\n",
            "step 2148 - loss 1.2574841976165771 - moving ave loss 1.0619455237329354\n",
            "step 2149 - loss 1.106351375579834 - moving ave loss 1.0663861089176252\n",
            "step 2150 - loss 1.041790246963501 - moving ave loss 1.0639265227222128\n",
            "step 2151 - loss 0.7083427906036377 - moving ave loss 1.0283681495103552\n",
            "step 2152 - loss 0.8086185455322266 - moving ave loss 1.0063931891125424\n",
            "step 2153 - loss 0.8800058960914612 - moving ave loss 0.9937544598104343\n",
            "step 2154 - loss 0.9145621061325073 - moving ave loss 0.9858352244426416\n",
            "step 2155 - loss 1.0178872346878052 - moving ave loss 0.989040425467158\n",
            "step 2156 - loss 1.3784559965133667 - moving ave loss 1.0279819825717789\n",
            "step 2157 - loss 0.7387923002243042 - moving ave loss 0.9990630143370315\n",
            "step 2158 - loss 0.9715192914009094 - moving ave loss 0.9963086420434193\n",
            "step 2159 - loss 0.8673168420791626 - moving ave loss 0.9834094620469938\n",
            "step 2160 - loss 0.9612780809402466 - moving ave loss 0.9811963239363191\n",
            "step 2161 - loss 1.2515358924865723 - moving ave loss 1.0082302807913444\n",
            "step 2162 - loss 1.076643705368042 - moving ave loss 1.015071623249014\n",
            "step 2163 - loss 0.8315489292144775 - moving ave loss 0.9967193538455603\n",
            "step 2164 - loss 0.9630621671676636 - moving ave loss 0.9933536351777708\n",
            "step 2165 - loss 1.061657428741455 - moving ave loss 1.0001840145341392\n",
            "step 2166 - loss 1.1338740587234497 - moving ave loss 1.0135530189530702\n",
            "step 2167 - loss 0.8265347480773926 - moving ave loss 0.9948511918655025\n",
            "step 2168 - loss 1.006664514541626 - moving ave loss 0.9960325241331149\n",
            "step 2169 - loss 0.7437752485275269 - moving ave loss 0.9708067965725562\n",
            "step 2170 - loss 0.9775320291519165 - moving ave loss 0.9714793198304922\n",
            "step 2171 - loss 0.8512051105499268 - moving ave loss 0.9594518989024357\n",
            "step 2172 - loss 0.8429195284843445 - moving ave loss 0.9477986618606266\n",
            "step 2173 - loss 0.8423036336898804 - moving ave loss 0.937249159043552\n",
            "step 2174 - loss 0.9715121984481812 - moving ave loss 0.9406754629840149\n",
            "step 2175 - loss 0.7124143838882446 - moving ave loss 0.9178493550744379\n",
            "step 2176 - loss 1.0683344602584839 - moving ave loss 0.9328978655928425\n",
            "step 2177 - loss 0.9226019382476807 - moving ave loss 0.9318682728583263\n",
            "step 2178 - loss 0.6716207265853882 - moving ave loss 0.9058435182310325\n",
            "step 2179 - loss 1.7805233001708984 - moving ave loss 0.9933114964250191\n",
            "step 2180 - loss 0.7116876840591431 - moving ave loss 0.9651491151884316\n",
            "step 2181 - loss 0.9723893404006958 - moving ave loss 0.965873137709658\n",
            "step 2182 - loss 0.9019087553024292 - moving ave loss 0.9594766994689352\n",
            "step 2183 - loss 1.1442444324493408 - moving ave loss 0.9779534727669758\n",
            "step 2184 - loss 1.1774914264678955 - moving ave loss 0.9979072681370678\n",
            "step 2185 - loss 0.9008843302726746 - moving ave loss 0.9882049743506285\n",
            "step 2186 - loss 0.8387355804443359 - moving ave loss 0.9732580349599993\n",
            "step 2187 - loss 0.6955963373184204 - moving ave loss 0.9454918651958414\n",
            "step 2188 - loss 0.9990421533584595 - moving ave loss 0.9508468940121032\n",
            "step 2189 - loss 0.9110007286071777 - moving ave loss 0.9468622774716107\n",
            "step 2190 - loss 0.7694275379180908 - moving ave loss 0.9291188035162588\n",
            "step 2191 - loss 0.9681063890457153 - moving ave loss 0.9330175620692044\n",
            "step 2192 - loss 0.8619394302368164 - moving ave loss 0.9259097488859657\n",
            "step 2193 - loss 1.009709119796753 - moving ave loss 0.9342896859770444\n",
            "step 2194 - loss 1.043717861175537 - moving ave loss 0.9452325034968937\n",
            "step 2195 - loss 0.663797914981842 - moving ave loss 0.9170890446453885\n",
            "step 2196 - loss 0.9871152639389038 - moving ave loss 0.9240916665747401\n",
            "step 2197 - loss 0.7525235414505005 - moving ave loss 0.9069348540623161\n",
            "step 2198 - loss 0.7145689725875854 - moving ave loss 0.8876982659148431\n",
            "step 2199 - loss 1.016359806060791 - moving ave loss 0.900564419929438\n",
            "step 2200 - loss 0.8527316451072693 - moving ave loss 0.8957811424472212\n",
            "Finish 22 epoch(es)\n",
            "step 2201 - loss 0.8329325318336487 - moving ave loss 0.889496281385864\n",
            "step 2202 - loss 0.7741782665252686 - moving ave loss 0.8779644798998044\n",
            "step 2203 - loss 0.7357102632522583 - moving ave loss 0.8637390582350498\n",
            "step 2204 - loss 1.1413755416870117 - moving ave loss 0.891502706580246\n",
            "step 2205 - loss 0.6938216686248779 - moving ave loss 0.8717346027847092\n",
            "step 2206 - loss 0.9677088856697083 - moving ave loss 0.881332031073209\n",
            "step 2207 - loss 1.0015883445739746 - moving ave loss 0.8933576624232856\n",
            "step 2208 - loss 0.8509429693222046 - moving ave loss 0.8891161931131776\n",
            "step 2209 - loss 0.9384687542915344 - moving ave loss 0.8940514492310133\n",
            "step 2210 - loss 0.7421913743019104 - moving ave loss 0.878865441738103\n",
            "step 2211 - loss 0.8358815908432007 - moving ave loss 0.8745670566486128\n",
            "step 2212 - loss 0.7088178396224976 - moving ave loss 0.8579921349460012\n",
            "step 2213 - loss 0.7452019453048706 - moving ave loss 0.8467131159818883\n",
            "step 2214 - loss 1.0221092700958252 - moving ave loss 0.864252731393282\n",
            "step 2215 - loss 1.4697896242141724 - moving ave loss 0.9248064206753711\n",
            "step 2216 - loss 1.339214563369751 - moving ave loss 0.966247234944809\n",
            "step 2217 - loss 1.1325914859771729 - moving ave loss 0.9828816600480454\n",
            "step 2218 - loss 1.0393022298812866 - moving ave loss 0.9885237170313697\n",
            "step 2219 - loss 0.948157787322998 - moving ave loss 0.9844871240605325\n",
            "step 2220 - loss 0.89693284034729 - moving ave loss 0.9757316956892083\n",
            "step 2221 - loss 0.851642906665802 - moving ave loss 0.9633228167868677\n",
            "step 2222 - loss 0.7881036996841431 - moving ave loss 0.9458009050765952\n",
            "step 2223 - loss 0.7230978012084961 - moving ave loss 0.9235305946897854\n",
            "step 2224 - loss 0.6927745342254639 - moving ave loss 0.9004549886433533\n",
            "step 2225 - loss 0.8719877004623413 - moving ave loss 0.897608259825252\n",
            "step 2226 - loss 1.9339814186096191 - moving ave loss 1.0012455757036887\n",
            "step 2227 - loss 0.768722414970398 - moving ave loss 0.9779932596303595\n",
            "step 2228 - loss 0.6720507144927979 - moving ave loss 0.9473990051166034\n",
            "step 2229 - loss 0.8716942071914673 - moving ave loss 0.9398285253240897\n",
            "step 2230 - loss 0.6931833028793335 - moving ave loss 0.9151640030796141\n",
            "step 2231 - loss 0.8883384466171265 - moving ave loss 0.9124814474333653\n",
            "step 2232 - loss 0.976622462272644 - moving ave loss 0.9188955489172932\n",
            "step 2233 - loss 0.705129086971283 - moving ave loss 0.8975189027226922\n",
            "step 2234 - loss 0.8488039970397949 - moving ave loss 0.8926474121544026\n",
            "step 2235 - loss 0.961654782295227 - moving ave loss 0.899548149168485\n",
            "step 2236 - loss 0.7123231887817383 - moving ave loss 0.8808256531298103\n",
            "step 2237 - loss 1.5464590787887573 - moving ave loss 0.9473889956957051\n",
            "step 2238 - loss 0.7876592874526978 - moving ave loss 0.9314160248714044\n",
            "step 2239 - loss 0.9988002777099609 - moving ave loss 0.9381544501552601\n",
            "step 2240 - loss 0.8081624507904053 - moving ave loss 0.9251552502187746\n",
            "step 2241 - loss 1.0514942407608032 - moving ave loss 0.9377891492729775\n",
            "step 2242 - loss 0.9115359783172607 - moving ave loss 0.9351638321774058\n",
            "step 2243 - loss 1.13643217086792 - moving ave loss 0.9552906660464573\n",
            "step 2244 - loss 0.966507077217102 - moving ave loss 0.9564123071635219\n",
            "step 2245 - loss 0.763130247592926 - moving ave loss 0.9370841012064622\n",
            "step 2246 - loss 0.7055710554122925 - moving ave loss 0.9139327966270453\n",
            "step 2247 - loss 1.4086298942565918 - moving ave loss 0.96340250639\n",
            "step 2248 - loss 0.6299794912338257 - moving ave loss 0.9300602048743826\n",
            "step 2249 - loss 0.6988590359687805 - moving ave loss 0.9069400879838224\n",
            "step 2250 - loss 0.8104011416435242 - moving ave loss 0.8972861933497926\n",
            "Checkpoint at step 2250\n",
            "step 2251 - loss 0.9907616376876831 - moving ave loss 0.9066337377835818\n",
            "step 2252 - loss 0.6694989204406738 - moving ave loss 0.882920256049291\n",
            "step 2253 - loss 0.744412899017334 - moving ave loss 0.8690695203460953\n",
            "step 2254 - loss 1.0310581922531128 - moving ave loss 0.885268387536797\n",
            "step 2255 - loss 1.0226795673370361 - moving ave loss 0.8990095055168209\n",
            "step 2256 - loss 0.7937818765640259 - moving ave loss 0.8884867426215414\n",
            "step 2257 - loss 0.673198401927948 - moving ave loss 0.866957908552182\n",
            "step 2258 - loss 0.7523212432861328 - moving ave loss 0.8554942420255771\n",
            "step 2259 - loss 0.7302521467208862 - moving ave loss 0.842970032495108\n",
            "step 2260 - loss 0.7968778610229492 - moving ave loss 0.8383608153478921\n",
            "step 2261 - loss 0.6580946445465088 - moving ave loss 0.8203341982677538\n",
            "step 2262 - loss 1.1702388525009155 - moving ave loss 0.85532466369107\n",
            "step 2263 - loss 0.8521563410758972 - moving ave loss 0.8550078314295527\n",
            "step 2264 - loss 1.0617098808288574 - moving ave loss 0.8756780363694832\n",
            "step 2265 - loss 0.835262656211853 - moving ave loss 0.8716364983537201\n",
            "step 2266 - loss 0.9234210252761841 - moving ave loss 0.8768149510459666\n",
            "step 2267 - loss 1.320704698562622 - moving ave loss 0.9212039257976322\n",
            "step 2268 - loss 1.0141164064407349 - moving ave loss 0.9304951738619425\n",
            "step 2269 - loss 1.0027519464492798 - moving ave loss 0.9377208511206762\n",
            "step 2270 - loss 1.1512126922607422 - moving ave loss 0.9590700352346828\n",
            "step 2271 - loss 0.8089103698730469 - moving ave loss 0.9440540686985193\n",
            "step 2272 - loss 1.1589994430541992 - moving ave loss 0.9655486061340873\n",
            "step 2273 - loss 0.6892422437667847 - moving ave loss 0.9379179698973571\n",
            "step 2274 - loss 0.7570258975028992 - moving ave loss 0.9198287626579114\n",
            "step 2275 - loss 0.7997950911521912 - moving ave loss 0.9078253955073393\n",
            "step 2276 - loss 0.737906813621521 - moving ave loss 0.8908335373187575\n",
            "step 2277 - loss 0.6897974014282227 - moving ave loss 0.870729923729704\n",
            "step 2278 - loss 1.087296962738037 - moving ave loss 0.8923866276305373\n",
            "step 2279 - loss 0.716206431388855 - moving ave loss 0.8747686080063691\n",
            "step 2280 - loss 0.8694337606430054 - moving ave loss 0.8742351232700328\n",
            "step 2281 - loss 0.7350768446922302 - moving ave loss 0.8603192954122526\n",
            "step 2282 - loss 1.2359013557434082 - moving ave loss 0.8978775014453682\n",
            "step 2283 - loss 0.7424237132072449 - moving ave loss 0.8823321226215559\n",
            "step 2284 - loss 0.778564453125 - moving ave loss 0.8719553556719004\n",
            "step 2285 - loss 1.1900649070739746 - moving ave loss 0.9037663108121078\n",
            "step 2286 - loss 0.8793169856071472 - moving ave loss 0.9013213782916117\n",
            "step 2287 - loss 0.9091372489929199 - moving ave loss 0.9021029653617425\n",
            "step 2288 - loss 0.6874706745147705 - moving ave loss 0.8806397362770454\n",
            "step 2289 - loss 0.9738677144050598 - moving ave loss 0.8899625340898468\n",
            "step 2290 - loss 0.9309558272361755 - moving ave loss 0.8940618634044797\n",
            "step 2291 - loss 1.048349380493164 - moving ave loss 0.9094906151133482\n",
            "step 2292 - loss 1.2607860565185547 - moving ave loss 0.9446201592538689\n",
            "step 2293 - loss 1.0845160484313965 - moving ave loss 0.9586097481716217\n",
            "step 2294 - loss 0.8237346410751343 - moving ave loss 0.945122237461973\n",
            "step 2295 - loss 1.0192896127700806 - moving ave loss 0.9525389749927837\n",
            "step 2296 - loss 0.674159586429596 - moving ave loss 0.9247010361364649\n",
            "step 2297 - loss 0.6411545872688293 - moving ave loss 0.8963463912497014\n",
            "step 2298 - loss 0.988088071346283 - moving ave loss 0.9055205592593596\n",
            "step 2299 - loss 0.7437448501586914 - moving ave loss 0.8893429883492928\n",
            "step 2300 - loss 0.8394668698310852 - moving ave loss 0.8843553764974721\n",
            "Finish 23 epoch(es)\n",
            "step 2301 - loss 0.8117719888687134 - moving ave loss 0.8770970377345962\n",
            "step 2302 - loss 0.9577171206474304 - moving ave loss 0.8851590460258796\n",
            "step 2303 - loss 0.9878073334693909 - moving ave loss 0.8954238747702308\n",
            "step 2304 - loss 0.7691528797149658 - moving ave loss 0.8827967752647043\n",
            "step 2305 - loss 0.6542646884918213 - moving ave loss 0.8599435665874161\n",
            "step 2306 - loss 1.031998634338379 - moving ave loss 0.8771490733625125\n",
            "step 2307 - loss 0.6577152013778687 - moving ave loss 0.8552056861640481\n",
            "step 2308 - loss 0.7293180227279663 - moving ave loss 0.84261691982044\n",
            "step 2309 - loss 0.7590957283973694 - moving ave loss 0.8342648006781329\n",
            "step 2310 - loss 0.7274221181869507 - moving ave loss 0.8235805324290147\n",
            "step 2311 - loss 0.6222658753395081 - moving ave loss 0.8034490667200641\n",
            "step 2312 - loss 0.9551923871040344 - moving ave loss 0.8186233987584611\n",
            "step 2313 - loss 0.6876375675201416 - moving ave loss 0.8055248156346292\n",
            "step 2314 - loss 1.1262168884277344 - moving ave loss 0.8375940229139397\n",
            "step 2315 - loss 0.8029955625534058 - moving ave loss 0.8341341768778863\n",
            "step 2316 - loss 0.8044467568397522 - moving ave loss 0.8311654348740729\n",
            "step 2317 - loss 0.8979204893112183 - moving ave loss 0.8378409403177874\n",
            "step 2318 - loss 0.6457635164260864 - moving ave loss 0.8186331979286173\n",
            "step 2319 - loss 1.0000286102294922 - moving ave loss 0.8367727391587048\n",
            "step 2320 - loss 0.8638205528259277 - moving ave loss 0.8394775205254271\n",
            "step 2321 - loss 0.898352861404419 - moving ave loss 0.8453650546133263\n",
            "step 2322 - loss 0.6783846616744995 - moving ave loss 0.8286670153194436\n",
            "step 2323 - loss 1.780824899673462 - moving ave loss 0.9238828037548455\n",
            "step 2324 - loss 0.6856896877288818 - moving ave loss 0.9000634921522492\n",
            "step 2325 - loss 0.7289379835128784 - moving ave loss 0.8829509412883122\n",
            "step 2326 - loss 0.7054460048675537 - moving ave loss 0.8652004476462364\n",
            "step 2327 - loss 0.8057752251625061 - moving ave loss 0.8592579253978634\n",
            "step 2328 - loss 0.6100289225578308 - moving ave loss 0.8343350251138602\n",
            "step 2329 - loss 1.0629664659500122 - moving ave loss 0.8571981691974754\n",
            "step 2330 - loss 0.7618653774261475 - moving ave loss 0.8476648900203426\n",
            "step 2331 - loss 1.083723545074463 - moving ave loss 0.8712707555257547\n",
            "step 2332 - loss 0.7309023141860962 - moving ave loss 0.8572339113917888\n",
            "step 2333 - loss 0.781122088432312 - moving ave loss 0.8496227290958412\n",
            "step 2334 - loss 1.0440689325332642 - moving ave loss 0.8690673494395835\n",
            "step 2335 - loss 0.6342620253562927 - moving ave loss 0.8455868170312545\n",
            "step 2336 - loss 0.9125419855117798 - moving ave loss 0.8522823338793071\n",
            "step 2337 - loss 0.9894777536392212 - moving ave loss 0.8660018758552985\n",
            "step 2338 - loss 1.068326711654663 - moving ave loss 0.8862343594352351\n",
            "step 2339 - loss 0.8264943361282349 - moving ave loss 0.8802603571045351\n",
            "step 2340 - loss 0.7205248475074768 - moving ave loss 0.8642868061448292\n",
            "step 2341 - loss 0.7978017330169678 - moving ave loss 0.857638298832043\n",
            "step 2342 - loss 0.7219113111495972 - moving ave loss 0.8440656000637984\n",
            "step 2343 - loss 0.9101594686508179 - moving ave loss 0.8506749869225003\n",
            "step 2344 - loss 0.7329973578453064 - moving ave loss 0.8389072240147809\n",
            "step 2345 - loss 0.7206408977508545 - moving ave loss 0.8270805913883883\n",
            "step 2346 - loss 0.6209377646446228 - moving ave loss 0.8064663087140117\n",
            "step 2347 - loss 1.51381516456604 - moving ave loss 0.8772011942992146\n",
            "step 2348 - loss 0.805587649345398 - moving ave loss 0.870039839803833\n",
            "step 2349 - loss 1.164987325668335 - moving ave loss 0.8995345883902832\n",
            "step 2350 - loss 0.7045235633850098 - moving ave loss 0.8800334858897559\n",
            "step 2351 - loss 0.5810517072677612 - moving ave loss 0.8501353080275564\n",
            "step 2352 - loss 0.8254810571670532 - moving ave loss 0.8476698829415061\n",
            "step 2353 - loss 0.8089826107025146 - moving ave loss 0.8438011557176069\n",
            "step 2354 - loss 0.956689715385437 - moving ave loss 0.8550900116843899\n",
            "step 2355 - loss 0.760566234588623 - moving ave loss 0.8456376339748133\n",
            "step 2356 - loss 0.7977482080459595 - moving ave loss 0.840848691381928\n",
            "step 2357 - loss 0.7448333501815796 - moving ave loss 0.8312471572618931\n",
            "step 2358 - loss 0.7225682735443115 - moving ave loss 0.820379268890135\n",
            "step 2359 - loss 0.8677599430084229 - moving ave loss 0.8251173363019638\n",
            "step 2360 - loss 0.6720148324966431 - moving ave loss 0.8098070859214318\n",
            "step 2361 - loss 1.0125219821929932 - moving ave loss 0.830078575548588\n",
            "step 2362 - loss 0.793571949005127 - moving ave loss 0.826427912894242\n",
            "step 2363 - loss 0.9413047432899475 - moving ave loss 0.8379155959338126\n",
            "step 2364 - loss 1.0345160961151123 - moving ave loss 0.8575756459519426\n",
            "step 2365 - loss 0.7988642454147339 - moving ave loss 0.8517045058982218\n",
            "step 2366 - loss 0.7576482892036438 - moving ave loss 0.842298884228764\n",
            "step 2367 - loss 0.8387686014175415 - moving ave loss 0.8419458559476418\n",
            "step 2368 - loss 0.8261107206344604 - moving ave loss 0.8403623424163238\n",
            "step 2369 - loss 0.9023618102073669 - moving ave loss 0.8465622891954282\n",
            "step 2370 - loss 0.6056569814682007 - moving ave loss 0.8224717584227055\n",
            "step 2371 - loss 0.7325030565261841 - moving ave loss 0.8134748882330534\n",
            "step 2372 - loss 0.8218216896057129 - moving ave loss 0.8143095683703193\n",
            "step 2373 - loss 0.7463962435722351 - moving ave loss 0.8075182358905109\n",
            "step 2374 - loss 0.9094692468643188 - moving ave loss 0.8177133369878917\n",
            "step 2375 - loss 1.028367280960083 - moving ave loss 0.8387787313851108\n",
            "step 2376 - loss 0.7561168670654297 - moving ave loss 0.8305125449531428\n",
            "step 2377 - loss 0.9014474153518677 - moving ave loss 0.8376060319930153\n",
            "step 2378 - loss 0.7344647645950317 - moving ave loss 0.8272919052532169\n",
            "step 2379 - loss 0.8969805240631104 - moving ave loss 0.8342607671342063\n",
            "step 2380 - loss 0.6846102476119995 - moving ave loss 0.8192957151819856\n",
            "step 2381 - loss 1.212576150894165 - moving ave loss 0.8586237587532035\n",
            "step 2382 - loss 0.7349297404289246 - moving ave loss 0.8462543569207757\n",
            "step 2383 - loss 1.2714812755584717 - moving ave loss 0.8887770487845452\n",
            "step 2384 - loss 0.6913356781005859 - moving ave loss 0.8690329117161494\n",
            "step 2385 - loss 0.6906659603118896 - moving ave loss 0.8511962165757234\n",
            "step 2386 - loss 0.7949619293212891 - moving ave loss 0.84557278785028\n",
            "step 2387 - loss 0.7735595107078552 - moving ave loss 0.8383714601360376\n",
            "step 2388 - loss 0.6470906734466553 - moving ave loss 0.8192433814670994\n",
            "step 2389 - loss 0.8546602725982666 - moving ave loss 0.8227850705802161\n",
            "step 2390 - loss 0.7761256694793701 - moving ave loss 0.8181191304701315\n",
            "step 2391 - loss 0.8090834617614746 - moving ave loss 0.8172155635992658\n",
            "step 2392 - loss 0.6896084547042847 - moving ave loss 0.8044548527097677\n",
            "step 2393 - loss 0.5930298566818237 - moving ave loss 0.7833123531069733\n",
            "step 2394 - loss 0.695238471031189 - moving ave loss 0.7745049648993949\n",
            "step 2395 - loss 0.673703670501709 - moving ave loss 0.7644248354596263\n",
            "step 2396 - loss 0.6290026903152466 - moving ave loss 0.7508826209451883\n",
            "step 2397 - loss 0.7453146576881409 - moving ave loss 0.7503258246194836\n",
            "step 2398 - loss 0.6001322865486145 - moving ave loss 0.7353064708123968\n",
            "step 2399 - loss 0.7112881541252136 - moving ave loss 0.7329046391436784\n",
            "step 2400 - loss 0.644844114780426 - moving ave loss 0.7240985867073533\n",
            "Finish 24 epoch(es)\n",
            "step 2401 - loss 0.8529459238052368 - moving ave loss 0.7369833204171417\n",
            "step 2402 - loss 0.7284221649169922 - moving ave loss 0.7361272048671267\n",
            "step 2403 - loss 0.6654176712036133 - moving ave loss 0.7290562515007754\n",
            "step 2404 - loss 0.6220978498458862 - moving ave loss 0.7183604113352865\n",
            "step 2405 - loss 0.7612192630767822 - moving ave loss 0.7226462965094361\n",
            "step 2406 - loss 0.9571917653083801 - moving ave loss 0.7461008433893306\n",
            "step 2407 - loss 0.7833510637283325 - moving ave loss 0.7498258654232308\n",
            "step 2408 - loss 1.0116283893585205 - moving ave loss 0.7760061178167599\n",
            "step 2409 - loss 0.958634078502655 - moving ave loss 0.7942689138853494\n",
            "step 2410 - loss 0.8416105508804321 - moving ave loss 0.7990030775848578\n",
            "step 2411 - loss 0.7486498951911926 - moving ave loss 0.7939677593454912\n",
            "step 2412 - loss 0.6151965856552124 - moving ave loss 0.7760906419764634\n",
            "step 2413 - loss 0.707177996635437 - moving ave loss 0.7691993774423608\n",
            "step 2414 - loss 0.7869205474853516 - moving ave loss 0.7709714944466598\n",
            "step 2415 - loss 0.5509531497955322 - moving ave loss 0.7489696599815471\n",
            "step 2416 - loss 0.7922857999801636 - moving ave loss 0.7533012739814088\n",
            "step 2417 - loss 0.6149251461029053 - moving ave loss 0.7394636611935584\n",
            "step 2418 - loss 0.5649045705795288 - moving ave loss 0.7220077521321555\n",
            "step 2419 - loss 0.9960324764251709 - moving ave loss 0.7494102245614571\n",
            "step 2420 - loss 0.8260350227355957 - moving ave loss 0.7570727043788711\n",
            "step 2421 - loss 0.8728441596031189 - moving ave loss 0.7686498499012959\n",
            "step 2422 - loss 0.8600199222564697 - moving ave loss 0.7777868571368133\n",
            "step 2423 - loss 0.6033817529678345 - moving ave loss 0.7603463467199154\n",
            "step 2424 - loss 0.7915656566619873 - moving ave loss 0.7634682777141226\n",
            "step 2425 - loss 0.654187023639679 - moving ave loss 0.7525401523066783\n",
            "step 2426 - loss 0.867795467376709 - moving ave loss 0.7640656838136815\n",
            "step 2427 - loss 0.6986962556838989 - moving ave loss 0.7575287410007032\n",
            "step 2428 - loss 0.5656915903091431 - moving ave loss 0.7383450259315473\n",
            "step 2429 - loss 1.3512821197509766 - moving ave loss 0.7996387353134902\n",
            "step 2430 - loss 0.7290024757385254 - moving ave loss 0.7925751093559936\n",
            "step 2431 - loss 0.6854044198989868 - moving ave loss 0.781858040410293\n",
            "step 2432 - loss 0.7012509107589722 - moving ave loss 0.773797327445161\n",
            "step 2433 - loss 0.6709175109863281 - moving ave loss 0.7635093457992779\n",
            "step 2434 - loss 0.869902491569519 - moving ave loss 0.7741486603763019\n",
            "step 2435 - loss 0.774937629699707 - moving ave loss 0.7742275573086425\n",
            "step 2436 - loss 0.9310562014579773 - moving ave loss 0.789910421723576\n",
            "step 2437 - loss 1.077675223350525 - moving ave loss 0.8186869018862709\n",
            "step 2438 - loss 0.8678985238075256 - moving ave loss 0.8236080640783964\n",
            "step 2439 - loss 0.8610053062438965 - moving ave loss 0.8273477882949465\n",
            "step 2440 - loss 0.5570271015167236 - moving ave loss 0.8003157196171242\n",
            "step 2441 - loss 0.5584778785705566 - moving ave loss 0.7761319355124675\n",
            "step 2442 - loss 0.8752771615982056 - moving ave loss 0.7860464581210413\n",
            "step 2443 - loss 1.0917757749557495 - moving ave loss 0.8166193898045122\n",
            "step 2444 - loss 0.708369791507721 - moving ave loss 0.8057944299748332\n",
            "step 2445 - loss 0.8237098455429077 - moving ave loss 0.8075859715316407\n",
            "step 2446 - loss 0.5376026630401611 - moving ave loss 0.7805876406824928\n",
            "step 2447 - loss 0.5730900168418884 - moving ave loss 0.7598378782984323\n",
            "step 2448 - loss 0.6956149339675903 - moving ave loss 0.7534155838653481\n",
            "step 2449 - loss 0.6638518571853638 - moving ave loss 0.7444592111973497\n",
            "step 2450 - loss 0.748366117477417 - moving ave loss 0.7448499018253565\n",
            "step 2451 - loss 0.6468714475631714 - moving ave loss 0.735052056399138\n",
            "step 2452 - loss 0.768904983997345 - moving ave loss 0.7384373491589586\n",
            "step 2453 - loss 0.7149804830551147 - moving ave loss 0.7360916625485743\n",
            "step 2454 - loss 0.608004093170166 - moving ave loss 0.7232829056107335\n",
            "step 2455 - loss 0.6627420783042908 - moving ave loss 0.7172288228800892\n",
            "step 2456 - loss 0.8287224173545837 - moving ave loss 0.7283781823275386\n",
            "step 2457 - loss 1.2566518783569336 - moving ave loss 0.7812055519304781\n",
            "step 2458 - loss 0.6372507214546204 - moving ave loss 0.7668100688828924\n",
            "step 2459 - loss 0.5906976461410522 - moving ave loss 0.7491988266087083\n",
            "step 2460 - loss 0.7564008831977844 - moving ave loss 0.7499190322676159\n",
            "step 2461 - loss 0.989056408405304 - moving ave loss 0.7738327698813848\n",
            "step 2462 - loss 0.636746346950531 - moving ave loss 0.7601241275882994\n",
            "step 2463 - loss 1.486358880996704 - moving ave loss 0.8327476029291399\n",
            "step 2464 - loss 0.7511318922042847 - moving ave loss 0.8245860318566545\n",
            "step 2465 - loss 1.0440946817398071 - moving ave loss 0.8465368968449698\n",
            "step 2466 - loss 0.6840962171554565 - moving ave loss 0.8302928288760185\n",
            "step 2467 - loss 0.9225543737411499 - moving ave loss 0.8395189833625317\n",
            "step 2468 - loss 1.1633245944976807 - moving ave loss 0.8718995444760467\n",
            "step 2469 - loss 0.6709110140800476 - moving ave loss 0.8518006914364468\n",
            "step 2470 - loss 0.7995409369468689 - moving ave loss 0.846574715987489\n",
            "step 2471 - loss 0.6367722749710083 - moving ave loss 0.8255944718858409\n",
            "step 2472 - loss 0.8694318532943726 - moving ave loss 0.829978210026694\n",
            "step 2473 - loss 0.8293296098709106 - moving ave loss 0.8299133500111158\n",
            "step 2474 - loss 0.7360018491744995 - moving ave loss 0.8205221999274541\n",
            "step 2475 - loss 0.7851887345314026 - moving ave loss 0.816988853387849\n",
            "step 2476 - loss 1.2823221683502197 - moving ave loss 0.863522184884086\n",
            "step 2477 - loss 0.8278077244758606 - moving ave loss 0.8599507388432636\n",
            "step 2478 - loss 0.5822718143463135 - moving ave loss 0.8321828463935685\n",
            "step 2479 - loss 0.9900436401367188 - moving ave loss 0.8479689257678835\n",
            "step 2480 - loss 0.7375251054763794 - moving ave loss 0.8369245437387332\n",
            "step 2481 - loss 0.6859555244445801 - moving ave loss 0.8218276418093179\n",
            "step 2482 - loss 0.7308582067489624 - moving ave loss 0.8127306983032824\n",
            "step 2483 - loss 0.7272078990936279 - moving ave loss 0.804178418382317\n",
            "step 2484 - loss 0.5303311347961426 - moving ave loss 0.7767936900236996\n",
            "step 2485 - loss 0.8034379482269287 - moving ave loss 0.7794581158440226\n",
            "step 2486 - loss 0.6755812168121338 - moving ave loss 0.7690704259408336\n",
            "step 2487 - loss 1.1890769004821777 - moving ave loss 0.8110710733949681\n",
            "step 2488 - loss 0.815177857875824 - moving ave loss 0.8114817518430537\n",
            "step 2489 - loss 0.7601725459098816 - moving ave loss 0.8063508312497365\n",
            "step 2490 - loss 0.6264199018478394 - moving ave loss 0.7883577383095468\n",
            "step 2491 - loss 1.226203203201294 - moving ave loss 0.8321422847987215\n",
            "step 2492 - loss 0.7247421741485596 - moving ave loss 0.8214022737337053\n",
            "step 2493 - loss 0.6745618581771851 - moving ave loss 0.8067182321780533\n",
            "step 2494 - loss 0.6946216225624084 - moving ave loss 0.7955085712164888\n",
            "step 2495 - loss 0.9531960487365723 - moving ave loss 0.8112773189684971\n",
            "step 2496 - loss 0.6464264392852783 - moving ave loss 0.7947922310001752\n",
            "step 2497 - loss 0.6996425986289978 - moving ave loss 0.7852772677630574\n",
            "step 2498 - loss 0.49677765369415283 - moving ave loss 0.756427306356167\n",
            "step 2499 - loss 0.7810011506080627 - moving ave loss 0.7588846907813566\n",
            "step 2500 - loss 1.368110179901123 - moving ave loss 0.8198072396933332\n",
            "Checkpoint at step 2500\n",
            "Finish 25 epoch(es)\n",
            "step 2501 - loss 0.8067797422409058 - moving ave loss 0.8185044899480906\n",
            "step 2502 - loss 0.8849076628684998 - moving ave loss 0.8251448072401315\n",
            "step 2503 - loss 0.5756202340126038 - moving ave loss 0.8001923499173788\n",
            "step 2504 - loss 0.6528719663619995 - moving ave loss 0.7854603115618408\n",
            "step 2505 - loss 0.7050266265869141 - moving ave loss 0.7774169430643482\n",
            "step 2506 - loss 0.8620847463607788 - moving ave loss 0.7858837233939913\n",
            "step 2507 - loss 0.8524109125137329 - moving ave loss 0.7925364423059655\n",
            "step 2508 - loss 1.0491015911102295 - moving ave loss 0.818192957186392\n",
            "step 2509 - loss 0.650234580039978 - moving ave loss 0.8013971194717505\n",
            "step 2510 - loss 0.6854363679885864 - moving ave loss 0.7898010443234341\n",
            "step 2511 - loss 0.8210697770118713 - moving ave loss 0.7929279175922779\n",
            "step 2512 - loss 0.7363067865371704 - moving ave loss 0.7872658044867672\n",
            "step 2513 - loss 0.8061832785606384 - moving ave loss 0.7891575518941543\n",
            "step 2514 - loss 0.5491092205047607 - moving ave loss 0.765152718755215\n",
            "step 2515 - loss 0.5581900477409363 - moving ave loss 0.7444564516537872\n",
            "step 2516 - loss 0.7529364824295044 - moving ave loss 0.745304454731359\n",
            "step 2517 - loss 0.5650526881217957 - moving ave loss 0.7272792780704026\n",
            "step 2518 - loss 0.7015863656997681 - moving ave loss 0.7247099868333391\n",
            "step 2519 - loss 0.9719746708869934 - moving ave loss 0.7494364552387046\n",
            "step 2520 - loss 0.6594480276107788 - moving ave loss 0.740437612475912\n",
            "step 2521 - loss 0.9737536311149597 - moving ave loss 0.7637692143398168\n",
            "step 2522 - loss 0.8292745351791382 - moving ave loss 0.770319746423749\n",
            "step 2523 - loss 0.8650240898132324 - moving ave loss 0.7797901807626973\n",
            "step 2524 - loss 0.7907001376152039 - moving ave loss 0.780881176447948\n",
            "step 2525 - loss 0.7432950139045715 - moving ave loss 0.7771225601936104\n",
            "step 2526 - loss 0.558940589427948 - moving ave loss 0.7553043631170441\n",
            "step 2527 - loss 0.727668046951294 - moving ave loss 0.7525407315004691\n",
            "step 2528 - loss 0.5925683975219727 - moving ave loss 0.7365434981026195\n",
            "step 2529 - loss 0.6792861223220825 - moving ave loss 0.7308177605245658\n",
            "step 2530 - loss 0.4967566132545471 - moving ave loss 0.707411645797564\n",
            "step 2531 - loss 0.5375209450721741 - moving ave loss 0.690422575725025\n",
            "step 2532 - loss 0.7723095417022705 - moving ave loss 0.6986112723227496\n",
            "step 2533 - loss 0.6117643117904663 - moving ave loss 0.6899265762695213\n",
            "step 2534 - loss 0.7918413877487183 - moving ave loss 0.700118057417441\n",
            "step 2535 - loss 0.7273101806640625 - moving ave loss 0.7028372697421033\n",
            "step 2536 - loss 0.7081551551818848 - moving ave loss 0.7033690582860814\n",
            "step 2537 - loss 0.8153719902038574 - moving ave loss 0.714569351477859\n",
            "step 2538 - loss 0.9100265502929688 - moving ave loss 0.73411507135937\n",
            "step 2539 - loss 0.7136237025260925 - moving ave loss 0.7320659344760423\n",
            "step 2540 - loss 0.7274177074432373 - moving ave loss 0.7316011117727619\n",
            "step 2541 - loss 0.5454459190368652 - moving ave loss 0.7129855924991723\n",
            "step 2542 - loss 0.4864312708377838 - moving ave loss 0.6903301603330334\n",
            "step 2543 - loss 0.6256133317947388 - moving ave loss 0.6838584774792039\n",
            "step 2544 - loss 1.1285829544067383 - moving ave loss 0.7283309251719574\n",
            "step 2545 - loss 1.482886552810669 - moving ave loss 0.8037864879358286\n",
            "step 2546 - loss 0.8287700414657593 - moving ave loss 0.8062848432888218\n",
            "step 2547 - loss 0.8348129391670227 - moving ave loss 0.8091376528766419\n",
            "step 2548 - loss 0.8198336362838745 - moving ave loss 0.8102072512173651\n",
            "step 2549 - loss 0.567130446434021 - moving ave loss 0.7858995707390307\n",
            "step 2550 - loss 0.587419867515564 - moving ave loss 0.7660516004166841\n",
            "step 2551 - loss 0.6038271188735962 - moving ave loss 0.7498291522623753\n",
            "step 2552 - loss 0.5782842040061951 - moving ave loss 0.7326746574367573\n",
            "step 2553 - loss 0.9912980794906616 - moving ave loss 0.7585369996421478\n",
            "step 2554 - loss 1.597604751586914 - moving ave loss 0.8424437748366245\n",
            "step 2555 - loss 0.7754988670349121 - moving ave loss 0.8357492840564533\n",
            "step 2556 - loss 0.690214991569519 - moving ave loss 0.8211958548077599\n",
            "step 2557 - loss 0.7922937273979187 - moving ave loss 0.8183056420667758\n",
            "step 2558 - loss 1.2157913446426392 - moving ave loss 0.8580542123243622\n",
            "step 2559 - loss 0.6650791168212891 - moving ave loss 0.8387567027740549\n",
            "step 2560 - loss 0.8173344135284424 - moving ave loss 0.8366144738494936\n",
            "step 2561 - loss 0.5779972672462463 - moving ave loss 0.810752753189169\n",
            "step 2562 - loss 0.7813938856124878 - moving ave loss 0.8078168664315009\n",
            "step 2563 - loss 0.7017245292663574 - moving ave loss 0.7972076327149865\n",
            "step 2564 - loss 0.6443371772766113 - moving ave loss 0.781920587171149\n",
            "step 2565 - loss 0.7286238670349121 - moving ave loss 0.7765909151575253\n",
            "step 2566 - loss 0.7057052254676819 - moving ave loss 0.769502346188541\n",
            "step 2567 - loss 0.7407968044281006 - moving ave loss 0.766631792012497\n",
            "step 2568 - loss 0.6157194375991821 - moving ave loss 0.7515405565711656\n",
            "step 2569 - loss 0.991728663444519 - moving ave loss 0.7755593672585009\n",
            "step 2570 - loss 0.5293045043945312 - moving ave loss 0.750933880972104\n",
            "step 2571 - loss 1.023258924484253 - moving ave loss 0.7781663853233189\n",
            "step 2572 - loss 0.4970936179161072 - moving ave loss 0.7500591085825977\n",
            "step 2573 - loss 1.0779716968536377 - moving ave loss 0.7828503674097017\n",
            "step 2574 - loss 0.8552930951118469 - moving ave loss 0.7900946401799163\n",
            "step 2575 - loss 0.8188188076019287 - moving ave loss 0.7929670569221176\n",
            "step 2576 - loss 0.9592157602310181 - moving ave loss 0.8095919272530077\n",
            "step 2577 - loss 0.8474075794219971 - moving ave loss 0.8133734924699066\n",
            "step 2578 - loss 0.657349705696106 - moving ave loss 0.7977711137925266\n",
            "step 2579 - loss 0.5107029676437378 - moving ave loss 0.7690642991776477\n",
            "step 2580 - loss 0.6595132946968079 - moving ave loss 0.7581091987295637\n",
            "step 2581 - loss 0.564248263835907 - moving ave loss 0.738723105240198\n",
            "step 2582 - loss 0.670539140701294 - moving ave loss 0.7319047087863076\n",
            "step 2583 - loss 0.520269513130188 - moving ave loss 0.7107411892206957\n",
            "step 2584 - loss 0.8147913813591003 - moving ave loss 0.7211462084345361\n",
            "step 2585 - loss 0.8204870820045471 - moving ave loss 0.7310802957915373\n",
            "step 2586 - loss 0.6078741550445557 - moving ave loss 0.7187596817168391\n",
            "step 2587 - loss 0.5381664633750916 - moving ave loss 0.7007003598826644\n",
            "step 2588 - loss 0.7178163528442383 - moving ave loss 0.7024119591788218\n",
            "step 2589 - loss 1.023673415184021 - moving ave loss 0.7345381047793418\n",
            "step 2590 - loss 0.5117765665054321 - moving ave loss 0.7122619509519508\n",
            "step 2591 - loss 0.7083501815795898 - moving ave loss 0.7118707740147148\n",
            "step 2592 - loss 0.5718111395835876 - moving ave loss 0.6978648105716021\n",
            "step 2593 - loss 0.7109732031822205 - moving ave loss 0.6991756498326639\n",
            "step 2594 - loss 0.7380403876304626 - moving ave loss 0.7030621236124438\n",
            "step 2595 - loss 0.8857501745223999 - moving ave loss 0.7213309287034395\n",
            "step 2596 - loss 0.6254755258560181 - moving ave loss 0.7117453884186974\n",
            "step 2597 - loss 0.7169406414031982 - moving ave loss 0.7122649137171475\n",
            "step 2598 - loss 0.5171768665313721 - moving ave loss 0.69275610899857\n",
            "step 2599 - loss 0.5758075714111328 - moving ave loss 0.6810612552398263\n",
            "step 2600 - loss 0.8216473460197449 - moving ave loss 0.6951198643178181\n",
            "Finish 26 epoch(es)\n",
            "step 2601 - loss 0.6355095505714417 - moving ave loss 0.6891588329431805\n",
            "step 2602 - loss 1.0068403482437134 - moving ave loss 0.7209269844732338\n",
            "step 2603 - loss 0.625231146812439 - moving ave loss 0.7113574007071544\n",
            "step 2604 - loss 0.6440833806991577 - moving ave loss 0.7046299987063547\n",
            "step 2605 - loss 0.818763256072998 - moving ave loss 0.7160433244430191\n",
            "step 2606 - loss 0.6366305947303772 - moving ave loss 0.708102051471755\n",
            "step 2607 - loss 0.5240967869758606 - moving ave loss 0.6897015250221655\n",
            "step 2608 - loss 0.6067016124725342 - moving ave loss 0.6814015337672025\n",
            "step 2609 - loss 0.447647362947464 - moving ave loss 0.6580261166852287\n",
            "step 2610 - loss 0.6385143399238586 - moving ave loss 0.6560749390090918\n",
            "step 2611 - loss 0.6667780876159668 - moving ave loss 0.6571452538697793\n",
            "step 2612 - loss 0.6272368431091309 - moving ave loss 0.6541544127937146\n",
            "step 2613 - loss 0.7435986995697021 - moving ave loss 0.6630988414713133\n",
            "step 2614 - loss 0.48919564485549927 - moving ave loss 0.6457085218097318\n",
            "step 2615 - loss 0.7031042575836182 - moving ave loss 0.6514480953871205\n",
            "step 2616 - loss 0.8882145881652832 - moving ave loss 0.6751247446649368\n",
            "step 2617 - loss 0.7078295946121216 - moving ave loss 0.6783952296596553\n",
            "step 2618 - loss 0.7127771377563477 - moving ave loss 0.6818334204693245\n",
            "step 2619 - loss 0.6630206108093262 - moving ave loss 0.6799521395033247\n",
            "step 2620 - loss 0.5812803506851196 - moving ave loss 0.6700849606215041\n",
            "step 2621 - loss 0.6639502048492432 - moving ave loss 0.669471485044278\n",
            "step 2622 - loss 0.5107432007789612 - moving ave loss 0.6535986566177464\n",
            "step 2623 - loss 0.8680335879325867 - moving ave loss 0.6750421497492305\n",
            "step 2624 - loss 0.588919460773468 - moving ave loss 0.6664298808516543\n",
            "step 2625 - loss 0.4718029499053955 - moving ave loss 0.6469671877570284\n",
            "step 2626 - loss 0.49154186248779297 - moving ave loss 0.6314246552301049\n",
            "step 2627 - loss 1.1906393766403198 - moving ave loss 0.6873461273711264\n",
            "step 2628 - loss 0.6777074337005615 - moving ave loss 0.6863822580040699\n",
            "step 2629 - loss 0.5084236860275269 - moving ave loss 0.6685864008064156\n",
            "step 2630 - loss 0.7926242351531982 - moving ave loss 0.6809901842410939\n",
            "step 2631 - loss 0.8816964626312256 - moving ave loss 0.7010608120801072\n",
            "step 2632 - loss 0.631053626537323 - moving ave loss 0.6940600935258289\n",
            "step 2633 - loss 0.5322588086128235 - moving ave loss 0.6778799650345283\n",
            "step 2634 - loss 0.5832059383392334 - moving ave loss 0.6684125623649988\n",
            "step 2635 - loss 0.6157293319702148 - moving ave loss 0.6631442393255205\n",
            "step 2636 - loss 0.6546139717102051 - moving ave loss 0.6622912125639889\n",
            "step 2637 - loss 1.1261416673660278 - moving ave loss 0.7086762580441928\n",
            "step 2638 - loss 0.9353623986244202 - moving ave loss 0.7313448721022155\n",
            "step 2639 - loss 0.6259831190109253 - moving ave loss 0.7208086967930866\n",
            "step 2640 - loss 0.6380804777145386 - moving ave loss 0.7125358748852318\n",
            "step 2641 - loss 0.5845398306846619 - moving ave loss 0.6997362704651748\n",
            "step 2642 - loss 0.5795450210571289 - moving ave loss 0.6877171455243702\n",
            "step 2643 - loss 0.613846480846405 - moving ave loss 0.6803300790565737\n",
            "step 2644 - loss 0.48948732018470764 - moving ave loss 0.6612458031693871\n",
            "step 2645 - loss 0.5477603077888489 - moving ave loss 0.6498972536313333\n",
            "step 2646 - loss 0.5767586827278137 - moving ave loss 0.6425833965409814\n",
            "step 2647 - loss 0.526883602142334 - moving ave loss 0.6310134171011167\n",
            "step 2648 - loss 0.714735209941864 - moving ave loss 0.6393855963851914\n",
            "step 2649 - loss 0.7542974948883057 - moving ave loss 0.6508767862355029\n",
            "step 2650 - loss 0.7339898943901062 - moving ave loss 0.6591880970509633\n",
            "step 2651 - loss 0.4921797215938568 - moving ave loss 0.6424872595052527\n",
            "step 2652 - loss 0.7145466208457947 - moving ave loss 0.6496931956393069\n",
            "step 2653 - loss 0.46182340383529663 - moving ave loss 0.6309062164589059\n",
            "step 2654 - loss 0.9269882440567017 - moving ave loss 0.6605144192186856\n",
            "step 2655 - loss 0.6679337024688721 - moving ave loss 0.6612563475437043\n",
            "step 2656 - loss 0.6446548700332642 - moving ave loss 0.6595961997926604\n",
            "step 2657 - loss 0.6529021263122559 - moving ave loss 0.6589267924446199\n",
            "step 2658 - loss 0.5810554027557373 - moving ave loss 0.6511396534757317\n",
            "step 2659 - loss 0.4697840213775635 - moving ave loss 0.6330040902659149\n",
            "step 2660 - loss 0.7704247236251831 - moving ave loss 0.6467461536018417\n",
            "step 2661 - loss 0.4632967710494995 - moving ave loss 0.6284012153466075\n",
            "step 2662 - loss 0.6900502443313599 - moving ave loss 0.6345661182450827\n",
            "step 2663 - loss 0.80135178565979 - moving ave loss 0.6512446849865534\n",
            "step 2664 - loss 0.6023493409156799 - moving ave loss 0.6463551505794661\n",
            "step 2665 - loss 0.7487870454788208 - moving ave loss 0.6565983400694015\n",
            "step 2666 - loss 0.6116011142730713 - moving ave loss 0.6520986174897686\n",
            "step 2667 - loss 0.49345284700393677 - moving ave loss 0.6362340404411855\n",
            "step 2668 - loss 0.9179770946502686 - moving ave loss 0.6644083458620939\n",
            "step 2669 - loss 0.5590418577194214 - moving ave loss 0.6538716970478265\n",
            "step 2670 - loss 0.6500070095062256 - moving ave loss 0.6534852282936665\n",
            "step 2671 - loss 0.8695338368415833 - moving ave loss 0.6750900891484581\n",
            "step 2672 - loss 0.5832489728927612 - moving ave loss 0.6659059775228885\n",
            "step 2673 - loss 1.0233278274536133 - moving ave loss 0.701648162515961\n",
            "step 2674 - loss 0.6221861839294434 - moving ave loss 0.6937019646573092\n",
            "step 2675 - loss 0.41713353991508484 - moving ave loss 0.6660451221830866\n",
            "step 2676 - loss 0.7823238372802734 - moving ave loss 0.6776729936928053\n",
            "step 2677 - loss 0.5647714734077454 - moving ave loss 0.6663828416642994\n",
            "step 2678 - loss 0.6676816940307617 - moving ave loss 0.6665127269009457\n",
            "step 2679 - loss 0.6274843215942383 - moving ave loss 0.662609886370275\n",
            "step 2680 - loss 0.8159703016281128 - moving ave loss 0.6779459278960588\n",
            "step 2681 - loss 0.8546236753463745 - moving ave loss 0.6956137026410903\n",
            "step 2682 - loss 0.5845874547958374 - moving ave loss 0.6845110778565651\n",
            "step 2683 - loss 0.7711890339851379 - moving ave loss 0.6931788734694224\n",
            "step 2684 - loss 0.5975695252418518 - moving ave loss 0.6836179386466654\n",
            "step 2685 - loss 0.6535772085189819 - moving ave loss 0.680613865633897\n",
            "step 2686 - loss 0.5864866375923157 - moving ave loss 0.671201142829739\n",
            "step 2687 - loss 0.6841676235198975 - moving ave loss 0.6724977908987548\n",
            "step 2688 - loss 1.0830700397491455 - moving ave loss 0.7135550157837939\n",
            "step 2689 - loss 0.7154844999313354 - moving ave loss 0.7137479641985481\n",
            "step 2690 - loss 0.5464671850204468 - moving ave loss 0.6970198862807381\n",
            "step 2691 - loss 0.6412399411201477 - moving ave loss 0.6914418917646791\n",
            "step 2692 - loss 0.5813075304031372 - moving ave loss 0.6804284556285248\n",
            "step 2693 - loss 0.4982951581478119 - moving ave loss 0.6622151258804536\n",
            "step 2694 - loss 0.6275897026062012 - moving ave loss 0.6587525835530285\n",
            "step 2695 - loss 0.6749338507652283 - moving ave loss 0.6603707102742484\n",
            "step 2696 - loss 0.8177506327629089 - moving ave loss 0.6761087025231145\n",
            "step 2697 - loss 0.8011775016784668 - moving ave loss 0.6886155824386498\n",
            "step 2698 - loss 0.530895471572876 - moving ave loss 0.6728435713520725\n",
            "step 2699 - loss 0.690894365310669 - moving ave loss 0.6746486507479322\n",
            "step 2700 - loss 0.6102429628372192 - moving ave loss 0.668208081956861\n",
            "Finish 27 epoch(es)\n",
            "step 2701 - loss 0.6481708288192749 - moving ave loss 0.6662043566431024\n",
            "step 2702 - loss 0.6485460996627808 - moving ave loss 0.6644385309450703\n",
            "step 2703 - loss 1.239885926246643 - moving ave loss 0.7219832704752276\n",
            "step 2704 - loss 0.49272745847702026 - moving ave loss 0.6990576892754069\n",
            "step 2705 - loss 0.6106750965118408 - moving ave loss 0.6902194299990504\n",
            "step 2706 - loss 0.5971694588661194 - moving ave loss 0.6809144328857573\n",
            "step 2707 - loss 0.8112037777900696 - moving ave loss 0.6939433673761884\n",
            "step 2708 - loss 0.5747071504592896 - moving ave loss 0.6820197456844985\n",
            "step 2709 - loss 0.4933207631111145 - moving ave loss 0.6631498474271602\n",
            "step 2710 - loss 0.7704262733459473 - moving ave loss 0.673877490019039\n",
            "step 2711 - loss 0.7614516019821167 - moving ave loss 0.6826349012153468\n",
            "step 2712 - loss 0.8173762559890747 - moving ave loss 0.6961090366927196\n",
            "step 2713 - loss 0.9083442687988281 - moving ave loss 0.7173325599033306\n",
            "step 2714 - loss 0.8357363939285278 - moving ave loss 0.7291729433058503\n",
            "step 2715 - loss 0.4470231533050537 - moving ave loss 0.7009579643057706\n",
            "step 2716 - loss 0.8395406007766724 - moving ave loss 0.7148162279528608\n",
            "step 2717 - loss 0.8649822473526001 - moving ave loss 0.7298328298928348\n",
            "step 2718 - loss 0.6511455178260803 - moving ave loss 0.7219640986861594\n",
            "step 2719 - loss 0.6887246370315552 - moving ave loss 0.7186401525206989\n",
            "step 2720 - loss 0.7726013660430908 - moving ave loss 0.7240362738729381\n",
            "step 2721 - loss 0.789830207824707 - moving ave loss 0.730615667268115\n",
            "step 2722 - loss 0.444557785987854 - moving ave loss 0.7020098791400888\n",
            "step 2723 - loss 0.5770946741104126 - moving ave loss 0.6895183586371212\n",
            "step 2724 - loss 0.9135419726371765 - moving ave loss 0.7119207200371267\n",
            "step 2725 - loss 0.6393358707427979 - moving ave loss 0.7046622351076938\n",
            "step 2726 - loss 0.530748724937439 - moving ave loss 0.6872708840906683\n",
            "step 2727 - loss 1.5975478887557983 - moving ave loss 0.7782985845571813\n",
            "step 2728 - loss 0.5556250810623169 - moving ave loss 0.7560312342076948\n",
            "step 2729 - loss 0.7714923024177551 - moving ave loss 0.7575773410287009\n",
            "step 2730 - loss 0.7040122747421265 - moving ave loss 0.7522208344000434\n",
            "step 2731 - loss 0.7051047086715698 - moving ave loss 0.747509221827196\n",
            "step 2732 - loss 0.6712824106216431 - moving ave loss 0.7398865407066407\n",
            "step 2733 - loss 0.7697880864143372 - moving ave loss 0.7428766952774104\n",
            "step 2734 - loss 0.5469756126403809 - moving ave loss 0.7232865870137075\n",
            "step 2735 - loss 0.4694822430610657 - moving ave loss 0.6979061526184434\n",
            "step 2736 - loss 0.7246185541152954 - moving ave loss 0.7005773927681286\n",
            "step 2737 - loss 0.703621506690979 - moving ave loss 0.7008818041604137\n",
            "step 2738 - loss 0.5112965703010559 - moving ave loss 0.681923280774478\n",
            "step 2739 - loss 0.4628840386867523 - moving ave loss 0.6600193565657054\n",
            "step 2740 - loss 0.787675142288208 - moving ave loss 0.6727849351379557\n",
            "step 2741 - loss 0.7952324151992798 - moving ave loss 0.6850296831440881\n",
            "step 2742 - loss 0.8127800226211548 - moving ave loss 0.6978047170917947\n",
            "step 2743 - loss 0.4084526300430298 - moving ave loss 0.6688695083869183\n",
            "step 2744 - loss 1.0586795806884766 - moving ave loss 0.7078505156170741\n",
            "step 2745 - loss 0.680759847164154 - moving ave loss 0.7051414487717821\n",
            "step 2746 - loss 0.47528600692749023 - moving ave loss 0.6821559045873529\n",
            "step 2747 - loss 0.5686761140823364 - moving ave loss 0.6708079255368512\n",
            "step 2748 - loss 0.7384623885154724 - moving ave loss 0.6775733718347133\n",
            "step 2749 - loss 0.6637982130050659 - moving ave loss 0.6761958559517486\n",
            "step 2750 - loss 0.8826466798782349 - moving ave loss 0.6968409383443972\n",
            "Checkpoint at step 2750\n",
            "step 2751 - loss 0.5534236431121826 - moving ave loss 0.6824992088211758\n",
            "step 2752 - loss 0.7925586700439453 - moving ave loss 0.6935051549434528\n",
            "step 2753 - loss 0.6376475691795349 - moving ave loss 0.687919396367061\n",
            "step 2754 - loss 0.5413042306900024 - moving ave loss 0.6732578797993553\n",
            "step 2755 - loss 0.8878804445266724 - moving ave loss 0.694720136272087\n",
            "step 2756 - loss 0.4906277358531952 - moving ave loss 0.6743108962301978\n",
            "step 2757 - loss 1.0064572095870972 - moving ave loss 0.7075255275658877\n",
            "step 2758 - loss 0.7733461260795593 - moving ave loss 0.7141075874172549\n",
            "step 2759 - loss 0.7273451089859009 - moving ave loss 0.7154313395741195\n",
            "step 2760 - loss 0.8137823939323425 - moving ave loss 0.7252664450099419\n",
            "step 2761 - loss 0.47691813111305237 - moving ave loss 0.7004316136202529\n",
            "step 2762 - loss 1.1541008949279785 - moving ave loss 0.7457985417510254\n",
            "step 2763 - loss 0.7879496216773987 - moving ave loss 0.7500136497436628\n",
            "step 2764 - loss 0.733941912651062 - moving ave loss 0.7484064760344027\n",
            "step 2765 - loss 0.4707183241844177 - moving ave loss 0.7206376608494043\n",
            "step 2766 - loss 0.6005008220672607 - moving ave loss 0.70862397697119\n",
            "step 2767 - loss 0.8941555619239807 - moving ave loss 0.727177135466469\n",
            "step 2768 - loss 0.46041935682296753 - moving ave loss 0.7005013576021188\n",
            "step 2769 - loss 0.5885083079338074 - moving ave loss 0.6893020526352877\n",
            "step 2770 - loss 0.5760783553123474 - moving ave loss 0.6779796829029936\n",
            "step 2771 - loss 0.9523240327835083 - moving ave loss 0.705414117891045\n",
            "step 2772 - loss 0.6541703939437866 - moving ave loss 0.7002897454963193\n",
            "step 2773 - loss 0.7805834412574768 - moving ave loss 0.7083191150724351\n",
            "step 2774 - loss 0.7184853553771973 - moving ave loss 0.7093357391029114\n",
            "step 2775 - loss 0.7795467972755432 - moving ave loss 0.7163568449201746\n",
            "step 2776 - loss 0.7458752393722534 - moving ave loss 0.7193086843653825\n",
            "step 2777 - loss 0.6129560470581055 - moving ave loss 0.7086734206346548\n",
            "step 2778 - loss 0.6464166641235352 - moving ave loss 0.7024477449835428\n",
            "step 2779 - loss 0.4510410726070404 - moving ave loss 0.6773070777458925\n",
            "step 2780 - loss 0.6391080617904663 - moving ave loss 0.6734871761503499\n",
            "step 2781 - loss 0.7832838892936707 - moving ave loss 0.684466847464682\n",
            "step 2782 - loss 0.5786557793617249 - moving ave loss 0.6738857406543863\n",
            "step 2783 - loss 0.6061416864395142 - moving ave loss 0.6671113352328991\n",
            "step 2784 - loss 0.607951283454895 - moving ave loss 0.6611953300550987\n",
            "step 2785 - loss 0.7508754134178162 - moving ave loss 0.6701633383913704\n",
            "step 2786 - loss 0.8604273796081543 - moving ave loss 0.6891897425130488\n",
            "step 2787 - loss 0.5000731945037842 - moving ave loss 0.6702780877121223\n",
            "step 2788 - loss 1.0979666709899902 - moving ave loss 0.7130469460399091\n",
            "step 2789 - loss 0.8510357737541199 - moving ave loss 0.7268458288113302\n",
            "step 2790 - loss 0.6129079461097717 - moving ave loss 0.7154520405411744\n",
            "step 2791 - loss 0.6854627132415771 - moving ave loss 0.7124531078112146\n",
            "step 2792 - loss 0.6268851161003113 - moving ave loss 0.7038963086401243\n",
            "step 2793 - loss 0.5430198311805725 - moving ave loss 0.6878086608941691\n",
            "step 2794 - loss 1.2057520151138306 - moving ave loss 0.7396029963161352\n",
            "step 2795 - loss 0.417315274477005 - moving ave loss 0.7073742241322222\n",
            "step 2796 - loss 0.6139764785766602 - moving ave loss 0.6980344495766659\n",
            "step 2797 - loss 0.7526991963386536 - moving ave loss 0.7035009242528647\n",
            "step 2798 - loss 0.4533793330192566 - moving ave loss 0.678488765129504\n",
            "step 2799 - loss 0.5620284080505371 - moving ave loss 0.6668427294216073\n",
            "step 2800 - loss 0.5028932094573975 - moving ave loss 0.6504477774251863\n",
            "Finish 28 epoch(es)\n",
            "step 2801 - loss 1.2444429397583008 - moving ave loss 0.7098472936584979\n",
            "step 2802 - loss 0.4739196300506592 - moving ave loss 0.686254527297714\n",
            "step 2803 - loss 0.6904935836791992 - moving ave loss 0.6866784329358625\n",
            "step 2804 - loss 0.9248899221420288 - moving ave loss 0.7104995818564792\n",
            "step 2805 - loss 0.43072500824928284 - moving ave loss 0.6825221244957597\n",
            "step 2806 - loss 0.6670186519622803 - moving ave loss 0.6809717772424118\n",
            "step 2807 - loss 0.7480928897857666 - moving ave loss 0.6876838884967472\n",
            "step 2808 - loss 0.5082637667655945 - moving ave loss 0.6697418763236319\n",
            "step 2809 - loss 0.49541613459587097 - moving ave loss 0.6523093021508558\n",
            "step 2810 - loss 0.4489177465438843 - moving ave loss 0.6319701465901587\n",
            "step 2811 - loss 0.6045191287994385 - moving ave loss 0.6292250448110868\n",
            "step 2812 - loss 0.6286343336105347 - moving ave loss 0.6291659736910316\n",
            "step 2813 - loss 0.6489651203155518 - moving ave loss 0.6311458883534836\n",
            "step 2814 - loss 1.0000661611557007 - moving ave loss 0.6680379156337053\n",
            "step 2815 - loss 0.40908610820770264 - moving ave loss 0.6421427348911051\n",
            "step 2816 - loss 0.6202139854431152 - moving ave loss 0.6399498599463062\n",
            "step 2817 - loss 0.860385537147522 - moving ave loss 0.6619934276664278\n",
            "step 2818 - loss 0.470802903175354 - moving ave loss 0.6428743752173204\n",
            "step 2819 - loss 0.7675298452377319 - moving ave loss 0.6553399222193615\n",
            "step 2820 - loss 0.623639702796936 - moving ave loss 0.6521699002771191\n",
            "step 2821 - loss 0.9107538461685181 - moving ave loss 0.678028294866259\n",
            "step 2822 - loss 0.455170601606369 - moving ave loss 0.6557425255402701\n",
            "step 2823 - loss 0.588202714920044 - moving ave loss 0.6489885444782475\n",
            "step 2824 - loss 0.7213560342788696 - moving ave loss 0.6562252934583097\n",
            "step 2825 - loss 0.4037638008594513 - moving ave loss 0.6309791441984239\n",
            "step 2826 - loss 0.6409794092178345 - moving ave loss 0.631979170700365\n",
            "step 2827 - loss 0.5817257761955261 - moving ave loss 0.6269538312498811\n",
            "step 2828 - loss 0.4170970618724823 - moving ave loss 0.6059681543121412\n",
            "step 2829 - loss 0.4879366159439087 - moving ave loss 0.5941650004753181\n",
            "step 2830 - loss 0.5784564018249512 - moving ave loss 0.5925941406102815\n",
            "step 2831 - loss 0.6691153049468994 - moving ave loss 0.6002462570439433\n",
            "step 2832 - loss 0.804057240486145 - moving ave loss 0.6206273553881636\n",
            "step 2833 - loss 0.7290011644363403 - moving ave loss 0.6314647362929813\n",
            "step 2834 - loss 1.0253545045852661 - moving ave loss 0.6708537131222098\n",
            "step 2835 - loss 0.6674397587776184 - moving ave loss 0.6705123176877507\n",
            "step 2836 - loss 0.6587001085281372 - moving ave loss 0.6693310967717894\n",
            "step 2837 - loss 0.7262029647827148 - moving ave loss 0.675018283572882\n",
            "step 2838 - loss 0.6198244690895081 - moving ave loss 0.6694989021245447\n",
            "step 2839 - loss 0.6339768767356873 - moving ave loss 0.6659466995856589\n",
            "step 2840 - loss 0.6855499744415283 - moving ave loss 0.6679070270712458\n",
            "step 2841 - loss 0.6210359334945679 - moving ave loss 0.663219917713578\n",
            "step 2842 - loss 0.5419799089431763 - moving ave loss 0.6510959168365379\n",
            "step 2843 - loss 0.953102707862854 - moving ave loss 0.6812965959391695\n",
            "step 2844 - loss 0.9138232469558716 - moving ave loss 0.7045492610408397\n",
            "step 2845 - loss 0.47012898325920105 - moving ave loss 0.6811072332626759\n",
            "step 2846 - loss 0.6006763577461243 - moving ave loss 0.6730641457110207\n",
            "step 2847 - loss 0.6437565088272095 - moving ave loss 0.6701333820226395\n",
            "step 2848 - loss 0.6305186152458191 - moving ave loss 0.6661719053449574\n",
            "step 2849 - loss 0.46096867322921753 - moving ave loss 0.6456515821333834\n",
            "step 2850 - loss 0.7218526601791382 - moving ave loss 0.6532716899379589\n",
            "step 2851 - loss 0.829184889793396 - moving ave loss 0.6708630099235027\n",
            "step 2852 - loss 0.7478996515274048 - moving ave loss 0.6785666740838929\n",
            "step 2853 - loss 0.45462241768836975 - moving ave loss 0.6561722484443406\n",
            "step 2854 - loss 0.6079089045524597 - moving ave loss 0.6513459140551526\n",
            "step 2855 - loss 0.6080416440963745 - moving ave loss 0.6470154870592748\n",
            "step 2856 - loss 0.9745041131973267 - moving ave loss 0.67976434967308\n",
            "step 2857 - loss 0.5163233876228333 - moving ave loss 0.6634202534680553\n",
            "step 2858 - loss 0.5601985454559326 - moving ave loss 0.653098082666843\n",
            "step 2859 - loss 0.7555559277534485 - moving ave loss 0.6633438671755035\n",
            "step 2860 - loss 0.4454233646392822 - moving ave loss 0.6415518169218815\n",
            "step 2861 - loss 1.1160595417022705 - moving ave loss 0.6890025893999203\n",
            "step 2862 - loss 0.5411185026168823 - moving ave loss 0.6742141807216165\n",
            "step 2863 - loss 0.6410164833068848 - moving ave loss 0.6708944109801434\n",
            "step 2864 - loss 0.5549125671386719 - moving ave loss 0.6592962265959963\n",
            "step 2865 - loss 0.5953116416931152 - moving ave loss 0.6528977681057082\n",
            "step 2866 - loss 0.5972046256065369 - moving ave loss 0.6473284538557911\n",
            "step 2867 - loss 0.4666714072227478 - moving ave loss 0.6292627491924867\n",
            "step 2868 - loss 0.5015288591384888 - moving ave loss 0.616489360187087\n",
            "step 2869 - loss 0.6096346378326416 - moving ave loss 0.6158038879516424\n",
            "step 2870 - loss 0.5264216065406799 - moving ave loss 0.6068656598105462\n",
            "step 2871 - loss 0.4593670070171356 - moving ave loss 0.5921157945312051\n",
            "step 2872 - loss 0.4961252212524414 - moving ave loss 0.5825167372033287\n",
            "step 2873 - loss 0.4805111885070801 - moving ave loss 0.5723161823337038\n",
            "step 2874 - loss 0.5418353080749512 - moving ave loss 0.5692680949078286\n",
            "step 2875 - loss 0.7498079538345337 - moving ave loss 0.5873220808004991\n",
            "step 2876 - loss 0.543328046798706 - moving ave loss 0.5829226774003198\n",
            "step 2877 - loss 1.093784213066101 - moving ave loss 0.634008830966898\n",
            "step 2878 - loss 0.560107409954071 - moving ave loss 0.6266186888656153\n",
            "step 2879 - loss 0.7617235779762268 - moving ave loss 0.6401291777766764\n",
            "step 2880 - loss 0.5731083154678345 - moving ave loss 0.6334270915457922\n",
            "step 2881 - loss 0.48874548077583313 - moving ave loss 0.6189589304687964\n",
            "step 2882 - loss 0.4672536253929138 - moving ave loss 0.6037883999612081\n",
            "step 2883 - loss 0.839104175567627 - moving ave loss 0.6273199775218501\n",
            "step 2884 - loss 0.5208927989006042 - moving ave loss 0.6166772596597255\n",
            "step 2885 - loss 0.531042754650116 - moving ave loss 0.6081138091587646\n",
            "step 2886 - loss 1.4106428623199463 - moving ave loss 0.6883667144748827\n",
            "step 2887 - loss 0.6104432344436646 - moving ave loss 0.680574366471761\n",
            "step 2888 - loss 0.38097643852233887 - moving ave loss 0.6506145736768187\n",
            "step 2889 - loss 0.5398646593093872 - moving ave loss 0.6395395822400756\n",
            "step 2890 - loss 1.0207304954528809 - moving ave loss 0.6776586735613561\n",
            "step 2891 - loss 0.44465702772140503 - moving ave loss 0.654358508977361\n",
            "step 2892 - loss 0.5902467370033264 - moving ave loss 0.6479473317799576\n",
            "step 2893 - loss 0.38762402534484863 - moving ave loss 0.6219150011364466\n",
            "step 2894 - loss 0.6100273728370667 - moving ave loss 0.6207262383065086\n",
            "step 2895 - loss 0.5122743248939514 - moving ave loss 0.6098810469652529\n",
            "step 2896 - loss 1.392455816268921 - moving ave loss 0.6881385238956197\n",
            "step 2897 - loss 0.6350134015083313 - moving ave loss 0.6828260116568908\n",
            "step 2898 - loss 0.8105090260505676 - moving ave loss 0.6955943130962585\n",
            "step 2899 - loss 0.7424314022064209 - moving ave loss 0.7002780220072747\n",
            "step 2900 - loss 0.6832815408706665 - moving ave loss 0.6985783738936139\n",
            "Finish 29 epoch(es)\n",
            "step 2901 - loss 0.6065807342529297 - moving ave loss 0.6893786099295455\n",
            "step 2902 - loss 0.6346257328987122 - moving ave loss 0.6839033222264622\n",
            "step 2903 - loss 0.6439507007598877 - moving ave loss 0.6799080600798048\n",
            "step 2904 - loss 0.3791359066963196 - moving ave loss 0.6498308447414562\n",
            "step 2905 - loss 0.53290855884552 - moving ave loss 0.6381386161518626\n",
            "step 2906 - loss 0.38415437936782837 - moving ave loss 0.6127401924734592\n",
            "step 2907 - loss 0.5571991801261902 - moving ave loss 0.6071860912387324\n",
            "step 2908 - loss 0.5981560945510864 - moving ave loss 0.6062830915699678\n",
            "step 2909 - loss 0.4587171673774719 - moving ave loss 0.5915264991507182\n",
            "step 2910 - loss 0.6828152537345886 - moving ave loss 0.6006553746091052\n",
            "step 2911 - loss 0.37534669041633606 - moving ave loss 0.5781245061898284\n",
            "step 2912 - loss 0.5672445893287659 - moving ave loss 0.5770365145037222\n",
            "step 2913 - loss 0.4862436056137085 - moving ave loss 0.5679572236147209\n",
            "step 2914 - loss 0.3568642735481262 - moving ave loss 0.5468479286080614\n",
            "step 2915 - loss 0.5346077680587769 - moving ave loss 0.545623912553133\n",
            "step 2916 - loss 0.7457501888275146 - moving ave loss 0.5656365401805712\n",
            "step 2917 - loss 0.5231021642684937 - moving ave loss 0.5613831025893635\n",
            "step 2918 - loss 0.696753740310669 - moving ave loss 0.5749201663614941\n",
            "step 2919 - loss 0.41455891728401184 - moving ave loss 0.5588840414537458\n",
            "step 2920 - loss 0.4803165793418884 - moving ave loss 0.5510272952425601\n",
            "step 2921 - loss 0.5213223695755005 - moving ave loss 0.5480568026758542\n",
            "step 2922 - loss 0.5569651126861572 - moving ave loss 0.5489476336768845\n",
            "step 2923 - loss 0.46885937452316284 - moving ave loss 0.5409388077615123\n",
            "step 2924 - loss 0.47070997953414917 - moving ave loss 0.5339159249387759\n",
            "step 2925 - loss 0.5359145998954773 - moving ave loss 0.5341157924344461\n",
            "step 2926 - loss 0.6206996440887451 - moving ave loss 0.542774177599876\n",
            "step 2927 - loss 0.6628634333610535 - moving ave loss 0.5547831031759938\n",
            "step 2928 - loss 0.370462030172348 - moving ave loss 0.5363509958756292\n",
            "step 2929 - loss 0.6696395874023438 - moving ave loss 0.5496798550283006\n",
            "step 2930 - loss 0.39470821619033813 - moving ave loss 0.5341826911445045\n",
            "step 2931 - loss 0.5945261716842651 - moving ave loss 0.5402170391984805\n",
            "step 2932 - loss 0.9902125597000122 - moving ave loss 0.5852165912486337\n",
            "step 2933 - loss 0.4200003147125244 - moving ave loss 0.5686949635950227\n",
            "step 2934 - loss 0.5344165563583374 - moving ave loss 0.5652671228713542\n",
            "step 2935 - loss 0.4925724267959595 - moving ave loss 0.5579976532638148\n",
            "step 2936 - loss 0.8360345363616943 - moving ave loss 0.5858013415736028\n",
            "step 2937 - loss 0.584492027759552 - moving ave loss 0.5856704101921977\n",
            "step 2938 - loss 0.35140520334243774 - moving ave loss 0.5622438895072217\n",
            "step 2939 - loss 0.49201297760009766 - moving ave loss 0.5552207983165094\n",
            "step 2940 - loss 0.458361953496933 - moving ave loss 0.5455349138345518\n",
            "step 2941 - loss 0.37129074335098267 - moving ave loss 0.5281104967861949\n",
            "step 2942 - loss 0.6797454357147217 - moving ave loss 0.5432739906790476\n",
            "step 2943 - loss 0.7094156742095947 - moving ave loss 0.5598881590321023\n",
            "step 2944 - loss 0.4495273232460022 - moving ave loss 0.5488520754534922\n",
            "step 2945 - loss 0.5239659547805786 - moving ave loss 0.5463634633862009\n",
            "step 2946 - loss 0.4537973999977112 - moving ave loss 0.537106857047352\n",
            "step 2947 - loss 0.7518495321273804 - moving ave loss 0.5585811245553548\n",
            "step 2948 - loss 0.4028390049934387 - moving ave loss 0.5430069125991631\n",
            "step 2949 - loss 0.8858801126480103 - moving ave loss 0.5772942326040478\n",
            "step 2950 - loss 0.4563969373703003 - moving ave loss 0.565204503080673\n",
            "step 2951 - loss 0.4781889319419861 - moving ave loss 0.5565029459668044\n",
            "step 2952 - loss 1.1866484880447388 - moving ave loss 0.6195175001745978\n",
            "step 2953 - loss 0.5526212453842163 - moving ave loss 0.6128278746955597\n",
            "step 2954 - loss 0.7585998177528381 - moving ave loss 0.6274050690012876\n",
            "step 2955 - loss 0.533825159072876 - moving ave loss 0.6180470780084464\n",
            "step 2956 - loss 0.4473264515399933 - moving ave loss 0.6009750153616011\n",
            "step 2957 - loss 0.9557598233222961 - moving ave loss 0.6364534961576707\n",
            "step 2958 - loss 0.5710545778274536 - moving ave loss 0.6299136043246489\n",
            "step 2959 - loss 0.6446422338485718 - moving ave loss 0.6313864672770412\n",
            "step 2960 - loss 0.5078462362289429 - moving ave loss 0.6190324441722314\n",
            "step 2961 - loss 0.47479718923568726 - moving ave loss 0.6046089186785769\n",
            "step 2962 - loss 0.9854978322982788 - moving ave loss 0.6426978100405472\n",
            "step 2963 - loss 0.7401083111763 - moving ave loss 0.6524388601541224\n",
            "step 2964 - loss 0.43298274278640747 - moving ave loss 0.630493248417351\n",
            "step 2965 - loss 0.5372538566589355 - moving ave loss 0.6211693092415095\n",
            "step 2966 - loss 0.6042162775993347 - moving ave loss 0.619474006077292\n",
            "step 2967 - loss 0.8090320825576782 - moving ave loss 0.6384298137253306\n",
            "step 2968 - loss 0.6395565271377563 - moving ave loss 0.6385424850665732\n",
            "step 2969 - loss 1.1678893566131592 - moving ave loss 0.6914771722212318\n",
            "step 2970 - loss 0.7491060495376587 - moving ave loss 0.6972400599528745\n",
            "step 2971 - loss 1.0656956434249878 - moving ave loss 0.7340856183000859\n",
            "step 2972 - loss 0.8334550857543945 - moving ave loss 0.7440225650455168\n",
            "step 2973 - loss 0.5236555337905884 - moving ave loss 0.7219858619200239\n",
            "step 2974 - loss 0.4475729465484619 - moving ave loss 0.6945445703828678\n",
            "step 2975 - loss 0.4747336506843567 - moving ave loss 0.6725634784130167\n",
            "step 2976 - loss 0.5198009610176086 - moving ave loss 0.6572872266734759\n",
            "step 2977 - loss 0.5130158066749573 - moving ave loss 0.6428600846736241\n",
            "step 2978 - loss 0.5349715948104858 - moving ave loss 0.6320712356873103\n",
            "step 2979 - loss 0.6344617605209351 - moving ave loss 0.6323102881706727\n",
            "step 2980 - loss 0.6273115873336792 - moving ave loss 0.6318104180869734\n",
            "step 2981 - loss 0.7148326635360718 - moving ave loss 0.6401126426318832\n",
            "step 2982 - loss 0.8126883506774902 - moving ave loss 0.657370213436444\n",
            "step 2983 - loss 0.6643364429473877 - moving ave loss 0.6580668363875384\n",
            "step 2984 - loss 0.6210745573043823 - moving ave loss 0.6543676084792227\n",
            "step 2985 - loss 0.6780052185058594 - moving ave loss 0.6567313694818864\n",
            "step 2986 - loss 0.5739742517471313 - moving ave loss 0.6484556577084108\n",
            "step 2987 - loss 0.5014744997024536 - moving ave loss 0.6337575419078151\n",
            "step 2988 - loss 0.44808751344680786 - moving ave loss 0.6151905390617144\n",
            "step 2989 - loss 0.6717005968093872 - moving ave loss 0.6208415448364817\n",
            "step 2990 - loss 0.5043519139289856 - moving ave loss 0.6091925817457321\n",
            "step 2991 - loss 0.47279438376426697 - moving ave loss 0.5955527619475856\n",
            "step 2992 - loss 0.9034363031387329 - moving ave loss 0.6263411160667003\n",
            "step 2993 - loss 0.5095232725143433 - moving ave loss 0.6146593317114646\n",
            "step 2994 - loss 0.9281243085861206 - moving ave loss 0.6460058293989301\n",
            "step 2995 - loss 0.609451174736023 - moving ave loss 0.6423503639326394\n",
            "step 2996 - loss 0.5315009355545044 - moving ave loss 0.631265421094826\n",
            "step 2997 - loss 0.4450821280479431 - moving ave loss 0.6126470917901378\n",
            "step 2998 - loss 0.6040245294570923 - moving ave loss 0.6117848355568333\n",
            "step 2999 - loss 1.1351227760314941 - moving ave loss 0.6641186296042993\n",
            "step 3000 - loss 0.6936066150665283 - moving ave loss 0.6670674281505223\n",
            "Checkpoint at step 3000\n",
            "Finish 30 epoch(es)\n",
            "step 3001 - loss 0.4161699414253235 - moving ave loss 0.6419776794780025\n",
            "step 3002 - loss 0.4722141623497009 - moving ave loss 0.6250013277651725\n",
            "step 3003 - loss 0.5448678135871887 - moving ave loss 0.6169879763473741\n",
            "step 3004 - loss 0.4526808559894562 - moving ave loss 0.6005572643115823\n",
            "step 3005 - loss 0.4441679120063782 - moving ave loss 0.5849183290810619\n",
            "step 3006 - loss 1.1973414421081543 - moving ave loss 0.6461606403837711\n",
            "step 3007 - loss 0.708867073059082 - moving ave loss 0.6524312836513022\n",
            "step 3008 - loss 0.6136380434036255 - moving ave loss 0.6485519596265346\n",
            "step 3009 - loss 0.6403228640556335 - moving ave loss 0.6477290500694445\n",
            "step 3010 - loss 0.4350050687789917 - moving ave loss 0.6264566519403992\n",
            "step 3011 - loss 0.5170040130615234 - moving ave loss 0.6155113880525117\n",
            "step 3012 - loss 0.867013692855835 - moving ave loss 0.640661618532844\n",
            "step 3013 - loss 0.5157119631767273 - moving ave loss 0.6281666529972323\n",
            "step 3014 - loss 0.6759976148605347 - moving ave loss 0.6329497491835626\n",
            "step 3015 - loss 0.9032199382781982 - moving ave loss 0.6599767680930262\n",
            "step 3016 - loss 0.4528035521507263 - moving ave loss 0.6392594464987963\n",
            "step 3017 - loss 0.5533032417297363 - moving ave loss 0.6306638260218903\n",
            "step 3018 - loss 0.7705577611923218 - moving ave loss 0.6446532195389335\n",
            "step 3019 - loss 0.7915191650390625 - moving ave loss 0.6593398140889465\n",
            "step 3020 - loss 0.4794881343841553 - moving ave loss 0.6413546461184674\n",
            "step 3021 - loss 0.6195900440216064 - moving ave loss 0.6391781859087813\n",
            "step 3022 - loss 0.5645357966423035 - moving ave loss 0.6317139469821336\n",
            "step 3023 - loss 0.3788734972476959 - moving ave loss 0.6064299020086898\n",
            "step 3024 - loss 0.4074142575263977 - moving ave loss 0.5865283375604606\n",
            "step 3025 - loss 0.7374277114868164 - moving ave loss 0.6016182749530963\n",
            "step 3026 - loss 0.600466251373291 - moving ave loss 0.6015030725951157\n",
            "step 3027 - loss 0.5419464707374573 - moving ave loss 0.5955474124093499\n",
            "step 3028 - loss 0.8027969598770142 - moving ave loss 0.6162723671561164\n",
            "step 3029 - loss 0.7303920388221741 - moving ave loss 0.6276843343227222\n",
            "step 3030 - loss 0.3938857913017273 - moving ave loss 0.6043044800206226\n",
            "step 3031 - loss 0.3681211471557617 - moving ave loss 0.5806861467341367\n",
            "step 3032 - loss 0.7508167624473572 - moving ave loss 0.5976992083054588\n",
            "step 3033 - loss 0.5541472434997559 - moving ave loss 0.5933440118248885\n",
            "step 3034 - loss 0.48681730031967163 - moving ave loss 0.5826913406743669\n",
            "step 3035 - loss 0.6364948749542236 - moving ave loss 0.5880716941023525\n",
            "step 3036 - loss 1.4408764839172363 - moving ave loss 0.6733521730838409\n",
            "step 3037 - loss 0.979217529296875 - moving ave loss 0.7039387087051443\n",
            "step 3038 - loss 0.6670926809310913 - moving ave loss 0.7002541059277391\n",
            "step 3039 - loss 0.6797007322311401 - moving ave loss 0.6981987685580792\n",
            "step 3040 - loss 0.5237318277359009 - moving ave loss 0.6807520744758613\n",
            "step 3041 - loss 0.6006605625152588 - moving ave loss 0.672742923279801\n",
            "step 3042 - loss 0.4333967864513397 - moving ave loss 0.6488083095969549\n",
            "step 3043 - loss 0.6146570444107056 - moving ave loss 0.64539318307833\n",
            "step 3044 - loss 0.4082885980606079 - moving ave loss 0.6216827245765578\n",
            "step 3045 - loss 0.36917150020599365 - moving ave loss 0.5964316021395014\n",
            "step 3046 - loss 0.6408195495605469 - moving ave loss 0.600870396881606\n",
            "step 3047 - loss 0.5553236603736877 - moving ave loss 0.5963157232308143\n",
            "step 3048 - loss 0.6054162979125977 - moving ave loss 0.5972257806989927\n",
            "step 3049 - loss 0.6502467393875122 - moving ave loss 0.6025278765678447\n",
            "step 3050 - loss 0.623403787612915 - moving ave loss 0.6046154676723517\n",
            "step 3051 - loss 0.5536820888519287 - moving ave loss 0.5995221297903095\n",
            "step 3052 - loss 0.5018335580825806 - moving ave loss 0.5897532726195366\n",
            "step 3053 - loss 0.32832199335098267 - moving ave loss 0.5636101446926812\n",
            "step 3054 - loss 0.3340528905391693 - moving ave loss 0.54065441927733\n",
            "step 3055 - loss 1.0109918117523193 - moving ave loss 0.587688158524829\n",
            "step 3056 - loss 0.6121912598609924 - moving ave loss 0.5901384686584454\n",
            "step 3057 - loss 0.49870166182518005 - moving ave loss 0.5809947879751189\n",
            "step 3058 - loss 0.6125140190124512 - moving ave loss 0.5841467110788522\n",
            "step 3059 - loss 0.561987042427063 - moving ave loss 0.5819307442136733\n",
            "step 3060 - loss 0.38069623708724976 - moving ave loss 0.561807293501031\n",
            "step 3061 - loss 0.41669541597366333 - moving ave loss 0.5472961057482942\n",
            "step 3062 - loss 0.4715467691421509 - moving ave loss 0.5397211720876799\n",
            "step 3063 - loss 0.39715784788131714 - moving ave loss 0.5254648396670436\n",
            "step 3064 - loss 0.6346203088760376 - moving ave loss 0.536380386587943\n",
            "step 3065 - loss 0.5153388977050781 - moving ave loss 0.5342762376996565\n",
            "step 3066 - loss 0.5653338432312012 - moving ave loss 0.537381998252811\n",
            "step 3067 - loss 1.157045602798462 - moving ave loss 0.599348358707376\n",
            "step 3068 - loss 0.40149450302124023 - moving ave loss 0.5795629731387625\n",
            "step 3069 - loss 0.759462833404541 - moving ave loss 0.5975529591653403\n",
            "step 3070 - loss 0.6347513198852539 - moving ave loss 0.6012727952373317\n",
            "step 3071 - loss 0.6614137887954712 - moving ave loss 0.6072868945931456\n",
            "step 3072 - loss 0.47780248522758484 - moving ave loss 0.5943384536565895\n",
            "step 3073 - loss 0.5827346444129944 - moving ave loss 0.59317807273223\n",
            "step 3074 - loss 0.4657815098762512 - moving ave loss 0.5804384164466321\n",
            "step 3075 - loss 0.44444161653518677 - moving ave loss 0.5668387364554877\n",
            "step 3076 - loss 0.633238673210144 - moving ave loss 0.5734787301309533\n",
            "step 3077 - loss 0.6745244264602661 - moving ave loss 0.5835832997638846\n",
            "step 3078 - loss 0.5806678533554077 - moving ave loss 0.5832917551230369\n",
            "step 3079 - loss 0.8043976426124573 - moving ave loss 0.605402343871979\n",
            "step 3080 - loss 0.6193983554840088 - moving ave loss 0.606801945033182\n",
            "step 3081 - loss 0.61845463514328 - moving ave loss 0.6079672140441917\n",
            "step 3082 - loss 0.8541373610496521 - moving ave loss 0.6325842287447379\n",
            "step 3083 - loss 0.4210803210735321 - moving ave loss 0.6114338379776173\n",
            "step 3084 - loss 0.727023184299469 - moving ave loss 0.6229927726098025\n",
            "step 3085 - loss 0.39532917737960815 - moving ave loss 0.600226413086783\n",
            "step 3086 - loss 0.6042239665985107 - moving ave loss 0.6006261684379558\n",
            "step 3087 - loss 0.45976024866104126 - moving ave loss 0.5865395764602643\n",
            "step 3088 - loss 0.6268497109413147 - moving ave loss 0.5905705899083694\n",
            "step 3089 - loss 0.49393948912620544 - moving ave loss 0.580907479830153\n",
            "step 3090 - loss 0.3801824450492859 - moving ave loss 0.5608349763520664\n",
            "step 3091 - loss 0.6340165734291077 - moving ave loss 0.5681531360597706\n",
            "step 3092 - loss 0.6413593292236328 - moving ave loss 0.5754737553761569\n",
            "step 3093 - loss 0.6990786790847778 - moving ave loss 0.587834247747019\n",
            "step 3094 - loss 0.36154675483703613 - moving ave loss 0.5652054984560207\n",
            "step 3095 - loss 0.6293877363204956 - moving ave loss 0.5716237222424683\n",
            "step 3096 - loss 0.5487178564071655 - moving ave loss 0.5693331356589381\n",
            "step 3097 - loss 0.7411763668060303 - moving ave loss 0.5865174587736472\n",
            "step 3098 - loss 0.4418456554412842 - moving ave loss 0.572050278440411\n",
            "step 3099 - loss 0.4507451355457306 - moving ave loss 0.5599197641509429\n",
            "step 3100 - loss 0.4296001195907593 - moving ave loss 0.5468877996949246\n",
            "Finish 31 epoch(es)\n",
            "step 3101 - loss 0.987175703048706 - moving ave loss 0.5909165900303028\n",
            "step 3102 - loss 0.8495121002197266 - moving ave loss 0.6167761410492453\n",
            "step 3103 - loss 0.4729112982749939 - moving ave loss 0.6023896567718201\n",
            "step 3104 - loss 0.8261372447013855 - moving ave loss 0.6247644155647767\n",
            "step 3105 - loss 0.5400299429893494 - moving ave loss 0.616290968307234\n",
            "step 3106 - loss 0.4553243815898895 - moving ave loss 0.6001943096354996\n",
            "step 3107 - loss 0.5554295778274536 - moving ave loss 0.595717836454695\n",
            "step 3108 - loss 0.5227317810058594 - moving ave loss 0.5884192309098115\n",
            "step 3109 - loss 0.43346428871154785 - moving ave loss 0.5729237366899852\n",
            "step 3110 - loss 0.679923951625824 - moving ave loss 0.583623758183569\n",
            "step 3111 - loss 0.5286533832550049 - moving ave loss 0.5781267206907126\n",
            "step 3112 - loss 0.660217821598053 - moving ave loss 0.5863358307814466\n",
            "step 3113 - loss 0.5538966655731201 - moving ave loss 0.583091914260614\n",
            "step 3114 - loss 0.4392722249031067 - moving ave loss 0.5687099453248633\n",
            "step 3115 - loss 0.6813545227050781 - moving ave loss 0.5799744030628847\n",
            "step 3116 - loss 1.2346090078353882 - moving ave loss 0.645437863540135\n",
            "step 3117 - loss 0.7325596809387207 - moving ave loss 0.6541500452799935\n",
            "step 3118 - loss 0.5801303386688232 - moving ave loss 0.6467480746188765\n",
            "step 3119 - loss 0.5004169940948486 - moving ave loss 0.6321149665664738\n",
            "step 3120 - loss 0.412017285823822 - moving ave loss 0.6101051984922087\n",
            "step 3121 - loss 0.34366267919540405 - moving ave loss 0.5834609465625282\n",
            "step 3122 - loss 1.802138090133667 - moving ave loss 0.7053286609196421\n",
            "step 3123 - loss 0.6011852025985718 - moving ave loss 0.6949143150875351\n",
            "step 3124 - loss 0.5409669876098633 - moving ave loss 0.679519582339768\n",
            "step 3125 - loss 0.7382519245147705 - moving ave loss 0.6853928165572681\n",
            "step 3126 - loss 0.7571290731430054 - moving ave loss 0.692566442215842\n",
            "step 3127 - loss 0.5741736888885498 - moving ave loss 0.6807271668831127\n",
            "step 3128 - loss 0.41998055577278137 - moving ave loss 0.6546525057720796\n",
            "step 3129 - loss 0.6108434200286865 - moving ave loss 0.6502715971977402\n",
            "step 3130 - loss 0.4795722961425781 - moving ave loss 0.633201667092224\n",
            "step 3131 - loss 0.673592209815979 - moving ave loss 0.6372407213645995\n",
            "step 3132 - loss 0.4679817855358124 - moving ave loss 0.6203148277817209\n",
            "step 3133 - loss 1.12495756149292 - moving ave loss 0.6707791011528408\n",
            "step 3134 - loss 0.7919313311576843 - moving ave loss 0.6828943241533252\n",
            "step 3135 - loss 0.3872324526309967 - moving ave loss 0.6533281370010924\n",
            "step 3136 - loss 0.4492964744567871 - moving ave loss 0.6329249707466619\n",
            "step 3137 - loss 0.7130370140075684 - moving ave loss 0.6409361750727525\n",
            "step 3138 - loss 0.4167179763317108 - moving ave loss 0.6185143551986483\n",
            "step 3139 - loss 0.46914565563201904 - moving ave loss 0.6035774852419854\n",
            "step 3140 - loss 0.40994513034820557 - moving ave loss 0.5842142497526075\n",
            "step 3141 - loss 0.42781996726989746 - moving ave loss 0.5685748215043366\n",
            "step 3142 - loss 0.3888644576072693 - moving ave loss 0.5506037851146299\n",
            "step 3143 - loss 0.41548681259155273 - moving ave loss 0.5370920878623222\n",
            "step 3144 - loss 0.8180670142173767 - moving ave loss 0.5651895804978277\n",
            "step 3145 - loss 0.7338476181030273 - moving ave loss 0.5820553842583477\n",
            "step 3146 - loss 0.6585099101066589 - moving ave loss 0.5897008368431789\n",
            "step 3147 - loss 0.4358440935611725 - moving ave loss 0.5743151625149783\n",
            "step 3148 - loss 0.4998715817928314 - moving ave loss 0.5668708044427636\n",
            "step 3149 - loss 0.904630184173584 - moving ave loss 0.6006467424158456\n",
            "step 3150 - loss 0.49510622024536133 - moving ave loss 0.5900926901987972\n",
            "step 3151 - loss 0.42052146792411804 - moving ave loss 0.5731355679713293\n",
            "step 3152 - loss 0.451131671667099 - moving ave loss 0.5609351783409062\n",
            "step 3153 - loss 0.45276790857315063 - moving ave loss 0.5501184513641307\n",
            "step 3154 - loss 0.6390354633331299 - moving ave loss 0.5590101525610307\n",
            "step 3155 - loss 0.687178909778595 - moving ave loss 0.5718270282827872\n",
            "step 3156 - loss 0.8173268437385559 - moving ave loss 0.5963770098283641\n",
            "step 3157 - loss 0.7340350151062012 - moving ave loss 0.6101428103561478\n",
            "step 3158 - loss 0.5422638654708862 - moving ave loss 0.6033549158676217\n",
            "step 3159 - loss 0.573651134967804 - moving ave loss 0.60038453777764\n",
            "step 3160 - loss 0.42559075355529785 - moving ave loss 0.5829051593554059\n",
            "step 3161 - loss 1.1266342401504517 - moving ave loss 0.6372780674349104\n",
            "step 3162 - loss 0.4636242389678955 - moving ave loss 0.619912684588209\n",
            "step 3163 - loss 0.3921523690223694 - moving ave loss 0.5971366530316251\n",
            "step 3164 - loss 0.6586601734161377 - moving ave loss 0.6032890050700764\n",
            "step 3165 - loss 0.7690976858139038 - moving ave loss 0.6198698731444592\n",
            "step 3166 - loss 0.7843194007873535 - moving ave loss 0.6363148259087487\n",
            "step 3167 - loss 0.4732120633125305 - moving ave loss 0.6200045496491269\n",
            "step 3168 - loss 0.4960400462150574 - moving ave loss 0.6076080993057199\n",
            "step 3169 - loss 0.3871062397956848 - moving ave loss 0.5855579133547164\n",
            "step 3170 - loss 0.4198414087295532 - moving ave loss 0.5689862628922001\n",
            "step 3171 - loss 0.7510291337966919 - moving ave loss 0.5871905499826493\n",
            "step 3172 - loss 0.5413461923599243 - moving ave loss 0.5826061142203768\n",
            "step 3173 - loss 0.4751049876213074 - moving ave loss 0.5718560015604699\n",
            "step 3174 - loss 0.37295597791671753 - moving ave loss 0.5519659991960947\n",
            "step 3175 - loss 0.5155155658721924 - moving ave loss 0.5483209558637044\n",
            "step 3176 - loss 0.6261324286460876 - moving ave loss 0.5561021031419427\n",
            "step 3177 - loss 0.5644466876983643 - moving ave loss 0.556936561597585\n",
            "step 3178 - loss 0.4221229553222656 - moving ave loss 0.5434552009700531\n",
            "step 3179 - loss 0.33766695857048035 - moving ave loss 0.5228763767300958\n",
            "step 3180 - loss 0.9685720801353455 - moving ave loss 0.5674459470706208\n",
            "step 3181 - loss 0.42406895756721497 - moving ave loss 0.5531082481202803\n",
            "step 3182 - loss 0.45508337020874023 - moving ave loss 0.5433057603291263\n",
            "step 3183 - loss 0.7704300284385681 - moving ave loss 0.5660181871400705\n",
            "step 3184 - loss 0.439033180475235 - moving ave loss 0.5533196864735869\n",
            "step 3185 - loss 0.3949355483055115 - moving ave loss 0.5374812726567794\n",
            "step 3186 - loss 0.6520318984985352 - moving ave loss 0.548936335240955\n",
            "step 3187 - loss 0.6484185457229614 - moving ave loss 0.5588845562891557\n",
            "step 3188 - loss 0.33737051486968994 - moving ave loss 0.5367331521472092\n",
            "step 3189 - loss 0.47443217039108276 - moving ave loss 0.5305030539715966\n",
            "step 3190 - loss 0.34846335649490356 - moving ave loss 0.5122990842239272\n",
            "step 3191 - loss 0.4997802674770355 - moving ave loss 0.5110472025492381\n",
            "step 3192 - loss 0.3296588659286499 - moving ave loss 0.49290836888717926\n",
            "step 3193 - loss 0.9100251197814941 - moving ave loss 0.5346200439766108\n",
            "step 3194 - loss 0.4522802531719208 - moving ave loss 0.5263860648961418\n",
            "step 3195 - loss 0.4178979694843292 - moving ave loss 0.5155372553549605\n",
            "step 3196 - loss 0.3610822558403015 - moving ave loss 0.5000917554034947\n",
            "step 3197 - loss 0.5415671467781067 - moving ave loss 0.504239294540956\n",
            "step 3198 - loss 0.39776045083999634 - moving ave loss 0.49359141017086\n",
            "step 3199 - loss 0.5897640585899353 - moving ave loss 0.5032086750127676\n",
            "step 3200 - loss 0.33544695377349854 - moving ave loss 0.48643250288884066\n",
            "Finish 32 epoch(es)\n",
            "step 3201 - loss 0.4487394094467163 - moving ave loss 0.4826631935446282\n",
            "step 3202 - loss 0.46529287099838257 - moving ave loss 0.4809261612900037\n",
            "step 3203 - loss 0.35677435994148254 - moving ave loss 0.4685109811551516\n",
            "step 3204 - loss 0.5085398554801941 - moving ave loss 0.47251386858765587\n",
            "step 3205 - loss 0.6209386587142944 - moving ave loss 0.48735634760031976\n",
            "step 3206 - loss 0.6017794609069824 - moving ave loss 0.49879865893098607\n",
            "step 3207 - loss 0.4436059594154358 - moving ave loss 0.493279388979431\n",
            "step 3208 - loss 0.4958136975765228 - moving ave loss 0.4935328198391402\n",
            "step 3209 - loss 0.6997939348220825 - moving ave loss 0.5141589313374344\n",
            "step 3210 - loss 0.5400251150131226 - moving ave loss 0.5167455497050032\n",
            "step 3211 - loss 0.3006662428379059 - moving ave loss 0.49513761901829345\n",
            "step 3212 - loss 0.4750061631202698 - moving ave loss 0.4931244734284911\n",
            "step 3213 - loss 0.49933168292045593 - moving ave loss 0.49374519437768755\n",
            "step 3214 - loss 0.3225504457950592 - moving ave loss 0.4766257195194247\n",
            "step 3215 - loss 0.30326318740844727 - moving ave loss 0.45928946630832695\n",
            "step 3216 - loss 0.5053816437721252 - moving ave loss 0.4638986840547068\n",
            "step 3217 - loss 0.46169185638427734 - moving ave loss 0.4636780012876639\n",
            "step 3218 - loss 0.5545535087585449 - moving ave loss 0.472765552034752\n",
            "step 3219 - loss 0.40107351541519165 - moving ave loss 0.465596348372796\n",
            "step 3220 - loss 0.6274185180664062 - moving ave loss 0.481778565342157\n",
            "step 3221 - loss 1.1431463956832886 - moving ave loss 0.5479153483762702\n",
            "step 3222 - loss 0.6391977071762085 - moving ave loss 0.5570435842562641\n",
            "step 3223 - loss 0.4239159822463989 - moving ave loss 0.5437308240552776\n",
            "step 3224 - loss 0.5805903673171997 - moving ave loss 0.5474167783814698\n",
            "step 3225 - loss 0.5151942372322083 - moving ave loss 0.5441945242665437\n",
            "step 3226 - loss 0.6057738065719604 - moving ave loss 0.5503524524970854\n",
            "step 3227 - loss 0.6532642841339111 - moving ave loss 0.560643635660768\n",
            "step 3228 - loss 0.4744390845298767 - moving ave loss 0.5520231805476788\n",
            "step 3229 - loss 0.4532112181186676 - moving ave loss 0.5421419843047777\n",
            "step 3230 - loss 0.7548091411590576 - moving ave loss 0.5634086999902057\n",
            "step 3231 - loss 0.6100401878356934 - moving ave loss 0.5680718487747545\n",
            "step 3232 - loss 0.4249279499053955 - moving ave loss 0.5537574588878187\n",
            "step 3233 - loss 0.4895962178707123 - moving ave loss 0.547341334786108\n",
            "step 3234 - loss 0.5162836909294128 - moving ave loss 0.5442355704004386\n",
            "step 3235 - loss 0.6694608926773071 - moving ave loss 0.5567581026281254\n",
            "step 3236 - loss 0.6791563034057617 - moving ave loss 0.568997922705889\n",
            "step 3237 - loss 1.0852025747299194 - moving ave loss 0.6206183879082922\n",
            "step 3238 - loss 1.0320454835891724 - moving ave loss 0.6617610974763802\n",
            "step 3239 - loss 0.3596300184726715 - moving ave loss 0.6315479895760094\n",
            "step 3240 - loss 0.4571670591831207 - moving ave loss 0.6141098965367207\n",
            "step 3241 - loss 0.3605761229991913 - moving ave loss 0.5887565191829677\n",
            "step 3242 - loss 0.6931500434875488 - moving ave loss 0.5991958716134258\n",
            "step 3243 - loss 0.3903196156024933 - moving ave loss 0.5783082460123325\n",
            "step 3244 - loss 0.33232200145721436 - moving ave loss 0.5537096215568208\n",
            "step 3245 - loss 0.2876462936401367 - moving ave loss 0.5271032887651524\n",
            "step 3246 - loss 0.5960323214530945 - moving ave loss 0.5339961920339467\n",
            "step 3247 - loss 0.5023152232170105 - moving ave loss 0.530828095152253\n",
            "step 3248 - loss 0.5059117674827576 - moving ave loss 0.5283364623853035\n",
            "step 3249 - loss 0.5696269273757935 - moving ave loss 0.5324655088843525\n",
            "step 3250 - loss 0.6360841989517212 - moving ave loss 0.5428273778910894\n",
            "Checkpoint at step 3250\n",
            "step 3251 - loss 0.41387540102005005 - moving ave loss 0.5299321802039855\n",
            "step 3252 - loss 0.5807781219482422 - moving ave loss 0.5350167743784111\n",
            "step 3253 - loss 0.3360706567764282 - moving ave loss 0.5151221626182128\n",
            "step 3254 - loss 0.3310159146785736 - moving ave loss 0.4967115378242488\n",
            "step 3255 - loss 0.7911618947982788 - moving ave loss 0.5261565735216518\n",
            "step 3256 - loss 1.1474878787994385 - moving ave loss 0.5882897040494305\n",
            "step 3257 - loss 1.0870128870010376 - moving ave loss 0.6381620223445912\n",
            "step 3258 - loss 0.31114399433135986 - moving ave loss 0.6054602195432681\n",
            "step 3259 - loss 0.6042553186416626 - moving ave loss 0.6053397294531075\n",
            "step 3260 - loss 0.31864991784095764 - moving ave loss 0.5766707482918926\n",
            "step 3261 - loss 0.3217134475708008 - moving ave loss 0.5511750182197834\n",
            "step 3262 - loss 0.44608426094055176 - moving ave loss 0.5406659424918603\n",
            "step 3263 - loss 0.41831493377685547 - moving ave loss 0.5284308416203598\n",
            "step 3264 - loss 0.6756498217582703 - moving ave loss 0.5431527396341509\n",
            "step 3265 - loss 0.6735398173332214 - moving ave loss 0.556191447404058\n",
            "step 3266 - loss 0.48728325963020325 - moving ave loss 0.5493006286266726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b9fb94a28d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/darkflow/darkflow/net/flow.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mloss_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         if not i: self.say(train_stats.format(\n\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/darkflow/darkflow/net/yolo/data.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mtrain_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffle_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This image's width or height are zeros: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_instance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/darkflow/darkflow/net/yolov2/data.py\u001b[0m in \u001b[0;36m_batch\u001b[0;34m(self, chunk)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mallobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallobj_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Calculate regression target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/darkflow/darkflow/net/yolo/predict.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, im, allobj)\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mobj_1_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimcv2_recolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/darkflow/darkflow/utils/im_transform.py\u001b[0m in \u001b[0;36mimcv2_recolor\u001b[0;34m(im, a)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#       im = np.power(im/mx, 1. + up * .5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mup\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLsYgbX22nNa",
        "colab_type": "text"
      },
      "source": [
        "Para entrenar desde el último checkpoint, ejecutamos el siguiente comando para cargarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E0SHL7TSDOV",
        "colab_type": "code",
        "outputId": "2d3d9813-5f24-464e-818c-b1da6086e8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "options = {\"model\": \"cfg/custom-voc.cfg\",\n",
        "           \"load\": -1,\n",
        "           \"gpu\": 1.0}\n",
        "tfnet2 = TFNet(options)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing cfg/custom-voc.cfg\n",
            "Loading None ...\n",
            "Finished in 0.00011563301086425781s\n",
            "\n",
            "Building net ...\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 16)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 16)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 32)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_1                     | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 50)\n",
            "-------+--------+----------------------------------+---------------\n",
            "GPU mode with 1.0 usage\n",
            "Loading from ./ckpt/custom-voc-1300\n",
            "INFO:tensorflow:Restoring parameters from ./ckpt/custom-voc-1300\n",
            "Finished in 1.8059673309326172s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxnfwvkO2wU8",
        "colab_type": "text"
      },
      "source": [
        "Reanudamos el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQq00escSdZy",
        "colab_type": "code",
        "outputId": "8c3bf26a-2b47-453f-faa6-f651185076bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tfnet.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "cfg/custom-voc.cfg parsing /content/drive/My Drive/YOLOv2/Dataset/Annotations\n",
            "Parsing for ['chiky', 'chiky fresa', 'flan', 'frijoles', 'leche'] \n",
            "[====================>]100%  IMG_20200523_223254.xml\n",
            "Statistics:\n",
            "chiky: 38\n",
            "flan: 34\n",
            "leche: 22\n",
            "frijoles: 12\n",
            "chiky fresa: 10\n",
            "Dataset size: 110\n",
            "Dataset of 110 instance(s)\n",
            "Training statistics: \n",
            "\tLearning rate : 1e-05\n",
            "\tBatch size    : 8\n",
            "\tEpoch number  : 100\n",
            "\tBackup every  : 2000\n",
            "step 1 - loss 1.9389839172363281 - moving ave loss 1.9389839172363281\n",
            "step 2 - loss 1.7182705402374268 - moving ave loss 1.9169125795364381\n",
            "step 3 - loss 2.1955065727233887 - moving ave loss 1.9447719788551332\n",
            "step 4 - loss 1.5861968994140625 - moving ave loss 1.9089144709110262\n",
            "step 5 - loss 2.0250329971313477 - moving ave loss 1.9205263235330585\n",
            "step 6 - loss 1.6854578256607056 - moving ave loss 1.8970194737458232\n",
            "step 7 - loss 1.8627474308013916 - moving ave loss 1.8935922694513803\n",
            "step 8 - loss 2.4400625228881836 - moving ave loss 1.9482392947950606\n",
            "step 9 - loss 1.5801483392715454 - moving ave loss 1.9114301992427092\n",
            "step 10 - loss 1.426009178161621 - moving ave loss 1.8628880971346002\n",
            "step 11 - loss 1.7679858207702637 - moving ave loss 1.8533978694981665\n",
            "step 12 - loss 1.6602314710617065 - moving ave loss 1.8340812296545206\n",
            "step 13 - loss 1.84279465675354 - moving ave loss 1.8349525723644224\n",
            "Finish 1 epoch(es)\n",
            "step 14 - loss 1.8784451484680176 - moving ave loss 1.839301829974782\n",
            "step 15 - loss 1.8883357048034668 - moving ave loss 1.8442052174576506\n",
            "step 16 - loss 2.093174934387207 - moving ave loss 1.8691021891506063\n",
            "step 17 - loss 2.331239700317383 - moving ave loss 1.915315940267284\n",
            "step 18 - loss 1.6751115322113037 - moving ave loss 1.891295499461686\n",
            "step 19 - loss 1.4005833864212036 - moving ave loss 1.8422242881576378\n",
            "step 20 - loss 1.8905937671661377 - moving ave loss 1.847061236058488\n",
            "step 21 - loss 1.6440423727035522 - moving ave loss 1.8267593497229946\n",
            "step 22 - loss 1.757131576538086 - moving ave loss 1.8197965724045038\n",
            "step 23 - loss 1.5933717489242554 - moving ave loss 1.7971540900564789\n",
            "step 24 - loss 1.7567111253738403 - moving ave loss 1.793109793588215\n",
            "step 25 - loss 1.7993865013122559 - moving ave loss 1.7937374643606192\n",
            "step 26 - loss 1.571831226348877 - moving ave loss 1.771546840559445\n",
            "Finish 2 epoch(es)\n",
            "step 27 - loss 1.8660591840744019 - moving ave loss 1.7809980749109409\n",
            "step 28 - loss 1.377018690109253 - moving ave loss 1.7406001364307722\n",
            "step 29 - loss 1.6662843227386475 - moving ave loss 1.7331685550615596\n",
            "step 30 - loss 1.5756043195724487 - moving ave loss 1.7174121315126487\n",
            "step 31 - loss 1.584025263786316 - moving ave loss 1.7040734447400157\n",
            "step 32 - loss 2.1411404609680176 - moving ave loss 1.747780146362816\n",
            "step 33 - loss 1.671076774597168 - moving ave loss 1.7401098091862512\n",
            "step 34 - loss 1.7207542657852173 - moving ave loss 1.738174254846148\n",
            "step 35 - loss 2.039088010787964 - moving ave loss 1.7682656304403297\n",
            "step 36 - loss 1.9450151920318604 - moving ave loss 1.7859405865994828\n",
            "step 37 - loss 2.083224296569824 - moving ave loss 1.8156689575965173\n",
            "step 38 - loss 1.6039478778839111 - moving ave loss 1.7944968496252567\n",
            "step 39 - loss 1.6100903749465942 - moving ave loss 1.7760562021573905\n",
            "Finish 3 epoch(es)\n",
            "step 40 - loss 1.6016627550125122 - moving ave loss 1.7586168574429026\n",
            "step 41 - loss 1.7027454376220703 - moving ave loss 1.7530297154608194\n",
            "step 42 - loss 2.1564667224884033 - moving ave loss 1.793373416163578\n",
            "step 43 - loss 1.3236985206604004 - moving ave loss 1.7464059266132603\n",
            "step 44 - loss 1.5699775218963623 - moving ave loss 1.7287630861415706\n",
            "step 45 - loss 1.8738658428192139 - moving ave loss 1.743273361809335\n",
            "step 46 - loss 1.791239619255066 - moving ave loss 1.748069987553908\n",
            "step 47 - loss 1.6299304962158203 - moving ave loss 1.7362560384200993\n",
            "step 48 - loss 2.1555018424987793 - moving ave loss 1.7781806188279674\n",
            "step 49 - loss 2.081308126449585 - moving ave loss 1.8084933695901293\n",
            "step 50 - loss 1.7339857816696167 - moving ave loss 1.8010426107980781\n",
            "step 51 - loss 1.9399957656860352 - moving ave loss 1.814937926286874\n",
            "step 52 - loss 1.8966914415359497 - moving ave loss 1.8231132778117816\n",
            "Finish 4 epoch(es)\n",
            "step 53 - loss 1.5358772277832031 - moving ave loss 1.794389672808924\n",
            "step 54 - loss 1.584564447402954 - moving ave loss 1.773407150268327\n",
            "step 55 - loss 1.8640680313110352 - moving ave loss 1.7824732383725979\n",
            "step 56 - loss 1.7835583686828613 - moving ave loss 1.7825817514036242\n",
            "step 57 - loss 1.7340900897979736 - moving ave loss 1.7777325852430592\n",
            "step 58 - loss 1.4806177616119385 - moving ave loss 1.748021102879947\n",
            "step 59 - loss 2.0489861965179443 - moving ave loss 1.7781176122437468\n",
            "step 60 - loss 1.5062477588653564 - moving ave loss 1.750930626905908\n",
            "step 61 - loss 1.538928508758545 - moving ave loss 1.7297304150911719\n",
            "step 62 - loss 1.4094457626342773 - moving ave loss 1.6977019498454826\n",
            "step 63 - loss 1.713573694229126 - moving ave loss 1.699289124283847\n",
            "step 64 - loss 2.322448253631592 - moving ave loss 1.7616050372186216\n",
            "step 65 - loss 1.3083195686340332 - moving ave loss 1.7162764903601628\n",
            "Finish 5 epoch(es)\n",
            "step 66 - loss 1.7247511148452759 - moving ave loss 1.7171239528086741\n",
            "step 67 - loss 1.33207368850708 - moving ave loss 1.6786189263785147\n",
            "step 68 - loss 1.4016525745391846 - moving ave loss 1.6509222911945818\n",
            "step 69 - loss 1.7622841596603394 - moving ave loss 1.6620584780411576\n",
            "step 70 - loss 2.1204237937927246 - moving ave loss 1.7078950096163144\n",
            "step 71 - loss 1.642736554145813 - moving ave loss 1.7013791640692644\n",
            "step 72 - loss 1.6405251026153564 - moving ave loss 1.6952937579238738\n",
            "step 73 - loss 1.7486157417297363 - moving ave loss 1.7006259563044601\n",
            "step 74 - loss 1.4266974925994873 - moving ave loss 1.6732331099339628\n",
            "step 75 - loss 1.4060615301132202 - moving ave loss 1.6465159519518886\n",
            "step 76 - loss 2.064829111099243 - moving ave loss 1.6883472678666243\n",
            "step 77 - loss 1.9397960901260376 - moving ave loss 1.7134921500925657\n",
            "step 78 - loss 1.9274157285690308 - moving ave loss 1.7348845079402122\n",
            "Finish 6 epoch(es)\n",
            "step 79 - loss 2.4230356216430664 - moving ave loss 1.8036996193104977\n",
            "step 80 - loss 1.628674030303955 - moving ave loss 1.7861970604098436\n",
            "step 81 - loss 1.7886431217193604 - moving ave loss 1.7864416665407952\n",
            "step 82 - loss 1.687883973121643 - moving ave loss 1.77658589719888\n",
            "step 83 - loss 1.6782160997390747 - moving ave loss 1.7667489174528996\n",
            "step 84 - loss 1.8420026302337646 - moving ave loss 1.7742742887309864\n",
            "step 85 - loss 1.7475082874298096 - moving ave loss 1.7715976886008686\n",
            "step 86 - loss 1.4538381099700928 - moving ave loss 1.7398217307377912\n",
            "step 87 - loss 1.7365769147872925 - moving ave loss 1.7394972491427414\n",
            "step 88 - loss 1.7193888425827026 - moving ave loss 1.7374864084867376\n",
            "step 89 - loss 1.3758383989334106 - moving ave loss 1.701321607531405\n",
            "step 90 - loss 1.6345324516296387 - moving ave loss 1.6946426919412283\n",
            "step 91 - loss 1.8947927951812744 - moving ave loss 1.714657702265233\n",
            "Finish 7 epoch(es)\n",
            "step 92 - loss 1.4960920810699463 - moving ave loss 1.6928011401457044\n",
            "step 93 - loss 1.6469067335128784 - moving ave loss 1.688211699482422\n",
            "step 94 - loss 1.6451959609985352 - moving ave loss 1.6839101256340332\n",
            "step 95 - loss 2.064377546310425 - moving ave loss 1.7219568677016723\n",
            "step 96 - loss 1.7496060132980347 - moving ave loss 1.7247217822613086\n",
            "step 97 - loss 1.9351434707641602 - moving ave loss 1.7457639511115937\n",
            "step 98 - loss 1.697274088859558 - moving ave loss 1.74091496488639\n",
            "step 99 - loss 1.8683676719665527 - moving ave loss 1.7536602355944064\n",
            "step 100 - loss 1.529631495475769 - moving ave loss 1.7312573615825428\n",
            "step 101 - loss 1.6441726684570312 - moving ave loss 1.7225488922699916\n",
            "step 102 - loss 1.7698228359222412 - moving ave loss 1.7272762866352167\n",
            "step 103 - loss 1.6486334800720215 - moving ave loss 1.7194120059788973\n",
            "step 104 - loss 1.3173339366912842 - moving ave loss 1.679204199050136\n",
            "Finish 8 epoch(es)\n",
            "step 105 - loss 1.4648488759994507 - moving ave loss 1.6577686667450677\n",
            "step 106 - loss 1.625990629196167 - moving ave loss 1.6545908629901778\n",
            "step 107 - loss 1.6578445434570312 - moving ave loss 1.6549162310368633\n",
            "step 108 - loss 1.5442999601364136 - moving ave loss 1.6438546039468185\n",
            "step 109 - loss 1.6842143535614014 - moving ave loss 1.647890578908277\n",
            "step 110 - loss 2.2774922847747803 - moving ave loss 1.7108507494949272\n",
            "step 111 - loss 1.5231420993804932 - moving ave loss 1.692079884483484\n",
            "step 112 - loss 1.7928006649017334 - moving ave loss 1.702151962525309\n",
            "step 113 - loss 2.210357904434204 - moving ave loss 1.7529725567161984\n",
            "step 114 - loss 1.683508276939392 - moving ave loss 1.7460261287385177\n",
            "step 115 - loss 1.7381073236465454 - moving ave loss 1.7452342482293204\n",
            "step 116 - loss 1.6542940139770508 - moving ave loss 1.7361402248040936\n",
            "step 117 - loss 1.6829323768615723 - moving ave loss 1.7308194400098416\n",
            "Finish 9 epoch(es)\n",
            "step 118 - loss 1.771645188331604 - moving ave loss 1.7349020148420178\n",
            "step 119 - loss 1.7492430210113525 - moving ave loss 1.7363361154589514\n",
            "step 120 - loss 1.912698745727539 - moving ave loss 1.7539723784858101\n",
            "step 121 - loss 1.751183032989502 - moving ave loss 1.7536934439361793\n",
            "step 122 - loss 2.0181219577789307 - moving ave loss 1.7801362953204545\n",
            "step 123 - loss 1.7302851676940918 - moving ave loss 1.7751511825578183\n",
            "step 124 - loss 1.599553108215332 - moving ave loss 1.7575913751235699\n",
            "step 125 - loss 1.6435871124267578 - moving ave loss 1.7461909488538887\n",
            "step 126 - loss 1.421445369720459 - moving ave loss 1.713716390940546\n",
            "step 127 - loss 1.677614688873291 - moving ave loss 1.7101062207338207\n",
            "step 128 - loss 1.6545032262802124 - moving ave loss 1.70454592128846\n",
            "step 129 - loss 1.2655448913574219 - moving ave loss 1.660645818295356\n",
            "step 130 - loss 1.8206452131271362 - moving ave loss 1.676645757778534\n",
            "Finish 10 epoch(es)\n",
            "step 131 - loss 1.9558744430541992 - moving ave loss 1.7045686263061006\n",
            "step 132 - loss 1.399317979812622 - moving ave loss 1.6740435616567528\n",
            "step 133 - loss 1.6242074966430664 - moving ave loss 1.6690599551553842\n",
            "step 134 - loss 1.380234956741333 - moving ave loss 1.6401774553139792\n",
            "step 135 - loss 1.7405720949172974 - moving ave loss 1.6502169192743112\n",
            "step 136 - loss 1.5779004096984863 - moving ave loss 1.642985268316729\n",
            "step 137 - loss 1.7623546123504639 - moving ave loss 1.6549222027201025\n",
            "step 138 - loss 1.9203438758850098 - moving ave loss 1.6814643700365934\n",
            "step 139 - loss 1.7123007774353027 - moving ave loss 1.6845480107764643\n",
            "step 140 - loss 1.492485761642456 - moving ave loss 1.6653417858630637\n",
            "step 141 - loss 1.7567938566207886 - moving ave loss 1.6744869929388362\n",
            "step 142 - loss 1.5832008123397827 - moving ave loss 1.665358374878931\n",
            "step 143 - loss 1.6555548906326294 - moving ave loss 1.6643780264543007\n",
            "Finish 11 epoch(es)\n",
            "step 144 - loss 1.54899263381958 - moving ave loss 1.6528394871908287\n",
            "step 145 - loss 1.9637962579727173 - moving ave loss 1.6839351642690175\n",
            "step 146 - loss 1.3368408679962158 - moving ave loss 1.6492257346417374\n",
            "step 147 - loss 2.0540194511413574 - moving ave loss 1.6897051062916995\n",
            "step 148 - loss 1.4897263050079346 - moving ave loss 1.669707226163323\n",
            "step 149 - loss 1.9018629789352417 - moving ave loss 1.692922801440515\n",
            "step 150 - loss 1.3649379014968872 - moving ave loss 1.6601243114461524\n",
            "step 151 - loss 1.6121925115585327 - moving ave loss 1.6553311314573904\n",
            "step 152 - loss 1.3350839614868164 - moving ave loss 1.623306414460333\n",
            "step 153 - loss 1.5058939456939697 - moving ave loss 1.6115651675836968\n",
            "step 154 - loss 1.665549635887146 - moving ave loss 1.6169636144140418\n",
            "step 155 - loss 1.6266168355941772 - moving ave loss 1.6179289365320553\n",
            "step 156 - loss 1.5211265087127686 - moving ave loss 1.6082486937501266\n",
            "Finish 12 epoch(es)\n",
            "step 157 - loss 1.4285340309143066 - moving ave loss 1.5902772274665444\n",
            "step 158 - loss 2.295569896697998 - moving ave loss 1.6608064943896899\n",
            "step 159 - loss 1.4906184673309326 - moving ave loss 1.6437876916838141\n",
            "step 160 - loss 1.6449726819992065 - moving ave loss 1.6439061907153534\n",
            "step 161 - loss 1.7393893003463745 - moving ave loss 1.6534545016784554\n",
            "step 162 - loss 1.7409467697143555 - moving ave loss 1.6622037284820455\n",
            "step 163 - loss 1.5843555927276611 - moving ave loss 1.654418914906607\n",
            "step 164 - loss 1.5064122676849365 - moving ave loss 1.6396182501844403\n",
            "step 165 - loss 1.4457519054412842 - moving ave loss 1.6202316157101246\n",
            "step 166 - loss 1.4200648069381714 - moving ave loss 1.6002149348329293\n",
            "step 167 - loss 1.430113673210144 - moving ave loss 1.583204808670651\n",
            "step 168 - loss 1.9084416627883911 - moving ave loss 1.615728494082425\n",
            "step 169 - loss 2.0103209018707275 - moving ave loss 1.6551877348612554\n",
            "Finish 13 epoch(es)\n",
            "step 170 - loss 1.4440457820892334 - moving ave loss 1.6340735395840533\n",
            "step 171 - loss 1.8324050903320312 - moving ave loss 1.6539066946588512\n",
            "step 172 - loss 1.4347885847091675 - moving ave loss 1.631994883663883\n",
            "step 173 - loss 1.3717325925827026 - moving ave loss 1.6059686545557648\n",
            "step 174 - loss 1.328702688217163 - moving ave loss 1.5782420579219045\n",
            "step 175 - loss 1.2996286153793335 - moving ave loss 1.5503807136676475\n",
            "step 176 - loss 1.6237499713897705 - moving ave loss 1.55771763943986\n",
            "step 177 - loss 2.216599464416504 - moving ave loss 1.6236058219375245\n",
            "step 178 - loss 1.886526346206665 - moving ave loss 1.6498978743644386\n",
            "step 179 - loss 1.5983431339263916 - moving ave loss 1.644742400320634\n",
            "step 180 - loss 1.6147772073745728 - moving ave loss 1.641745881026028\n",
            "step 181 - loss 1.5513179302215576 - moving ave loss 1.6327030859455811\n",
            "step 182 - loss 1.6386810541152954 - moving ave loss 1.6333008827625526\n",
            "Finish 14 epoch(es)\n",
            "step 183 - loss 1.5406010150909424 - moving ave loss 1.6240308959953917\n",
            "step 184 - loss 1.7015390396118164 - moving ave loss 1.6317817103570342\n",
            "step 185 - loss 1.6536600589752197 - moving ave loss 1.6339695452188527\n",
            "step 186 - loss 1.4311480522155762 - moving ave loss 1.6136873959185252\n",
            "step 187 - loss 1.3383204936981201 - moving ave loss 1.5861507056964848\n",
            "step 188 - loss 1.7279435396194458 - moving ave loss 1.6003299890887808\n",
            "step 189 - loss 2.0218300819396973 - moving ave loss 1.6424799983738725\n",
            "step 190 - loss 1.5398690700531006 - moving ave loss 1.6322189055417955\n",
            "step 191 - loss 1.9509371519088745 - moving ave loss 1.6640907301785033\n",
            "step 192 - loss 1.4208428859710693 - moving ave loss 1.63976594575776\n",
            "step 193 - loss 2.0595688819885254 - moving ave loss 1.6817462393808364\n",
            "step 194 - loss 1.6152009963989258 - moving ave loss 1.6750917150826454\n",
            "step 195 - loss 1.5786150693893433 - moving ave loss 1.6654440505133152\n",
            "Finish 15 epoch(es)\n",
            "step 196 - loss 1.859343409538269 - moving ave loss 1.6848339864158108\n",
            "step 197 - loss 1.6276582479476929 - moving ave loss 1.679116412568999\n",
            "step 198 - loss 1.2435688972473145 - moving ave loss 1.6355616610368304\n",
            "step 199 - loss 1.4234957695007324 - moving ave loss 1.6143550718832207\n",
            "step 200 - loss 1.5863227844238281 - moving ave loss 1.6115518431372815\n",
            "step 201 - loss 1.573596477508545 - moving ave loss 1.6077563065744078\n",
            "step 202 - loss 1.2791781425476074 - moving ave loss 1.5748984901717278\n",
            "step 203 - loss 1.5367746353149414 - moving ave loss 1.5710861046860491\n",
            "step 204 - loss 1.7116187810897827 - moving ave loss 1.5851393723264227\n",
            "step 205 - loss 2.1616766452789307 - moving ave loss 1.6427930996216735\n",
            "step 206 - loss 2.2059712409973145 - moving ave loss 1.6991109137592377\n",
            "step 207 - loss 1.787876009941101 - moving ave loss 1.7079874233774242\n",
            "step 208 - loss 1.9768255949020386 - moving ave loss 1.7348712405298856\n",
            "Finish 16 epoch(es)\n",
            "step 209 - loss 1.2215526103973389 - moving ave loss 1.683539377516631\n",
            "step 210 - loss 1.611066460609436 - moving ave loss 1.6762920858259116\n",
            "step 211 - loss 1.3550348281860352 - moving ave loss 1.6441663600619238\n",
            "step 212 - loss 1.5246891975402832 - moving ave loss 1.63221864380976\n",
            "step 213 - loss 1.8015015125274658 - moving ave loss 1.6491469306815305\n",
            "step 214 - loss 1.1584384441375732 - moving ave loss 1.6000760820271347\n",
            "step 215 - loss 1.3858349323272705 - moving ave loss 1.5786519670571482\n",
            "step 216 - loss 1.9434287548065186 - moving ave loss 1.6151296458320852\n",
            "step 217 - loss 2.240889549255371 - moving ave loss 1.6777056361744138\n",
            "step 218 - loss 1.3682855367660522 - moving ave loss 1.6467636262335776\n",
            "step 219 - loss 1.3609983921051025 - moving ave loss 1.61818710282073\n",
            "step 220 - loss 1.5247581005096436 - moving ave loss 1.6088442025896215\n",
            "step 221 - loss 1.6347525119781494 - moving ave loss 1.6114350335284744\n",
            "Finish 17 epoch(es)\n",
            "step 222 - loss 1.4562230110168457 - moving ave loss 1.5959138312773116\n",
            "step 223 - loss 1.6642839908599854 - moving ave loss 1.602750847235579\n",
            "step 224 - loss 1.4770840406417847 - moving ave loss 1.5901841665761995\n",
            "step 225 - loss 1.3176732063293457 - moving ave loss 1.5629330705515143\n",
            "step 226 - loss 1.5155274868011475 - moving ave loss 1.5581925121764777\n",
            "step 227 - loss 1.5086668729782104 - moving ave loss 1.553239948256651\n",
            "step 228 - loss 1.5470247268676758 - moving ave loss 1.5526184261177536\n",
            "step 229 - loss 1.41888427734375 - moving ave loss 1.5392450112403533\n",
            "step 230 - loss 1.3825676441192627 - moving ave loss 1.5235772745282443\n",
            "step 231 - loss 1.9029810428619385 - moving ave loss 1.5615176513616138\n",
            "step 232 - loss 1.6340121030807495 - moving ave loss 1.5687670965335276\n",
            "step 233 - loss 2.002734899520874 - moving ave loss 1.6121638768322624\n",
            "step 234 - loss 1.647200345993042 - moving ave loss 1.6156675237483404\n",
            "Finish 18 epoch(es)\n",
            "step 235 - loss 1.654294729232788 - moving ave loss 1.6195302442967852\n",
            "step 236 - loss 1.9474132061004639 - moving ave loss 1.652318540477153\n",
            "step 237 - loss 1.2667841911315918 - moving ave loss 1.6137651055425968\n",
            "step 238 - loss 1.9116616249084473 - moving ave loss 1.6435547574791818\n",
            "step 239 - loss 1.5679996013641357 - moving ave loss 1.6359992418676772\n",
            "step 240 - loss 1.524064064025879 - moving ave loss 1.6248057240834974\n",
            "step 241 - loss 1.5146557092666626 - moving ave loss 1.613790722601814\n",
            "step 242 - loss 1.6634501218795776 - moving ave loss 1.6187566625295904\n",
            "step 243 - loss 1.3774828910827637 - moving ave loss 1.5946292853849078\n",
            "step 244 - loss 1.4595476388931274 - moving ave loss 1.5811211207357299\n",
            "step 245 - loss 1.5210330486297607 - moving ave loss 1.575112313525133\n",
            "step 246 - loss 1.5000563859939575 - moving ave loss 1.5676067207720155\n",
            "step 247 - loss 1.586979627609253 - moving ave loss 1.5695440114557393\n",
            "Finish 19 epoch(es)\n",
            "step 248 - loss 1.8849895000457764 - moving ave loss 1.6010885603147431\n",
            "step 249 - loss 1.3241908550262451 - moving ave loss 1.5733987897858934\n",
            "step 250 - loss 1.4895057678222656 - moving ave loss 1.5650094875895306\n",
            "Checkpoint at step 250\n",
            "step 251 - loss 1.6722288131713867 - moving ave loss 1.5757314201477164\n",
            "step 252 - loss 1.5628821849822998 - moving ave loss 1.5744464966311746\n",
            "step 253 - loss 1.9263945817947388 - moving ave loss 1.6096413051475311\n",
            "step 254 - loss 1.1977925300598145 - moving ave loss 1.5684564276387594\n",
            "step 255 - loss 1.684330701828003 - moving ave loss 1.5800438550576839\n",
            "step 256 - loss 1.8328498601913452 - moving ave loss 1.60532445557105\n",
            "step 257 - loss 1.7368391752243042 - moving ave loss 1.6184759275363756\n",
            "step 258 - loss 1.3981437683105469 - moving ave loss 1.5964427116137927\n",
            "step 259 - loss 1.5094776153564453 - moving ave loss 1.587746201988058\n",
            "step 260 - loss 1.345190167427063 - moving ave loss 1.5634905985319585\n",
            "Finish 20 epoch(es)\n",
            "step 261 - loss 1.824728012084961 - moving ave loss 1.5896143398872589\n",
            "step 262 - loss 1.970410943031311 - moving ave loss 1.6276940002016642\n",
            "step 263 - loss 1.339646577835083 - moving ave loss 1.598889257965006\n",
            "step 264 - loss 1.6212513446807861 - moving ave loss 1.6011254666365842\n",
            "step 265 - loss 1.5876414775848389 - moving ave loss 1.5997770677314098\n",
            "step 266 - loss 1.5871611833572388 - moving ave loss 1.5985154792939928\n",
            "step 267 - loss 1.8520764112472534 - moving ave loss 1.6238715724893191\n",
            "step 268 - loss 1.4994536638259888 - moving ave loss 1.6114297816229861\n",
            "step 269 - loss 1.4156440496444702 - moving ave loss 1.5918512084251346\n",
            "step 270 - loss 1.8827283382415771 - moving ave loss 1.6209389214067789\n",
            "step 271 - loss 1.6336442232131958 - moving ave loss 1.6222094515874206\n",
            "step 272 - loss 1.3657095432281494 - moving ave loss 1.5965594607514935\n",
            "step 273 - loss 1.654902696609497 - moving ave loss 1.602393784337294\n",
            "Finish 21 epoch(es)\n",
            "step 274 - loss 1.4846632480621338 - moving ave loss 1.5906207307097782\n",
            "step 275 - loss 1.2585434913635254 - moving ave loss 1.557413006775153\n",
            "step 276 - loss 1.6987042427062988 - moving ave loss 1.5715421303682677\n",
            "step 277 - loss 1.2391865253448486 - moving ave loss 1.538306569865926\n",
            "step 278 - loss 1.4508260488510132 - moving ave loss 1.5295585177644346\n",
            "step 279 - loss 1.9499046802520752 - moving ave loss 1.5715931340131988\n",
            "step 280 - loss 1.7272377014160156 - moving ave loss 1.5871575907534805\n",
            "step 281 - loss 1.3724110126495361 - moving ave loss 1.5656829329430861\n",
            "step 282 - loss 1.6017489433288574 - moving ave loss 1.5692895339816633\n",
            "step 283 - loss 1.5981061458587646 - moving ave loss 1.5721711951693733\n",
            "step 284 - loss 1.5356030464172363 - moving ave loss 1.5685143802941597\n",
            "step 285 - loss 1.3302778005599976 - moving ave loss 1.5446907223207436\n",
            "step 286 - loss 1.8768653869628906 - moving ave loss 1.5779081887849584\n",
            "Finish 22 epoch(es)\n",
            "step 287 - loss 1.5196702480316162 - moving ave loss 1.5720843947096244\n",
            "step 288 - loss 1.5301803350448608 - moving ave loss 1.5678939887431482\n",
            "step 289 - loss 1.6120855808258057 - moving ave loss 1.572313147951414\n",
            "step 290 - loss 1.3441736698150635 - moving ave loss 1.549499200137779\n",
            "step 291 - loss 1.379223346710205 - moving ave loss 1.5324716147950217\n",
            "step 292 - loss 1.7247068881988525 - moving ave loss 1.5516951421354048\n",
            "step 293 - loss 1.480391263961792 - moving ave loss 1.5445647543180434\n",
            "step 294 - loss 1.6228338479995728 - moving ave loss 1.5523916636861963\n",
            "step 295 - loss 1.6276546716690063 - moving ave loss 1.5599179644844772\n",
            "step 296 - loss 1.5252110958099365 - moving ave loss 1.5564472776170233\n",
            "step 297 - loss 1.456794023513794 - moving ave loss 1.5464819522067004\n",
            "step 298 - loss 1.5277740955352783 - moving ave loss 1.5446111665395583\n",
            "step 299 - loss 1.316643238067627 - moving ave loss 1.5218143736923653\n",
            "Finish 23 epoch(es)\n",
            "step 300 - loss 1.6349644660949707 - moving ave loss 1.5331293829326258\n",
            "step 301 - loss 1.6145374774932861 - moving ave loss 1.541270192388692\n",
            "step 302 - loss 1.4510257244110107 - moving ave loss 1.532245745590924\n",
            "step 303 - loss 1.4821341037750244 - moving ave loss 1.527234581409334\n",
            "step 304 - loss 1.3819077014923096 - moving ave loss 1.5127018934176315\n",
            "step 305 - loss 1.3412175178527832 - moving ave loss 1.4955534558611467\n",
            "step 306 - loss 1.3001463413238525 - moving ave loss 1.4760127444074174\n",
            "step 307 - loss 1.4471588134765625 - moving ave loss 1.473127351314332\n",
            "step 308 - loss 1.769371747970581 - moving ave loss 1.5027517909799568\n",
            "step 309 - loss 1.3959099054336548 - moving ave loss 1.4920676024253265\n",
            "step 310 - loss 1.2527379989624023 - moving ave loss 1.4681346420790342\n",
            "step 311 - loss 1.4914653301239014 - moving ave loss 1.4704677108835211\n",
            "step 312 - loss 2.06974720954895 - moving ave loss 1.5303956607500642\n",
            "Finish 24 epoch(es)\n",
            "step 313 - loss 2.0499958992004395 - moving ave loss 1.5823556845951017\n",
            "step 314 - loss 1.8094241619110107 - moving ave loss 1.6050625323266927\n",
            "step 315 - loss 1.5039576292037964 - moving ave loss 1.594952042014403\n",
            "step 316 - loss 1.2777068614959717 - moving ave loss 1.5632275239625597\n",
            "step 317 - loss 1.5052986145019531 - moving ave loss 1.557434633016499\n",
            "step 318 - loss 1.3983421325683594 - moving ave loss 1.541525382971685\n",
            "step 319 - loss 1.2801871299743652 - moving ave loss 1.5153915576719532\n",
            "step 320 - loss 1.6714673042297363 - moving ave loss 1.5309991323277317\n",
            "step 321 - loss 1.7318655252456665 - moving ave loss 1.5510857716195252\n",
            "step 322 - loss 1.779101848602295 - moving ave loss 1.5738873793178023\n",
            "step 323 - loss 2.0021140575408936 - moving ave loss 1.6167100471401115\n",
            "step 324 - loss 1.567766547203064 - moving ave loss 1.6118156971464068\n",
            "step 325 - loss 1.8893510103225708 - moving ave loss 1.6395692284640233\n",
            "Finish 25 epoch(es)\n",
            "step 326 - loss 1.42486572265625 - moving ave loss 1.618098877883246\n",
            "step 327 - loss 1.4926280975341797 - moving ave loss 1.6055517998483393\n",
            "step 328 - loss 1.255256175994873 - moving ave loss 1.5705222374629926\n",
            "step 329 - loss 1.718714714050293 - moving ave loss 1.5853414851217227\n",
            "step 330 - loss 1.4090847969055176 - moving ave loss 1.5677158163001021\n",
            "step 331 - loss 1.2705094814300537 - moving ave loss 1.5379951828130973\n",
            "step 332 - loss 1.7447535991668701 - moving ave loss 1.5586710244484747\n",
            "step 333 - loss 1.4447047710418701 - moving ave loss 1.5472743991078142\n",
            "step 334 - loss 1.363446593284607 - moving ave loss 1.5288916185254935\n",
            "step 335 - loss 1.4927148818969727 - moving ave loss 1.5252739448626413\n",
            "step 336 - loss 1.6758127212524414 - moving ave loss 1.5403278225016213\n",
            "step 337 - loss 1.604950189590454 - moving ave loss 1.5467900592105046\n",
            "step 338 - loss 1.429121971130371 - moving ave loss 1.5350232504024914\n",
            "Finish 26 epoch(es)\n",
            "step 339 - loss 1.931882381439209 - moving ave loss 1.5747091635061632\n",
            "step 340 - loss 1.6631605625152588 - moving ave loss 1.5835543034070727\n",
            "step 341 - loss 1.7585281133651733 - moving ave loss 1.6010516844028828\n",
            "step 342 - loss 1.3345433473587036 - moving ave loss 1.5744008506984648\n",
            "step 343 - loss 1.2445068359375 - moving ave loss 1.5414114492223683\n",
            "step 344 - loss 1.7991929054260254 - moving ave loss 1.5671895948427341\n",
            "step 345 - loss 1.3563337326049805 - moving ave loss 1.5461040086189588\n",
            "step 346 - loss 1.420776128768921 - moving ave loss 1.5335712206339551\n",
            "step 347 - loss 1.7290198802947998 - moving ave loss 1.5531160866000395\n",
            "step 348 - loss 1.789548635482788 - moving ave loss 1.5767593414883145\n",
            "step 349 - loss 1.7653310298919678 - moving ave loss 1.59561651032868\n",
            "step 350 - loss 1.6295231580734253 - moving ave loss 1.5990071751031545\n",
            "step 351 - loss 1.43239426612854 - moving ave loss 1.5823458842056932\n",
            "Finish 27 epoch(es)\n",
            "step 352 - loss 1.3954071998596191 - moving ave loss 1.5636520157710858\n",
            "step 353 - loss 1.5737383365631104 - moving ave loss 1.5646606478502882\n",
            "step 354 - loss 1.5544309616088867 - moving ave loss 1.5636376792261482\n",
            "step 355 - loss 1.5412347316741943 - moving ave loss 1.5613973844709528\n",
            "step 356 - loss 1.4944515228271484 - moving ave loss 1.5547027983065724\n",
            "step 357 - loss 1.269101858139038 - moving ave loss 1.526142704289819\n",
            "step 358 - loss 1.3788120746612549 - moving ave loss 1.5114096413269626\n",
            "step 359 - loss 1.5795528888702393 - moving ave loss 1.5182239660812904\n",
            "step 360 - loss 2.191429853439331 - moving ave loss 1.5855445548170946\n",
            "step 361 - loss 1.9137158393859863 - moving ave loss 1.6183616832739838\n",
            "step 362 - loss 1.4764600992202759 - moving ave loss 1.604171524868613\n",
            "step 363 - loss 1.7126126289367676 - moving ave loss 1.6150156352754286\n",
            "step 364 - loss 2.083209753036499 - moving ave loss 1.6618350470515357\n",
            "Finish 28 epoch(es)\n",
            "step 365 - loss 1.4995269775390625 - moving ave loss 1.6456042401002884\n",
            "step 366 - loss 1.2454371452331543 - moving ave loss 1.605587530613575\n",
            "step 367 - loss 1.5271785259246826 - moving ave loss 1.5977466301446857\n",
            "step 368 - loss 1.3010913133621216 - moving ave loss 1.5680810984664293\n",
            "step 369 - loss 1.1324567794799805 - moving ave loss 1.5245186665677843\n",
            "step 370 - loss 1.7102360725402832 - moving ave loss 1.5430904071650342\n",
            "step 371 - loss 1.3031092882156372 - moving ave loss 1.5190922952700947\n",
            "step 372 - loss 1.6277574300765991 - moving ave loss 1.5299588087507452\n",
            "step 373 - loss 1.6314513683319092 - moving ave loss 1.5401080647088616\n",
            "step 374 - loss 1.6163034439086914 - moving ave loss 1.5477276026288447\n",
            "step 375 - loss 1.4064784049987793 - moving ave loss 1.5336026828658382\n",
            "step 376 - loss 1.6431299448013306 - moving ave loss 1.5445554090593876\n",
            "step 377 - loss 1.1410291194915771 - moving ave loss 1.5042027801026066\n",
            "Finish 29 epoch(es)\n",
            "step 378 - loss 1.4894688129425049 - moving ave loss 1.5027293833865965\n",
            "step 379 - loss 1.6531392335891724 - moving ave loss 1.517770368406854\n",
            "step 380 - loss 1.2150732278823853 - moving ave loss 1.4875006543544071\n",
            "step 381 - loss 1.568581461906433 - moving ave loss 1.4956087351096097\n",
            "step 382 - loss 1.6531896591186523 - moving ave loss 1.5113668275105139\n",
            "step 383 - loss 1.534212589263916 - moving ave loss 1.5136514036858542\n",
            "step 384 - loss 1.2014389038085938 - moving ave loss 1.4824301536981281\n",
            "step 385 - loss 1.603611946105957 - moving ave loss 1.494548332938911\n",
            "step 386 - loss 1.6001243591308594 - moving ave loss 1.505105935558106\n",
            "step 387 - loss 1.4635381698608398 - moving ave loss 1.5009491589883794\n",
            "step 388 - loss 2.169893741607666 - moving ave loss 1.5678436172503083\n",
            "step 389 - loss 1.5718441009521484 - moving ave loss 1.5682436656204923\n",
            "step 390 - loss 2.0649707317352295 - moving ave loss 1.617916372231966\n",
            "Finish 30 epoch(es)\n",
            "step 391 - loss 1.5786066055297852 - moving ave loss 1.6139853955617478\n",
            "step 392 - loss 1.2639350891113281 - moving ave loss 1.5789803649167058\n",
            "step 393 - loss 2.1545255184173584 - moving ave loss 1.6365348802667712\n",
            "step 394 - loss 1.7804642915725708 - moving ave loss 1.6509278213973513\n",
            "step 395 - loss 1.2390638589859009 - moving ave loss 1.6097414251562063\n",
            "step 396 - loss 1.4359384775161743 - moving ave loss 1.5923611303922032\n",
            "step 397 - loss 1.449795126914978 - moving ave loss 1.5781045300444807\n",
            "step 398 - loss 1.3940205574035645 - moving ave loss 1.559696132780389\n",
            "step 399 - loss 1.4508161544799805 - moving ave loss 1.5488081349503484\n",
            "step 400 - loss 1.1227879524230957 - moving ave loss 1.5062061166976233\n",
            "step 401 - loss 1.6818219423294067 - moving ave loss 1.5237676992608016\n",
            "step 402 - loss 1.2165569067001343 - moving ave loss 1.493046620004735\n",
            "step 403 - loss 1.3344874382019043 - moving ave loss 1.477190701824452\n",
            "Finish 31 epoch(es)\n",
            "step 404 - loss 1.0895984172821045 - moving ave loss 1.4384314733702173\n",
            "step 405 - loss 1.3683295249938965 - moving ave loss 1.4314212785325853\n",
            "step 406 - loss 1.770371675491333 - moving ave loss 1.46531631822846\n",
            "step 407 - loss 1.3330740928649902 - moving ave loss 1.452092095692113\n",
            "step 408 - loss 1.3734979629516602 - moving ave loss 1.4442326824180678\n",
            "step 409 - loss 1.2348310947418213 - moving ave loss 1.4232925236504432\n",
            "step 410 - loss 1.8106107711791992 - moving ave loss 1.4620243484033189\n",
            "step 411 - loss 1.2108341455459595 - moving ave loss 1.436905328117583\n",
            "step 412 - loss 1.308530569076538 - moving ave loss 1.4240678522134784\n",
            "step 413 - loss 1.8995988368988037 - moving ave loss 1.471620950682011\n",
            "step 414 - loss 1.5461174249649048 - moving ave loss 1.4790705981103005\n",
            "step 415 - loss 1.4581351280212402 - moving ave loss 1.4769770511013947\n",
            "step 416 - loss 1.4998579025268555 - moving ave loss 1.4792651362439408\n",
            "Finish 32 epoch(es)\n",
            "step 417 - loss 1.5075528621673584 - moving ave loss 1.4820939088362826\n",
            "step 418 - loss 1.5060606002807617 - moving ave loss 1.4844905779807305\n",
            "step 419 - loss 1.6957035064697266 - moving ave loss 1.5056118708296302\n",
            "step 420 - loss 1.29049813747406 - moving ave loss 1.4841004974940732\n",
            "step 421 - loss 1.603058934211731 - moving ave loss 1.4959963411658392\n",
            "step 422 - loss 1.6924136877059937 - moving ave loss 1.5156380758198547\n",
            "step 423 - loss 1.490694522857666 - moving ave loss 1.5131437205236358\n",
            "step 424 - loss 1.3898892402648926 - moving ave loss 1.5008182724977615\n",
            "step 425 - loss 1.6514942646026611 - moving ave loss 1.5158858717082515\n",
            "step 426 - loss 1.5200817584991455 - moving ave loss 1.516305460387341\n",
            "step 427 - loss 1.4682037830352783 - moving ave loss 1.5114952926521346\n",
            "step 428 - loss 1.4035756587982178 - moving ave loss 1.5007033292667429\n",
            "step 429 - loss 1.2610456943511963 - moving ave loss 1.4767375657751884\n",
            "Finish 33 epoch(es)\n",
            "step 430 - loss 1.2939860820770264 - moving ave loss 1.4584624174053722\n",
            "step 431 - loss 1.7273273468017578 - moving ave loss 1.4853489103450106\n",
            "step 432 - loss 1.700075387954712 - moving ave loss 1.5068215581059807\n",
            "step 433 - loss 1.2047028541564941 - moving ave loss 1.4766096877110322\n",
            "step 434 - loss 1.4065821170806885 - moving ave loss 1.4696069306479977\n",
            "step 435 - loss 1.5531318187713623 - moving ave loss 1.4779594194603343\n",
            "step 436 - loss 1.462538242340088 - moving ave loss 1.4764173017483098\n",
            "step 437 - loss 1.3093138933181763 - moving ave loss 1.4597069609052964\n",
            "step 438 - loss 1.2761667966842651 - moving ave loss 1.4413529444831934\n",
            "step 439 - loss 1.4373743534088135 - moving ave loss 1.4409550853757553\n",
            "step 440 - loss 1.4961674213409424 - moving ave loss 1.446476318972274\n",
            "step 441 - loss 1.372525691986084 - moving ave loss 1.439081256273655\n",
            "step 442 - loss 1.5232203006744385 - moving ave loss 1.4474951607137334\n",
            "Finish 34 epoch(es)\n",
            "step 443 - loss 1.5907844305038452 - moving ave loss 1.4618240876927446\n",
            "step 444 - loss 1.299642562866211 - moving ave loss 1.4456059352100912\n",
            "step 445 - loss 1.1304370164871216 - moving ave loss 1.4140890433377944\n",
            "step 446 - loss 2.1583361625671387 - moving ave loss 1.4885137552607288\n",
            "step 447 - loss 1.2476608753204346 - moving ave loss 1.4644284672666996\n",
            "step 448 - loss 1.6164649724960327 - moving ave loss 1.479632117789633\n",
            "step 449 - loss 1.5014429092407227 - moving ave loss 1.481813196934742\n",
            "step 450 - loss 1.4635941982269287 - moving ave loss 1.4799912970639606\n",
            "step 451 - loss 1.549296498298645 - moving ave loss 1.486921817187429\n",
            "step 452 - loss 1.151423454284668 - moving ave loss 1.453371980897153\n",
            "step 453 - loss 1.3957760334014893 - moving ave loss 1.4476123861475867\n",
            "step 454 - loss 1.5709660053253174 - moving ave loss 1.45994774806536\n",
            "step 455 - loss 1.3957089185714722 - moving ave loss 1.4535238651159712\n",
            "Finish 35 epoch(es)\n",
            "step 456 - loss 1.4090096950531006 - moving ave loss 1.4490724481096842\n",
            "step 457 - loss 1.506591558456421 - moving ave loss 1.454824359144358\n",
            "step 458 - loss 1.231150507926941 - moving ave loss 1.4324569740226163\n",
            "step 459 - loss 1.8220067024230957 - moving ave loss 1.4714119468626643\n",
            "step 460 - loss 1.3780121803283691 - moving ave loss 1.4620719702092349\n",
            "step 461 - loss 1.4632632732391357 - moving ave loss 1.4621911005122248\n",
            "step 462 - loss 1.3862563371658325 - moving ave loss 1.4545976241775855\n",
            "step 463 - loss 1.4596794843673706 - moving ave loss 1.4551058101965642\n",
            "step 464 - loss 1.7918576002120972 - moving ave loss 1.4887809891981174\n",
            "step 465 - loss 1.2131186723709106 - moving ave loss 1.4612147575153966\n",
            "step 466 - loss 1.464784860610962 - moving ave loss 1.4615717678249531\n",
            "step 467 - loss 1.4958207607269287 - moving ave loss 1.4649966671151509\n",
            "step 468 - loss 1.1429109573364258 - moving ave loss 1.4327880961372783\n",
            "Finish 36 epoch(es)\n",
            "step 469 - loss 1.4163551330566406 - moving ave loss 1.4311447998292146\n",
            "step 470 - loss 1.5586228370666504 - moving ave loss 1.4438926035529582\n",
            "step 471 - loss 1.1643847227096558 - moving ave loss 1.4159418154686279\n",
            "step 472 - loss 1.394729495048523 - moving ave loss 1.4138205834266175\n",
            "step 473 - loss 1.171389102935791 - moving ave loss 1.389577435377535\n",
            "step 474 - loss 1.046941876411438 - moving ave loss 1.3553138794809254\n",
            "step 475 - loss 1.2649331092834473 - moving ave loss 1.3462758024611776\n",
            "step 476 - loss 1.791856050491333 - moving ave loss 1.3908338272641934\n",
            "step 477 - loss 1.4731982946395874 - moving ave loss 1.399070274001733\n",
            "step 478 - loss 1.311622977256775 - moving ave loss 1.390325544327237\n",
            "step 479 - loss 1.8488489389419556 - moving ave loss 1.436177883788709\n",
            "step 480 - loss 1.425625205039978 - moving ave loss 1.4351226159138357\n",
            "step 481 - loss 1.6283924579620361 - moving ave loss 1.4544496001186558\n",
            "Finish 37 epoch(es)\n",
            "step 482 - loss 1.3310747146606445 - moving ave loss 1.4421121115728548\n",
            "step 483 - loss 1.6467595100402832 - moving ave loss 1.4625768514195976\n",
            "step 484 - loss 1.559822916984558 - moving ave loss 1.4723014579760938\n",
            "step 485 - loss 1.999813199043274 - moving ave loss 1.525052632082812\n",
            "step 486 - loss 1.205249309539795 - moving ave loss 1.4930722998285104\n",
            "step 487 - loss 1.5239105224609375 - moving ave loss 1.4961561220917532\n",
            "step 488 - loss 1.0016088485717773 - moving ave loss 1.4467013947397558\n",
            "step 489 - loss 1.422621726989746 - moving ave loss 1.4442934279647548\n",
            "step 490 - loss 1.445609211921692 - moving ave loss 1.4444250063604487\n",
            "step 491 - loss 1.4285527467727661 - moving ave loss 1.4428377804016805\n",
            "step 492 - loss 1.2415834665298462 - moving ave loss 1.422712349014497\n",
            "step 493 - loss 1.4946810007095337 - moving ave loss 1.4299092141840009\n",
            "step 494 - loss 1.770780324935913 - moving ave loss 1.4639963252591923\n",
            "Finish 38 epoch(es)\n",
            "step 495 - loss 1.8097747564315796 - moving ave loss 1.498574168376431\n",
            "step 496 - loss 1.1623457670211792 - moving ave loss 1.4649513282409061\n",
            "step 497 - loss 1.238515019416809 - moving ave loss 1.4423076973584963\n",
            "step 498 - loss 1.4192308187484741 - moving ave loss 1.440000009497494\n",
            "step 499 - loss 0.9735623598098755 - moving ave loss 1.3933562445287324\n",
            "step 500 - loss 1.484383463859558 - moving ave loss 1.402458966461815\n",
            "Checkpoint at step 500\n",
            "step 501 - loss 1.5865143537521362 - moving ave loss 1.4208645051908473\n",
            "step 502 - loss 1.3992860317230225 - moving ave loss 1.4187066578440648\n",
            "step 503 - loss 1.5054097175598145 - moving ave loss 1.42737696381564\n",
            "step 504 - loss 1.2223867177963257 - moving ave loss 1.4068779392137087\n",
            "step 505 - loss 1.114908218383789 - moving ave loss 1.3776809671307169\n",
            "step 506 - loss 1.4974286556243896 - moving ave loss 1.389655735980084\n",
            "step 507 - loss 1.3262004852294922 - moving ave loss 1.3833102109050248\n",
            "Finish 39 epoch(es)\n",
            "step 508 - loss 1.3501654863357544 - moving ave loss 1.3799957384480979\n",
            "step 509 - loss 1.1829144954681396 - moving ave loss 1.3602876141501021\n",
            "step 510 - loss 1.3825514316558838 - moving ave loss 1.3625139959006802\n",
            "step 511 - loss 1.7277445793151855 - moving ave loss 1.3990370542421307\n",
            "step 512 - loss 1.4017510414123535 - moving ave loss 1.399308452959153\n",
            "step 513 - loss 1.0283246040344238 - moving ave loss 1.36221006806668\n",
            "step 514 - loss 1.2392456531524658 - moving ave loss 1.3499136265752585\n",
            "step 515 - loss 1.3476982116699219 - moving ave loss 1.3496920850847247\n",
            "step 516 - loss 1.3934627771377563 - moving ave loss 1.354069154290028\n",
            "step 517 - loss 1.7205724716186523 - moving ave loss 1.3907194860228906\n",
            "step 518 - loss 1.7520616054534912 - moving ave loss 1.4268536979659507\n",
            "step 519 - loss 1.229849934577942 - moving ave loss 1.40715332162715\n",
            "step 520 - loss 1.797685980796814 - moving ave loss 1.4462065875441164\n",
            "Finish 40 epoch(es)\n",
            "step 521 - loss 1.1716786623001099 - moving ave loss 1.4187537950197158\n",
            "step 522 - loss 1.3778303861618042 - moving ave loss 1.4146614541339246\n",
            "step 523 - loss 1.470095157623291 - moving ave loss 1.4202048244828611\n",
            "step 524 - loss 0.9492617845535278 - moving ave loss 1.3731105204899279\n",
            "step 525 - loss 1.6005889177322388 - moving ave loss 1.395858360214159\n",
            "step 526 - loss 1.9337809085845947 - moving ave loss 1.4496506150512025\n",
            "step 527 - loss 1.6083087921142578 - moving ave loss 1.465516432757508\n",
            "step 528 - loss 1.4150192737579346 - moving ave loss 1.4604667168575507\n",
            "step 529 - loss 1.1544623374938965 - moving ave loss 1.4298662789211851\n",
            "step 530 - loss 1.1531383991241455 - moving ave loss 1.402193490941481\n",
            "step 531 - loss 1.6224007606506348 - moving ave loss 1.4242142179123964\n",
            "step 532 - loss 1.8376941680908203 - moving ave loss 1.4655622129302388\n",
            "step 533 - loss 1.1788463592529297 - moving ave loss 1.436890627562508\n",
            "Finish 41 epoch(es)\n",
            "step 534 - loss 1.0724999904632568 - moving ave loss 1.4004515638525827\n",
            "step 535 - loss 1.3604702949523926 - moving ave loss 1.3964534369625636\n",
            "step 536 - loss 1.5703232288360596 - moving ave loss 1.4138404161499132\n",
            "step 537 - loss 1.9107292890548706 - moving ave loss 1.463529303440409\n",
            "step 538 - loss 0.9496734738349915 - moving ave loss 1.4121437204798672\n",
            "step 539 - loss 1.3028664588928223 - moving ave loss 1.4012159943211628\n",
            "step 540 - loss 1.3448824882507324 - moving ave loss 1.3955826437141197\n",
            "step 541 - loss 1.4485197067260742 - moving ave loss 1.4008763500153152\n",
            "step 542 - loss 1.1400794982910156 - moving ave loss 1.3747966648428853\n",
            "step 543 - loss 1.1086688041687012 - moving ave loss 1.348183878775467\n",
            "step 544 - loss 1.3248887062072754 - moving ave loss 1.3458543615186478\n",
            "step 545 - loss 1.5535550117492676 - moving ave loss 1.3666244265417098\n",
            "step 546 - loss 1.197784423828125 - moving ave loss 1.3497404262703514\n",
            "Finish 42 epoch(es)\n",
            "step 547 - loss 1.2754204273223877 - moving ave loss 1.342308426375555\n",
            "step 548 - loss 1.136025071144104 - moving ave loss 1.32168009085241\n",
            "step 549 - loss 1.67305326461792 - moving ave loss 1.356817408228961\n",
            "step 550 - loss 1.6660997867584229 - moving ave loss 1.3877456460819073\n",
            "step 551 - loss 1.362779140472412 - moving ave loss 1.385248995520958\n",
            "step 552 - loss 1.7819710969924927 - moving ave loss 1.4249212056681113\n",
            "step 553 - loss 1.3179551362991333 - moving ave loss 1.4142245987312136\n",
            "step 554 - loss 1.2868040800094604 - moving ave loss 1.4014825468590384\n",
            "step 555 - loss 1.463777780532837 - moving ave loss 1.4077120702264183\n",
            "step 556 - loss 1.3935701847076416 - moving ave loss 1.4062978816745406\n",
            "step 557 - loss 1.4716602563858032 - moving ave loss 1.4128341191456668\n",
            "step 558 - loss 1.4486384391784668 - moving ave loss 1.4164145511489468\n",
            "step 559 - loss 1.5369141101837158 - moving ave loss 1.4284645070524238\n",
            "Finish 43 epoch(es)\n",
            "step 560 - loss 1.171884298324585 - moving ave loss 1.40280648617964\n",
            "step 561 - loss 1.3535609245300293 - moving ave loss 1.397881930014679\n",
            "step 562 - loss 1.6235239505767822 - moving ave loss 1.4204461320708892\n",
            "step 563 - loss 1.6001737117767334 - moving ave loss 1.4384188900414736\n",
            "step 564 - loss 1.716494083404541 - moving ave loss 1.4662264093777804\n",
            "step 565 - loss 0.9125409722328186 - moving ave loss 1.4108578656632842\n",
            "step 566 - loss 1.6608591079711914 - moving ave loss 1.4358579898940749\n",
            "step 567 - loss 1.5361990928649902 - moving ave loss 1.4458921001911667\n",
            "step 568 - loss 2.075779914855957 - moving ave loss 1.5088808816576458\n",
            "step 569 - loss 1.0036966800689697 - moving ave loss 1.4583624614987782\n",
            "step 570 - loss 1.594102382659912 - moving ave loss 1.4719364536148916\n",
            "step 571 - loss 1.512543797492981 - moving ave loss 1.4759971880027005\n",
            "step 572 - loss 1.5264639854431152 - moving ave loss 1.4810438677467421\n",
            "Finish 44 epoch(es)\n",
            "step 573 - loss 1.1132227182388306 - moving ave loss 1.4442617527959511\n",
            "step 574 - loss 1.3436527252197266 - moving ave loss 1.4342008500383288\n",
            "step 575 - loss 1.3508319854736328 - moving ave loss 1.4258639635818593\n",
            "step 576 - loss 1.711702823638916 - moving ave loss 1.454447849587565\n",
            "step 577 - loss 1.5684069395065308 - moving ave loss 1.4658437585794615\n",
            "step 578 - loss 1.3041646480560303 - moving ave loss 1.4496758475271183\n",
            "step 579 - loss 1.1568551063537598 - moving ave loss 1.4203937734097825\n",
            "step 580 - loss 1.3920621871948242 - moving ave loss 1.4175606147882867\n",
            "step 581 - loss 1.7043209075927734 - moving ave loss 1.4462366440687353\n",
            "step 582 - loss 1.2093758583068848 - moving ave loss 1.4225505654925503\n",
            "step 583 - loss 1.3303920030593872 - moving ave loss 1.4133347092492339\n",
            "step 584 - loss 1.1159613132476807 - moving ave loss 1.3835973696490784\n",
            "step 585 - loss 1.5642688274383545 - moving ave loss 1.401664515428006\n",
            "Finish 45 epoch(es)\n",
            "step 586 - loss 1.829759120941162 - moving ave loss 1.4444739759793217\n",
            "step 587 - loss 1.4834376573562622 - moving ave loss 1.4483703441170157\n",
            "step 588 - loss 1.1321310997009277 - moving ave loss 1.416746419675407\n",
            "step 589 - loss 1.4038639068603516 - moving ave loss 1.4154581683939014\n",
            "step 590 - loss 1.4730608463287354 - moving ave loss 1.4212184361873847\n",
            "step 591 - loss 1.3120694160461426 - moving ave loss 1.4103035341732606\n",
            "step 592 - loss 1.410372018814087 - moving ave loss 1.4103103826373433\n",
            "step 593 - loss 1.2029263973236084 - moving ave loss 1.38957198410597\n",
            "step 594 - loss 1.2734684944152832 - moving ave loss 1.3779616351369013\n",
            "step 595 - loss 1.1448006629943848 - moving ave loss 1.3546455379226496\n",
            "step 596 - loss 1.709855079650879 - moving ave loss 1.3901664920954726\n",
            "step 597 - loss 1.3292293548583984 - moving ave loss 1.3840727783717652\n",
            "step 598 - loss 1.3063751459121704 - moving ave loss 1.3763030151258058\n",
            "Finish 46 epoch(es)\n",
            "step 599 - loss 0.8939484357833862 - moving ave loss 1.3280675571915639\n",
            "step 600 - loss 1.3497231006622314 - moving ave loss 1.3302331115386308\n",
            "step 601 - loss 1.3105993270874023 - moving ave loss 1.328269733093508\n",
            "step 602 - loss 1.108017921447754 - moving ave loss 1.3062445519289327\n",
            "step 603 - loss 1.3278617858886719 - moving ave loss 1.3084062753249066\n",
            "step 604 - loss 1.3895446062088013 - moving ave loss 1.316520108413296\n",
            "step 605 - loss 1.4244792461395264 - moving ave loss 1.3273160221859193\n",
            "step 606 - loss 1.3916330337524414 - moving ave loss 1.3337477233425716\n",
            "step 607 - loss 1.5056068897247314 - moving ave loss 1.3509336399807876\n",
            "step 608 - loss 1.9787946939468384 - moving ave loss 1.4137197453773929\n",
            "step 609 - loss 1.6776623725891113 - moving ave loss 1.4401140080985648\n",
            "step 610 - loss 1.30152428150177 - moving ave loss 1.4262550354388852\n",
            "step 611 - loss 1.1442458629608154 - moving ave loss 1.3980541181910782\n",
            "Finish 47 epoch(es)\n",
            "step 612 - loss 1.503267765045166 - moving ave loss 1.408575482876487\n",
            "step 613 - loss 1.3715875148773193 - moving ave loss 1.4048766860765702\n",
            "step 614 - loss 1.6468517780303955 - moving ave loss 1.4290741952719528\n",
            "step 615 - loss 1.7172842025756836 - moving ave loss 1.4578951960023259\n",
            "step 616 - loss 1.4653499126434326 - moving ave loss 1.4586406676664365\n",
            "step 617 - loss 1.2325772047042847 - moving ave loss 1.4360343213702214\n",
            "step 618 - loss 1.1657613515853882 - moving ave loss 1.409007024391738\n",
            "step 619 - loss 1.1369874477386475 - moving ave loss 1.381805066726429\n",
            "step 620 - loss 1.326817274093628 - moving ave loss 1.3763062874631489\n",
            "step 621 - loss 1.0953725576400757 - moving ave loss 1.3482129144808415\n",
            "step 622 - loss 1.385871410369873 - moving ave loss 1.3519787640697445\n",
            "step 623 - loss 1.1236135959625244 - moving ave loss 1.3291422472590226\n",
            "step 624 - loss 1.5371754169464111 - moving ave loss 1.3499455642277614\n",
            "Finish 48 epoch(es)\n",
            "step 625 - loss 1.7012453079223633 - moving ave loss 1.3850755385972215\n",
            "step 626 - loss 1.1900956630706787 - moving ave loss 1.3655775510445674\n",
            "step 627 - loss 1.0522143840789795 - moving ave loss 1.3342412343480086\n",
            "step 628 - loss 1.5183978080749512 - moving ave loss 1.352656891720703\n",
            "step 629 - loss 1.311842918395996 - moving ave loss 1.3485754943882322\n",
            "step 630 - loss 1.8092937469482422 - moving ave loss 1.3946473196442333\n",
            "step 631 - loss 1.1773263216018677 - moving ave loss 1.3729152198399968\n",
            "step 632 - loss 1.6133171319961548 - moving ave loss 1.3969554110556126\n",
            "step 633 - loss 1.1670844554901123 - moving ave loss 1.3739683154990627\n",
            "step 634 - loss 1.0830729007720947 - moving ave loss 1.344878774026366\n",
            "step 635 - loss 1.17533278465271 - moving ave loss 1.3279241750890003\n",
            "step 636 - loss 1.0411072969436646 - moving ave loss 1.2992424872744668\n",
            "step 637 - loss 1.5986846685409546 - moving ave loss 1.3291867054011157\n",
            "Finish 49 epoch(es)\n",
            "step 638 - loss 1.002663493156433 - moving ave loss 1.2965343841766475\n",
            "step 639 - loss 1.2288899421691895 - moving ave loss 1.2897699399759017\n",
            "step 640 - loss 1.8177459239959717 - moving ave loss 1.3425675383779088\n",
            "step 641 - loss 1.8663766384124756 - moving ave loss 1.3949484483813657\n",
            "step 642 - loss 1.259429931640625 - moving ave loss 1.3813965967072916\n",
            "step 643 - loss 1.6987860202789307 - moving ave loss 1.4131355390644555\n",
            "step 644 - loss 1.3676986694335938 - moving ave loss 1.4085918521013694\n",
            "step 645 - loss 1.38132905960083 - moving ave loss 1.4058655728513156\n",
            "step 646 - loss 1.6269938945770264 - moving ave loss 1.4279784050238868\n",
            "step 647 - loss 1.381887435913086 - moving ave loss 1.4233693081128067\n",
            "step 648 - loss 1.0468066930770874 - moving ave loss 1.3857130466092347\n",
            "step 649 - loss 1.0460491180419922 - moving ave loss 1.3517466537525105\n",
            "step 650 - loss 1.4324653148651123 - moving ave loss 1.3598185198637707\n",
            "Finish 50 epoch(es)\n",
            "step 651 - loss 1.4647979736328125 - moving ave loss 1.3703164652406747\n",
            "step 652 - loss 1.2385629415512085 - moving ave loss 1.3571411128717281\n",
            "step 653 - loss 1.2016428709030151 - moving ave loss 1.3415912886748569\n",
            "step 654 - loss 1.2405781745910645 - moving ave loss 1.3314899772664777\n",
            "step 655 - loss 1.2887446880340576 - moving ave loss 1.3272154483432357\n",
            "step 656 - loss 1.5347846746444702 - moving ave loss 1.347972370973359\n",
            "step 657 - loss 1.6258211135864258 - moving ave loss 1.3757572452346658\n",
            "step 658 - loss 1.417997121810913 - moving ave loss 1.3799812328922905\n",
            "step 659 - loss 1.5505309104919434 - moving ave loss 1.3970362006522556\n",
            "step 660 - loss 1.65474534034729 - moving ave loss 1.4228071146217591\n",
            "step 661 - loss 0.9998477101325989 - moving ave loss 1.3805111741728433\n",
            "step 662 - loss 1.499314308166504 - moving ave loss 1.3923914875722094\n",
            "step 663 - loss 1.1363487243652344 - moving ave loss 1.366787211251512\n",
            "Finish 51 epoch(es)\n",
            "step 664 - loss 1.2930567264556885 - moving ave loss 1.3594141627719296\n",
            "step 665 - loss 1.3473658561706543 - moving ave loss 1.358209332111802\n",
            "step 666 - loss 1.4972944259643555 - moving ave loss 1.3721178414970574\n",
            "step 667 - loss 1.1616356372833252 - moving ave loss 1.351069621075684\n",
            "step 668 - loss 1.5102862119674683 - moving ave loss 1.3669912801648625\n",
            "step 669 - loss 1.7223014831542969 - moving ave loss 1.402522300463806\n",
            "step 670 - loss 1.4502577781677246 - moving ave loss 1.407295848234198\n",
            "step 671 - loss 0.9799832105636597 - moving ave loss 1.3645645844671441\n",
            "step 672 - loss 1.1915204524993896 - moving ave loss 1.347260171270369\n",
            "step 673 - loss 1.5624566078186035 - moving ave loss 1.3687798149251924\n",
            "step 674 - loss 1.59244966506958 - moving ave loss 1.3911467999396312\n",
            "step 675 - loss 1.0414390563964844 - moving ave loss 1.3561760255853166\n",
            "step 676 - loss 1.3784503936767578 - moving ave loss 1.3584034623944607\n",
            "Finish 52 epoch(es)\n",
            "step 677 - loss 1.403745412826538 - moving ave loss 1.3629376574376686\n",
            "step 678 - loss 1.2942631244659424 - moving ave loss 1.356070204140496\n",
            "step 679 - loss 1.2378805875778198 - moving ave loss 1.3442512424842283\n",
            "step 680 - loss 1.460350751876831 - moving ave loss 1.3558611934234885\n",
            "step 681 - loss 1.5512067079544067 - moving ave loss 1.3753957448765803\n",
            "step 682 - loss 1.6673263311386108 - moving ave loss 1.4045888035027834\n",
            "step 683 - loss 1.1613552570343018 - moving ave loss 1.3802654488559354\n",
            "step 684 - loss 1.0206626653671265 - moving ave loss 1.3443051705070546\n",
            "step 685 - loss 1.6516928672790527 - moving ave loss 1.3750439401842545\n",
            "step 686 - loss 1.4590463638305664 - moving ave loss 1.3834441825488857\n",
            "step 687 - loss 1.5388176441192627 - moving ave loss 1.3989815287059235\n",
            "step 688 - loss 1.4589197635650635 - moving ave loss 1.4049753521918376\n",
            "step 689 - loss 1.3612455129623413 - moving ave loss 1.400602368268888\n",
            "Finish 53 epoch(es)\n",
            "step 690 - loss 1.3099219799041748 - moving ave loss 1.3915343294324165\n",
            "step 691 - loss 1.274599552154541 - moving ave loss 1.379840851704629\n",
            "step 692 - loss 1.3399486541748047 - moving ave loss 1.3758516319516467\n",
            "step 693 - loss 1.4748762845993042 - moving ave loss 1.3857540972164126\n",
            "step 694 - loss 1.5686595439910889 - moving ave loss 1.4040446418938803\n",
            "step 695 - loss 1.3324044942855835 - moving ave loss 1.3968806271330507\n",
            "step 696 - loss 1.3191485404968262 - moving ave loss 1.3891074184694283\n",
            "step 697 - loss 1.395342469215393 - moving ave loss 1.3897309235440247\n",
            "step 698 - loss 1.4864635467529297 - moving ave loss 1.3994041858649153\n",
            "step 699 - loss 1.6950933933258057 - moving ave loss 1.4289731066110045\n",
            "step 700 - loss 1.3109010457992554 - moving ave loss 1.4171659005298296\n",
            "step 701 - loss 1.0284488201141357 - moving ave loss 1.3782941924882604\n",
            "step 702 - loss 1.4602099657058716 - moving ave loss 1.3864857698100215\n",
            "Finish 54 epoch(es)\n",
            "step 703 - loss 1.0374071598052979 - moving ave loss 1.351577908809549\n",
            "step 704 - loss 1.4759867191314697 - moving ave loss 1.364018789841741\n",
            "step 705 - loss 1.138902187347412 - moving ave loss 1.3415071295923082\n",
            "step 706 - loss 1.1220810413360596 - moving ave loss 1.3195645207666835\n",
            "step 707 - loss 1.6264348030090332 - moving ave loss 1.3502515489909186\n",
            "step 708 - loss 1.3637698888778687 - moving ave loss 1.3516033829796137\n",
            "step 709 - loss 1.615254521369934 - moving ave loss 1.3779684968186459\n",
            "step 710 - loss 1.5745584964752197 - moving ave loss 1.3976274967843034\n",
            "step 711 - loss 1.3075463771820068 - moving ave loss 1.3886193848240738\n",
            "step 712 - loss 1.8408143520355225 - moving ave loss 1.4338388815452188\n",
            "step 713 - loss 1.2893272638320923 - moving ave loss 1.4193877197739062\n",
            "step 714 - loss 1.2093290090560913 - moving ave loss 1.3983818487021247\n",
            "step 715 - loss 1.1309540271759033 - moving ave loss 1.3716390665495026\n",
            "Finish 55 epoch(es)\n",
            "step 716 - loss 1.6933943033218384 - moving ave loss 1.4038145902267363\n",
            "step 717 - loss 1.054787516593933 - moving ave loss 1.368911882863456\n",
            "step 718 - loss 1.3914315700531006 - moving ave loss 1.3711638515824207\n",
            "step 719 - loss 1.2670447826385498 - moving ave loss 1.3607519446880336\n",
            "step 720 - loss 1.0613696575164795 - moving ave loss 1.3308137159708784\n",
            "step 721 - loss 1.3543304204940796 - moving ave loss 1.3331653864231985\n",
            "step 722 - loss 1.094242811203003 - moving ave loss 1.309273128901179\n",
            "step 723 - loss 1.0232555866241455 - moving ave loss 1.2806713746734757\n",
            "step 724 - loss 1.2273634672164917 - moving ave loss 1.2753405839277774\n",
            "step 725 - loss 0.8956599831581116 - moving ave loss 1.2373725238508109\n",
            "step 726 - loss 1.3263165950775146 - moving ave loss 1.2462669309734813\n",
            "step 727 - loss 1.4023624658584595 - moving ave loss 1.2618764844619792\n",
            "step 728 - loss 1.3253757953643799 - moving ave loss 1.2682264155522194\n",
            "Finish 56 epoch(es)\n",
            "step 729 - loss 1.3985601663589478 - moving ave loss 1.2812597906328924\n",
            "step 730 - loss 1.3840808868408203 - moving ave loss 1.2915419002536852\n",
            "step 731 - loss 1.3340120315551758 - moving ave loss 1.2957889133838343\n",
            "step 732 - loss 1.2086656093597412 - moving ave loss 1.287076582981425\n",
            "step 733 - loss 1.5138306617736816 - moving ave loss 1.3097519908606507\n",
            "step 734 - loss 1.2583930492401123 - moving ave loss 1.304616096698597\n",
            "step 735 - loss 1.904874563217163 - moving ave loss 1.3646419433504535\n",
            "step 736 - loss 1.1827021837234497 - moving ave loss 1.3464479673877532\n",
            "step 737 - loss 1.512399673461914 - moving ave loss 1.3630431379951693\n",
            "step 738 - loss 1.4167070388793945 - moving ave loss 1.368409528083592\n",
            "step 739 - loss 1.1587826013565063 - moving ave loss 1.3474468354108835\n",
            "step 740 - loss 1.539520502090454 - moving ave loss 1.3666542020788406\n",
            "step 741 - loss 1.446158528327942 - moving ave loss 1.3746046347037506\n",
            "Finish 57 epoch(es)\n",
            "step 742 - loss 0.9368178844451904 - moving ave loss 1.3308259596778946\n",
            "step 743 - loss 1.4514495134353638 - moving ave loss 1.3428883150536415\n",
            "step 744 - loss 1.3851509094238281 - moving ave loss 1.3471145744906603\n",
            "step 745 - loss 1.6271356344223022 - moving ave loss 1.3751166804838246\n",
            "step 746 - loss 1.252977728843689 - moving ave loss 1.3629027853198112\n",
            "step 747 - loss 1.3054792881011963 - moving ave loss 1.3571604355979499\n",
            "step 748 - loss 1.3123478889465332 - moving ave loss 1.352679180932808\n",
            "step 749 - loss 1.9984023571014404 - moving ave loss 1.4172514985496714\n",
            "step 750 - loss 1.1549105644226074 - moving ave loss 1.3910174051369648\n",
            "Checkpoint at step 750\n",
            "step 751 - loss 0.9698862433433533 - moving ave loss 1.3489042889576037\n",
            "step 752 - loss 1.741864562034607 - moving ave loss 1.388200316265304\n",
            "step 753 - loss 1.406897783279419 - moving ave loss 1.3900700629667155\n",
            "step 754 - loss 1.1303991079330444 - moving ave loss 1.3641029674633485\n",
            "Finish 58 epoch(es)\n",
            "step 755 - loss 1.3112388849258423 - moving ave loss 1.358816559209598\n",
            "step 756 - loss 1.7917574644088745 - moving ave loss 1.4021106497295257\n",
            "step 757 - loss 1.35872220993042 - moving ave loss 1.3977718057496153\n",
            "step 758 - loss 1.4350191354751587 - moving ave loss 1.4014965387221698\n",
            "step 759 - loss 1.4075826406478882 - moving ave loss 1.4021051489147418\n",
            "step 760 - loss 1.4728755950927734 - moving ave loss 1.409182193532545\n",
            "step 761 - loss 1.2564070224761963 - moving ave loss 1.39390467642691\n",
            "step 762 - loss 1.839232087135315 - moving ave loss 1.4384374174977506\n",
            "step 763 - loss 1.4288725852966309 - moving ave loss 1.4374809342776385\n",
            "step 764 - loss 1.4492383003234863 - moving ave loss 1.4386566708822233\n",
            "step 765 - loss 1.673688530921936 - moving ave loss 1.4621598568861947\n",
            "step 766 - loss 0.904590904712677 - moving ave loss 1.406402961668843\n",
            "step 767 - loss 1.047938346862793 - moving ave loss 1.370556500188238\n",
            "Finish 59 epoch(es)\n",
            "step 768 - loss 1.5435773134231567 - moving ave loss 1.38785858151173\n",
            "step 769 - loss 1.5753977298736572 - moving ave loss 1.4066124963479227\n",
            "step 770 - loss 1.7772928476333618 - moving ave loss 1.4436805314764667\n",
            "step 771 - loss 0.994652271270752 - moving ave loss 1.3987777054558954\n",
            "step 772 - loss 1.1778779029846191 - moving ave loss 1.3766877252087677\n",
            "step 773 - loss 1.5121402740478516 - moving ave loss 1.390232980092676\n",
            "step 774 - loss 0.9045311212539673 - moving ave loss 1.341662794208805\n",
            "step 775 - loss 1.1878687143325806 - moving ave loss 1.3262833862211827\n",
            "step 776 - loss 1.310483694076538 - moving ave loss 1.3247034170067182\n",
            "step 777 - loss 1.1807684898376465 - moving ave loss 1.310309924289811\n",
            "step 778 - loss 1.088773250579834 - moving ave loss 1.2881562569188134\n",
            "step 779 - loss 1.2628884315490723 - moving ave loss 1.2856294743818393\n",
            "step 780 - loss 1.3444762229919434 - moving ave loss 1.2915141492428497\n",
            "Finish 60 epoch(es)\n",
            "step 781 - loss 1.0829907655715942 - moving ave loss 1.2706618108757242\n",
            "step 782 - loss 1.580710530281067 - moving ave loss 1.3016666828162584\n",
            "step 783 - loss 1.3149161338806152 - moving ave loss 1.302991627922694\n",
            "step 784 - loss 1.2748603820800781 - moving ave loss 1.3001785033384325\n",
            "step 785 - loss 1.1041338443756104 - moving ave loss 1.2805740374421504\n",
            "step 786 - loss 1.8949655294418335 - moving ave loss 1.3420131866421188\n",
            "step 787 - loss 1.1706832647323608 - moving ave loss 1.324880194451143\n",
            "step 788 - loss 1.0935050249099731 - moving ave loss 1.301742677497026\n",
            "step 789 - loss 0.9481572508811951 - moving ave loss 1.2663841348354428\n",
            "step 790 - loss 1.2872085571289062 - moving ave loss 1.2684665770647892\n",
            "step 791 - loss 1.2171419858932495 - moving ave loss 1.2633341179476352\n",
            "step 792 - loss 0.8612438440322876 - moving ave loss 1.2231250905561004\n",
            "step 793 - loss 1.5574510097503662 - moving ave loss 1.256557682475527\n",
            "Finish 61 epoch(es)\n",
            "step 794 - loss 1.0322778224945068 - moving ave loss 1.2341296964774249\n",
            "step 795 - loss 1.5745619535446167 - moving ave loss 1.2681729221841442\n",
            "step 796 - loss 1.1923726797103882 - moving ave loss 1.2605928979367687\n",
            "step 797 - loss 1.2692697048187256 - moving ave loss 1.2614605786249644\n",
            "step 798 - loss 1.2646316289901733 - moving ave loss 1.2617776836614853\n",
            "step 799 - loss 1.0899136066436768 - moving ave loss 1.2445912759597046\n",
            "step 800 - loss 1.1333541870117188 - moving ave loss 1.2334675670649062\n",
            "step 801 - loss 1.40919029712677 - moving ave loss 1.2510398400710927\n",
            "step 802 - loss 1.1187946796417236 - moving ave loss 1.2378153240281558\n",
            "step 803 - loss 1.2232462167739868 - moving ave loss 1.236358413302739\n",
            "step 804 - loss 0.9129936099052429 - moving ave loss 1.2040219329629895\n",
            "step 805 - loss 1.1690762042999268 - moving ave loss 1.2005273600966833\n",
            "step 806 - loss 1.4542285203933716 - moving ave loss 1.2258974761263521\n",
            "Finish 62 epoch(es)\n",
            "step 807 - loss 1.278154730796814 - moving ave loss 1.2311232015933984\n",
            "step 808 - loss 1.0670372247695923 - moving ave loss 1.2147146039110177\n",
            "step 809 - loss 1.5252211093902588 - moving ave loss 1.245765254458942\n",
            "step 810 - loss 0.9234801530838013 - moving ave loss 1.213536744321428\n",
            "step 811 - loss 1.215681791305542 - moving ave loss 1.2137512490198394\n",
            "step 812 - loss 0.9592041373252869 - moving ave loss 1.1882965378503842\n",
            "step 813 - loss 1.2212486267089844 - moving ave loss 1.1915917467362442\n",
            "step 814 - loss 1.163472056388855 - moving ave loss 1.1887797777015052\n",
            "step 815 - loss 1.3063535690307617 - moving ave loss 1.200537156834431\n",
            "step 816 - loss 1.2565244436264038 - moving ave loss 1.2061358855136282\n",
            "step 817 - loss 1.5956294536590576 - moving ave loss 1.245085242328171\n",
            "step 818 - loss 1.400231122970581 - moving ave loss 1.2605998303924122\n",
            "step 819 - loss 1.1924309730529785 - moving ave loss 1.2537829446584687\n",
            "Finish 63 epoch(es)\n",
            "step 820 - loss 1.1222671270370483 - moving ave loss 1.2406313628963268\n",
            "step 821 - loss 1.0220686197280884 - moving ave loss 1.218775088579503\n",
            "step 822 - loss 1.078918695449829 - moving ave loss 1.2047894492665356\n",
            "step 823 - loss 1.6243102550506592 - moving ave loss 1.246741529844948\n",
            "step 824 - loss 1.173527717590332 - moving ave loss 1.2394201486194865\n",
            "step 825 - loss 0.9054217338562012 - moving ave loss 1.206020307143158\n",
            "step 826 - loss 1.0407123565673828 - moving ave loss 1.1894895120855806\n",
            "step 827 - loss 1.3460547924041748 - moving ave loss 1.20514604011744\n",
            "step 828 - loss 1.4308078289031982 - moving ave loss 1.227712218996016\n",
            "step 829 - loss 1.5205130577087402 - moving ave loss 1.2569923028672885\n",
            "step 830 - loss 1.0209873914718628 - moving ave loss 1.233391811727746\n",
            "step 831 - loss 1.2636839151382446 - moving ave loss 1.236421022068796\n",
            "step 832 - loss 1.0229573249816895 - moving ave loss 1.2150746523600853\n",
            "Finish 64 epoch(es)\n",
            "step 833 - loss 0.7914259433746338 - moving ave loss 1.1727097814615401\n",
            "step 834 - loss 1.0904152393341064 - moving ave loss 1.1644803272487967\n",
            "step 835 - loss 1.1268293857574463 - moving ave loss 1.1607152330996617\n",
            "step 836 - loss 0.9700757265090942 - moving ave loss 1.141651282440605\n",
            "step 837 - loss 0.9528789520263672 - moving ave loss 1.1227740493991814\n",
            "step 838 - loss 1.0415148735046387 - moving ave loss 1.1146481318097272\n",
            "step 839 - loss 0.9134968519210815 - moving ave loss 1.0945330038208625\n",
            "step 840 - loss 1.7206470966339111 - moving ave loss 1.1571444131021673\n",
            "step 841 - loss 1.7233455181121826 - moving ave loss 1.2137645236031689\n",
            "step 842 - loss 1.5619041919708252 - moving ave loss 1.2485784904399346\n",
            "step 843 - loss 1.2880909442901611 - moving ave loss 1.2525297358249574\n",
            "step 844 - loss 1.3072798252105713 - moving ave loss 1.258004744763519\n",
            "step 845 - loss 1.310487985610962 - moving ave loss 1.2632530688482633\n",
            "Finish 65 epoch(es)\n",
            "step 846 - loss 1.216700792312622 - moving ave loss 1.2585978411946992\n",
            "step 847 - loss 1.0826585292816162 - moving ave loss 1.241003910003391\n",
            "step 848 - loss 1.4213998317718506 - moving ave loss 1.2590435021802369\n",
            "step 849 - loss 1.2204041481018066 - moving ave loss 1.2551795667723937\n",
            "step 850 - loss 1.3806259632110596 - moving ave loss 1.2677242064162604\n",
            "step 851 - loss 1.2011559009552002 - moving ave loss 1.2610673758701543\n",
            "step 852 - loss 0.9584317803382874 - moving ave loss 1.2308038163169677\n",
            "step 853 - loss 1.6278529167175293 - moving ave loss 1.2705087263570238\n",
            "step 854 - loss 0.9038679599761963 - moving ave loss 1.2338446497189413\n",
            "step 855 - loss 1.2896888256072998 - moving ave loss 1.2394290673077772\n",
            "step 856 - loss 1.141994833946228 - moving ave loss 1.2296856439716222\n",
            "step 857 - loss 1.342982292175293 - moving ave loss 1.2410153087919893\n",
            "step 858 - loss 1.3209939002990723 - moving ave loss 1.2490131679426977\n",
            "Finish 66 epoch(es)\n",
            "step 859 - loss 1.4251577854156494 - moving ave loss 1.266627629689993\n",
            "step 860 - loss 0.802063524723053 - moving ave loss 1.220171219193299\n",
            "step 861 - loss 1.5382165908813477 - moving ave loss 1.251975756362104\n",
            "step 862 - loss 1.1420555114746094 - moving ave loss 1.2409837318733545\n",
            "step 863 - loss 1.5792150497436523 - moving ave loss 1.2748068636603842\n",
            "step 864 - loss 1.5988600254058838 - moving ave loss 1.307212179834934\n",
            "step 865 - loss 1.2265552282333374 - moving ave loss 1.2991464846747744\n",
            "step 866 - loss 1.1262297630310059 - moving ave loss 1.2818548125103977\n",
            "step 867 - loss 1.7705626487731934 - moving ave loss 1.3307255961366773\n",
            "step 868 - loss 1.161909818649292 - moving ave loss 1.3138440183879387\n",
            "step 869 - loss 1.1114985942840576 - moving ave loss 1.2936094759775507\n",
            "step 870 - loss 1.4265685081481934 - moving ave loss 1.306905379194615\n",
            "step 871 - loss 1.3428843021392822 - moving ave loss 1.3105032714890819\n",
            "Finish 67 epoch(es)\n",
            "step 872 - loss 1.5465598106384277 - moving ave loss 1.3341089254040166\n",
            "step 873 - loss 1.0780727863311768 - moving ave loss 1.3085053114967327\n",
            "step 874 - loss 1.4854888916015625 - moving ave loss 1.3262036695072157\n",
            "step 875 - loss 1.1970059871673584 - moving ave loss 1.31328390127323\n",
            "step 876 - loss 1.6084671020507812 - moving ave loss 1.3428022213509851\n",
            "step 877 - loss 1.5255963802337646 - moving ave loss 1.3610816372392631\n",
            "step 878 - loss 0.9892675280570984 - moving ave loss 1.3239002263210466\n",
            "step 879 - loss 1.0898295640945435 - moving ave loss 1.3004931600983964\n",
            "step 880 - loss 0.9766252040863037 - moving ave loss 1.268106364497187\n",
            "step 881 - loss 1.3942946195602417 - moving ave loss 1.2807251900034926\n",
            "step 882 - loss 1.3978769779205322 - moving ave loss 1.2924403687951964\n",
            "step 883 - loss 1.2370191812515259 - moving ave loss 1.2868982500408295\n",
            "step 884 - loss 1.0448157787322998 - moving ave loss 1.2626900029099766\n",
            "Finish 68 epoch(es)\n",
            "step 885 - loss 1.1059762239456177 - moving ave loss 1.2470186250135407\n",
            "step 886 - loss 1.1303273439407349 - moving ave loss 1.2353494969062602\n",
            "step 887 - loss 1.2060877084732056 - moving ave loss 1.2324233180629547\n",
            "step 888 - loss 1.6210572719573975 - moving ave loss 1.271286713452399\n",
            "step 889 - loss 1.006798267364502 - moving ave loss 1.2448378688436093\n",
            "step 890 - loss 1.2546597719192505 - moving ave loss 1.2458200591511734\n",
            "step 891 - loss 1.319538950920105 - moving ave loss 1.2531919483280667\n",
            "step 892 - loss 1.303295373916626 - moving ave loss 1.2582022908869226\n",
            "step 893 - loss 1.5131137371063232 - moving ave loss 1.2836934355088627\n",
            "step 894 - loss 1.1909300088882446 - moving ave loss 1.274417092846801\n",
            "step 895 - loss 0.9437620639801025 - moving ave loss 1.2413515899601313\n",
            "step 896 - loss 1.0638575553894043 - moving ave loss 1.2236021865030586\n",
            "step 897 - loss 1.4363892078399658 - moving ave loss 1.2448808886367493\n",
            "Finish 69 epoch(es)\n",
            "step 898 - loss 1.2235743999481201 - moving ave loss 1.2427502397678865\n",
            "step 899 - loss 1.1039890050888062 - moving ave loss 1.2288741162999783\n",
            "step 900 - loss 1.1817986965179443 - moving ave loss 1.224166574321775\n",
            "step 901 - loss 1.6200793981552124 - moving ave loss 1.2637578567051186\n",
            "step 902 - loss 0.9013513326644897 - moving ave loss 1.2275172043010558\n",
            "step 903 - loss 1.0191590785980225 - moving ave loss 1.2066813917307524\n",
            "step 904 - loss 1.1255555152893066 - moving ave loss 1.1985688040866078\n",
            "step 905 - loss 1.2414156198501587 - moving ave loss 1.202853485662963\n",
            "step 906 - loss 1.3986999988555908 - moving ave loss 1.2224381369822257\n",
            "step 907 - loss 0.982090413570404 - moving ave loss 1.1984033646410437\n",
            "step 908 - loss 1.5980477333068848 - moving ave loss 1.2383678015076278\n",
            "step 909 - loss 1.2295174598693848 - moving ave loss 1.2374827673438036\n",
            "step 910 - loss 1.2803692817687988 - moving ave loss 1.2417714187863031\n",
            "Finish 70 epoch(es)\n",
            "step 911 - loss 1.2740106582641602 - moving ave loss 1.2449953427340887\n",
            "step 912 - loss 1.4079142808914185 - moving ave loss 1.2612872365498218\n",
            "step 913 - loss 1.229320764541626 - moving ave loss 1.2580905893490022\n",
            "step 914 - loss 1.3642503023147583 - moving ave loss 1.2687065606455779\n",
            "step 915 - loss 1.1225528717041016 - moving ave loss 1.2540911917514301\n",
            "step 916 - loss 1.041548728942871 - moving ave loss 1.2328369454705743\n",
            "step 917 - loss 0.837723970413208 - moving ave loss 1.1933256479648378\n",
            "step 918 - loss 1.3883440494537354 - moving ave loss 1.2128274881137275\n",
            "step 919 - loss 1.4003853797912598 - moving ave loss 1.2315832772814808\n",
            "step 920 - loss 1.077636957168579 - moving ave loss 1.2161886452701907\n",
            "step 921 - loss 1.4463307857513428 - moving ave loss 1.2392028593183058\n",
            "step 922 - loss 1.2552837133407593 - moving ave loss 1.2408109447205513\n",
            "step 923 - loss 1.0482914447784424 - moving ave loss 1.2215589947263403\n",
            "Finish 71 epoch(es)\n",
            "step 924 - loss 1.392305850982666 - moving ave loss 1.238633680351973\n",
            "step 925 - loss 1.578607439994812 - moving ave loss 1.272631056316257\n",
            "step 926 - loss 0.9957441687583923 - moving ave loss 1.2449423675604707\n",
            "step 927 - loss 1.2599468231201172 - moving ave loss 1.2464428131164353\n",
            "step 928 - loss 1.660348892211914 - moving ave loss 1.2878334210259832\n",
            "step 929 - loss 1.0598013401031494 - moving ave loss 1.2650302129336999\n",
            "step 930 - loss 1.0496830940246582 - moving ave loss 1.2434955010427957\n",
            "step 931 - loss 1.0641536712646484 - moving ave loss 1.2255613180649811\n",
            "step 932 - loss 1.3440628051757812 - moving ave loss 1.2374114667760612\n",
            "step 933 - loss 1.0498031377792358 - moving ave loss 1.2186506338763785\n",
            "step 934 - loss 1.2307164669036865 - moving ave loss 1.2198572171791093\n",
            "step 935 - loss 1.0930345058441162 - moving ave loss 1.20717494604561\n",
            "step 936 - loss 1.2279291152954102 - moving ave loss 1.20925036297059\n",
            "Finish 72 epoch(es)\n",
            "step 937 - loss 0.9473360776901245 - moving ave loss 1.1830589344425435\n",
            "step 938 - loss 1.1244783401489258 - moving ave loss 1.177200875013182\n",
            "step 939 - loss 1.3519819974899292 - moving ave loss 1.1946789872608565\n",
            "step 940 - loss 1.2363907098770142 - moving ave loss 1.1988501595224723\n",
            "step 941 - loss 0.9138844013214111 - moving ave loss 1.1703535837023664\n",
            "step 942 - loss 0.9697994589805603 - moving ave loss 1.1502981712301859\n",
            "step 943 - loss 1.4940881729125977 - moving ave loss 1.184677171398427\n",
            "step 944 - loss 1.1348179578781128 - moving ave loss 1.1796912500463956\n",
            "step 945 - loss 1.1178656816482544 - moving ave loss 1.1735086932065815\n",
            "step 946 - loss 1.5826866626739502 - moving ave loss 1.2144264901533184\n",
            "step 947 - loss 1.3046787977218628 - moving ave loss 1.223451720910173\n",
            "step 948 - loss 1.1900285482406616 - moving ave loss 1.2201094036432218\n",
            "step 949 - loss 1.3311150074005127 - moving ave loss 1.2312099640189509\n",
            "Finish 73 epoch(es)\n",
            "step 950 - loss 1.3111823797225952 - moving ave loss 1.2392072055893153\n",
            "step 951 - loss 1.1232037544250488 - moving ave loss 1.2276068604728887\n",
            "step 952 - loss 1.6252355575561523 - moving ave loss 1.2673697301812152\n",
            "step 953 - loss 1.1896203756332397 - moving ave loss 1.2595947947264177\n",
            "step 954 - loss 1.3112941980361938 - moving ave loss 1.2647647350573954\n",
            "step 955 - loss 1.0534101724624634 - moving ave loss 1.2436292787979022\n",
            "step 956 - loss 0.9503144025802612 - moving ave loss 1.2142977911761381\n",
            "step 957 - loss 0.8668385744094849 - moving ave loss 1.1795518694994729\n",
            "step 958 - loss 1.2173643112182617 - moving ave loss 1.1833331136713516\n",
            "step 959 - loss 1.4974011182785034 - moving ave loss 1.2147399141320667\n",
            "step 960 - loss 1.3304778337478638 - moving ave loss 1.2263137060936464\n",
            "step 961 - loss 0.856421709060669 - moving ave loss 1.1893245063903486\n",
            "step 962 - loss 1.0823984146118164 - moving ave loss 1.1786318972124954\n",
            "Finish 74 epoch(es)\n",
            "step 963 - loss 1.7076854705810547 - moving ave loss 1.2315372545493515\n",
            "step 964 - loss 1.5899670124053955 - moving ave loss 1.267380230334956\n",
            "step 965 - loss 1.5919560194015503 - moving ave loss 1.2998378092416154\n",
            "step 966 - loss 1.0515024662017822 - moving ave loss 1.275004274937632\n",
            "step 967 - loss 0.825533390045166 - moving ave loss 1.2300571864483854\n",
            "step 968 - loss 0.7951177358627319 - moving ave loss 1.18656324138982\n",
            "step 969 - loss 1.388808012008667 - moving ave loss 1.2067877184517046\n",
            "step 970 - loss 1.3145966529846191 - moving ave loss 1.217568611904996\n",
            "step 971 - loss 1.4045450687408447 - moving ave loss 1.236266257588581\n",
            "step 972 - loss 1.0969910621643066 - moving ave loss 1.2223387380461537\n",
            "step 973 - loss 1.6634401082992554 - moving ave loss 1.2664488750714638\n",
            "step 974 - loss 0.7653094530105591 - moving ave loss 1.2163349328653732\n",
            "step 975 - loss 1.406579613685608 - moving ave loss 1.2353594009473967\n",
            "Finish 75 epoch(es)\n",
            "step 976 - loss 1.1651387214660645 - moving ave loss 1.2283373329992635\n",
            "step 977 - loss 1.00946044921875 - moving ave loss 1.2064496446212123\n",
            "step 978 - loss 1.9407634735107422 - moving ave loss 1.2798810275101653\n",
            "step 979 - loss 1.2437729835510254 - moving ave loss 1.2762702231142513\n",
            "step 980 - loss 1.289191484451294 - moving ave loss 1.2775623492479555\n",
            "step 981 - loss 1.477017879486084 - moving ave loss 1.2975079022717684\n",
            "step 982 - loss 1.4100077152252197 - moving ave loss 1.3087578835671134\n",
            "step 983 - loss 0.8691228628158569 - moving ave loss 1.2647943814919878\n",
            "step 984 - loss 1.0434355735778809 - moving ave loss 1.242658500700577\n",
            "step 985 - loss 1.65897536277771 - moving ave loss 1.2842901869082903\n",
            "step 986 - loss 0.8628662824630737 - moving ave loss 1.2421477964637686\n",
            "step 987 - loss 1.2237048149108887 - moving ave loss 1.2403034983084806\n",
            "step 988 - loss 1.0909839868545532 - moving ave loss 1.225371547163088\n",
            "Finish 76 epoch(es)\n",
            "step 989 - loss 1.1433463096618652 - moving ave loss 1.2171690234129657\n",
            "step 990 - loss 1.203438401222229 - moving ave loss 1.2157959611938922\n",
            "step 991 - loss 1.2743662595748901 - moving ave loss 1.221652991031992\n",
            "step 992 - loss 1.3187440633773804 - moving ave loss 1.2313620982665308\n",
            "step 993 - loss 1.3444124460220337 - moving ave loss 1.242667133042081\n",
            "step 994 - loss 1.4655945301055908 - moving ave loss 1.2649598727484321\n",
            "step 995 - loss 1.8229191303253174 - moving ave loss 1.3207557985061207\n",
            "step 996 - loss 1.2870075702667236 - moving ave loss 1.3173809756821808\n",
            "step 997 - loss 1.5890425443649292 - moving ave loss 1.3445471325504557\n",
            "step 998 - loss 0.9824051856994629 - moving ave loss 1.3083329378653563\n",
            "step 999 - loss 0.9493328928947449 - moving ave loss 1.2724329333682953\n",
            "step 1000 - loss 0.9403437376022339 - moving ave loss 1.2392240137916892\n",
            "Checkpoint at step 1000\n",
            "step 1001 - loss 1.4023511409759521 - moving ave loss 1.2555367265101156\n",
            "Finish 77 epoch(es)\n",
            "step 1002 - loss 1.0933690071105957 - moving ave loss 1.2393199545701636\n",
            "step 1003 - loss 1.141188383102417 - moving ave loss 1.2295067974233889\n",
            "step 1004 - loss 1.0504170656204224 - moving ave loss 1.2115978242430923\n",
            "step 1005 - loss 1.2096381187438965 - moving ave loss 1.2114018536931728\n",
            "step 1006 - loss 1.5750043392181396 - moving ave loss 1.2477621022456695\n",
            "step 1007 - loss 1.3878631591796875 - moving ave loss 1.2617722079390714\n",
            "step 1008 - loss 1.3048310279846191 - moving ave loss 1.2660780899436261\n",
            "step 1009 - loss 1.5768953561782837 - moving ave loss 1.297159816567092\n",
            "step 1010 - loss 1.6231799125671387 - moving ave loss 1.3297618261670967\n",
            "step 1011 - loss 0.9922770261764526 - moving ave loss 1.2960133461680323\n",
            "step 1012 - loss 1.188450813293457 - moving ave loss 1.2852570928805749\n",
            "step 1013 - loss 1.0829124450683594 - moving ave loss 1.2650226280993535\n",
            "step 1014 - loss 1.4926389455795288 - moving ave loss 1.2877842598473712\n",
            "Finish 78 epoch(es)\n",
            "step 1015 - loss 1.4996916055679321 - moving ave loss 1.3089749944194273\n",
            "step 1016 - loss 1.0563175678253174 - moving ave loss 1.2837092517600164\n",
            "step 1017 - loss 1.031056523323059 - moving ave loss 1.2584439789163206\n",
            "step 1018 - loss 1.204549789428711 - moving ave loss 1.2530545599675598\n",
            "step 1019 - loss 1.4553089141845703 - moving ave loss 1.2732799953892608\n",
            "step 1020 - loss 1.2508304119110107 - moving ave loss 1.2710350370414358\n",
            "step 1021 - loss 0.9814955592155457 - moving ave loss 1.242081089258847\n",
            "step 1022 - loss 0.8500834703445435 - moving ave loss 1.2028813273674166\n",
            "step 1023 - loss 1.0856579542160034 - moving ave loss 1.1911589900522754\n",
            "step 1024 - loss 1.356480598449707 - moving ave loss 1.2076911508920187\n",
            "step 1025 - loss 1.541712760925293 - moving ave loss 1.2410933118953462\n",
            "step 1026 - loss 1.439009189605713 - moving ave loss 1.260884899666383\n",
            "step 1027 - loss 1.374199390411377 - moving ave loss 1.2722163487408824\n",
            "Finish 79 epoch(es)\n",
            "step 1028 - loss 1.334033489227295 - moving ave loss 1.2783980627895237\n",
            "step 1029 - loss 1.2288148403167725 - moving ave loss 1.2734397405422486\n",
            "step 1030 - loss 1.229895830154419 - moving ave loss 1.2690853495034657\n",
            "step 1031 - loss 1.1276254653930664 - moving ave loss 1.254939361092426\n",
            "step 1032 - loss 1.0771230459213257 - moving ave loss 1.237157729575316\n",
            "step 1033 - loss 1.4912917613983154 - moving ave loss 1.262571132757616\n",
            "step 1034 - loss 0.9296582937240601 - moving ave loss 1.2292798488542604\n",
            "step 1035 - loss 1.2366983890533447 - moving ave loss 1.230021702874169\n",
            "step 1036 - loss 1.1362016201019287 - moving ave loss 1.2206396945969449\n",
            "step 1037 - loss 1.0512490272521973 - moving ave loss 1.20370062786247\n",
            "step 1038 - loss 1.1870620250701904 - moving ave loss 1.2020367675832422\n",
            "step 1039 - loss 1.0103405714035034 - moving ave loss 1.1828671479652684\n",
            "step 1040 - loss 1.0796799659729004 - moving ave loss 1.1725484297660316\n",
            "Finish 80 epoch(es)\n",
            "step 1041 - loss 1.4275264739990234 - moving ave loss 1.1980462341893308\n",
            "step 1042 - loss 1.3934730291366577 - moving ave loss 1.2175889136840636\n",
            "step 1043 - loss 1.5746886730194092 - moving ave loss 1.2532988896175983\n",
            "step 1044 - loss 1.4737820625305176 - moving ave loss 1.2753472069088903\n",
            "step 1045 - loss 1.5119552612304688 - moving ave loss 1.2990080123410481\n",
            "step 1046 - loss 1.676414966583252 - moving ave loss 1.3367487077652687\n",
            "step 1047 - loss 1.8196638822555542 - moving ave loss 1.3850402252142975\n",
            "step 1048 - loss 1.203126072883606 - moving ave loss 1.3668488099812284\n",
            "step 1049 - loss 1.125110387802124 - moving ave loss 1.342674967763318\n",
            "step 1050 - loss 0.9252008199691772 - moving ave loss 1.300927552983904\n",
            "step 1051 - loss 1.118276834487915 - moving ave loss 1.282662481134305\n",
            "step 1052 - loss 0.8095005750656128 - moving ave loss 1.235346290527436\n",
            "step 1053 - loss 1.4775488376617432 - moving ave loss 1.2595665452408669\n",
            "Finish 81 epoch(es)\n",
            "step 1054 - loss 1.2796722650527954 - moving ave loss 1.2615771172220598\n",
            "step 1055 - loss 0.7418702244758606 - moving ave loss 1.2096064279474399\n",
            "step 1056 - loss 0.9472030401229858 - moving ave loss 1.1833660891649944\n",
            "step 1057 - loss 1.2568165063858032 - moving ave loss 1.1907111308870753\n",
            "step 1058 - loss 1.0376572608947754 - moving ave loss 1.1754057438878454\n",
            "step 1059 - loss 1.3189048767089844 - moving ave loss 1.1897556571699592\n",
            "step 1060 - loss 1.0806525945663452 - moving ave loss 1.1788453509095977\n",
            "step 1061 - loss 1.0818774700164795 - moving ave loss 1.169148562820286\n",
            "step 1062 - loss 1.4855625629425049 - moving ave loss 1.2007899628325078\n",
            "step 1063 - loss 1.2790322303771973 - moving ave loss 1.2086141895869769\n",
            "step 1064 - loss 1.7233905792236328 - moving ave loss 1.2600918285506426\n",
            "step 1065 - loss 0.925474226474762 - moving ave loss 1.2266300683430547\n",
            "step 1066 - loss 1.2529172897338867 - moving ave loss 1.2292587904821377\n",
            "Finish 82 epoch(es)\n",
            "step 1067 - loss 0.838951587677002 - moving ave loss 1.1902280702016241\n",
            "step 1068 - loss 1.3190288543701172 - moving ave loss 1.2031081486184734\n",
            "step 1069 - loss 1.2846999168395996 - moving ave loss 1.2112673254405861\n",
            "step 1070 - loss 1.0307129621505737 - moving ave loss 1.1932118891115848\n",
            "step 1071 - loss 0.6938269138336182 - moving ave loss 1.143273391583788\n",
            "step 1072 - loss 1.4270433187484741 - moving ave loss 1.1716503843002566\n",
            "step 1073 - loss 0.9565544724464417 - moving ave loss 1.1501407931148753\n",
            "step 1074 - loss 1.0929852724075317 - moving ave loss 1.144425241044141\n",
            "step 1075 - loss 1.1777899265289307 - moving ave loss 1.14776170959262\n",
            "step 1076 - loss 0.9931524991989136 - moving ave loss 1.1323007885532492\n",
            "step 1077 - loss 0.9282771944999695 - moving ave loss 1.1118984291479213\n",
            "step 1078 - loss 1.26267671585083 - moving ave loss 1.126976257818212\n",
            "step 1079 - loss 1.0780632495880127 - moving ave loss 1.1220849569951923\n",
            "Finish 83 epoch(es)\n",
            "step 1080 - loss 0.8699650168418884 - moving ave loss 1.096872962979862\n",
            "step 1081 - loss 0.8735542893409729 - moving ave loss 1.074541095615973\n",
            "step 1082 - loss 0.8866086602210999 - moving ave loss 1.0557478520764858\n",
            "step 1083 - loss 1.307186245918274 - moving ave loss 1.0808916914606648\n",
            "step 1084 - loss 1.1336109638214111 - moving ave loss 1.0861636186967394\n",
            "step 1085 - loss 1.3968955278396606 - moving ave loss 1.1172368096110314\n",
            "step 1086 - loss 1.3589918613433838 - moving ave loss 1.1414123147842667\n",
            "step 1087 - loss 0.9286825060844421 - moving ave loss 1.1201393339142842\n",
            "step 1088 - loss 1.0051143169403076 - moving ave loss 1.1086368322168867\n",
            "step 1089 - loss 0.8525387644767761 - moving ave loss 1.0830270254428758\n",
            "step 1090 - loss 0.9264085292816162 - moving ave loss 1.06736517582675\n",
            "step 1091 - loss 1.1572482585906982 - moving ave loss 1.0763534841031448\n",
            "step 1092 - loss 1.071603775024414 - moving ave loss 1.0758785131952717\n",
            "Finish 84 epoch(es)\n",
            "step 1093 - loss 0.9408109784126282 - moving ave loss 1.0623717597170073\n",
            "step 1094 - loss 1.1769534349441528 - moving ave loss 1.0738299272397218\n",
            "step 1095 - loss 0.7900768518447876 - moving ave loss 1.0454546197002283\n",
            "step 1096 - loss 0.9578092098236084 - moving ave loss 1.0366900787125664\n",
            "step 1097 - loss 1.2937774658203125 - moving ave loss 1.062398817423341\n",
            "step 1098 - loss 1.3614776134490967 - moving ave loss 1.0923066970259165\n",
            "step 1099 - loss 1.324750304222107 - moving ave loss 1.1155510577455356\n",
            "step 1100 - loss 1.062281608581543 - moving ave loss 1.1102241128291364\n",
            "step 1101 - loss 1.2492172718048096 - moving ave loss 1.1241234287267037\n",
            "step 1102 - loss 2.2246832847595215 - moving ave loss 1.2341794143299853\n",
            "step 1103 - loss 1.3912482261657715 - moving ave loss 1.249886295513564\n",
            "step 1104 - loss 1.389604091644287 - moving ave loss 1.2638580751266364\n",
            "step 1105 - loss 1.3646211624145508 - moving ave loss 1.2739343838554278\n",
            "Finish 85 epoch(es)\n",
            "step 1106 - loss 0.9432163834571838 - moving ave loss 1.2408625838156033\n",
            "step 1107 - loss 0.7987495064735413 - moving ave loss 1.1966512760813972\n",
            "step 1108 - loss 1.2000389099121094 - moving ave loss 1.1969900394644684\n",
            "step 1109 - loss 1.5873249769210815 - moving ave loss 1.2360235332101297\n",
            "step 1110 - loss 1.4718875885009766 - moving ave loss 1.2596099387392146\n",
            "step 1111 - loss 0.9843060970306396 - moving ave loss 1.2320795545683572\n",
            "step 1112 - loss 0.9191023111343384 - moving ave loss 1.2007818302249553\n",
            "step 1113 - loss 1.0876078605651855 - moving ave loss 1.1894644332589783\n",
            "step 1114 - loss 1.8095959424972534 - moving ave loss 1.2514775841828059\n",
            "step 1115 - loss 1.406301736831665 - moving ave loss 1.2669599994476919\n",
            "step 1116 - loss 0.9498533010482788 - moving ave loss 1.2352493296077505\n",
            "step 1117 - loss 1.5615817308425903 - moving ave loss 1.2678825697312344\n",
            "step 1118 - loss 1.4130827188491821 - moving ave loss 1.2824025846430291\n",
            "Finish 86 epoch(es)\n",
            "step 1119 - loss 1.3351991176605225 - moving ave loss 1.2876822379447783\n",
            "step 1120 - loss 1.297025442123413 - moving ave loss 1.2886165583626419\n",
            "step 1121 - loss 1.0532782077789307 - moving ave loss 1.265082723304271\n",
            "step 1122 - loss 0.9086804986000061 - moving ave loss 1.2294425008338443\n",
            "step 1123 - loss 1.1869268417358398 - moving ave loss 1.225190934924044\n",
            "step 1124 - loss 1.0152252912521362 - moving ave loss 1.2041943705568532\n",
            "step 1125 - loss 1.2437208890914917 - moving ave loss 1.208147022410317\n",
            "step 1126 - loss 1.456632375717163 - moving ave loss 1.2329955577410017\n",
            "step 1127 - loss 1.400231122970581 - moving ave loss 1.2497191142639597\n",
            "step 1128 - loss 1.6130722761154175 - moving ave loss 1.2860544304491055\n",
            "step 1129 - loss 1.8723111152648926 - moving ave loss 1.3446800989306842\n",
            "step 1130 - loss 0.861159086227417 - moving ave loss 1.2963279976603574\n",
            "step 1131 - loss 1.001826286315918 - moving ave loss 1.2668778265259135\n",
            "Finish 87 epoch(es)\n",
            "step 1132 - loss 1.1370649337768555 - moving ave loss 1.2538965372510076\n",
            "step 1133 - loss 1.0426673889160156 - moving ave loss 1.2327736224175085\n",
            "step 1134 - loss 1.1057683229446411 - moving ave loss 1.2200730924702217\n",
            "step 1135 - loss 1.2409886121749878 - moving ave loss 1.2221646444406982\n",
            "step 1136 - loss 1.0339133739471436 - moving ave loss 1.2033395173913428\n",
            "step 1137 - loss 1.3469793796539307 - moving ave loss 1.2177035036176016\n",
            "step 1138 - loss 0.9783522486686707 - moving ave loss 1.1937683781227084\n",
            "step 1139 - loss 1.457888126373291 - moving ave loss 1.2201803529477666\n",
            "step 1140 - loss 1.4342173337936401 - moving ave loss 1.241584051032354\n",
            "step 1141 - loss 1.6131134033203125 - moving ave loss 1.2787369862611497\n",
            "step 1142 - loss 1.2252025604248047 - moving ave loss 1.2733835436775154\n",
            "step 1143 - loss 1.1441830396652222 - moving ave loss 1.2604634932762862\n",
            "step 1144 - loss 1.152327299118042 - moving ave loss 1.2496498738604618\n",
            "Finish 88 epoch(es)\n",
            "step 1145 - loss 1.2165772914886475 - moving ave loss 1.2463426156232804\n",
            "step 1146 - loss 1.7388542890548706 - moving ave loss 1.2955937829664395\n",
            "step 1147 - loss 1.204738974571228 - moving ave loss 1.2865083021269184\n",
            "step 1148 - loss 1.3145513534545898 - moving ave loss 1.2893126072596854\n",
            "step 1149 - loss 0.8929916024208069 - moving ave loss 1.2496805067757977\n",
            "step 1150 - loss 1.2958855628967285 - moving ave loss 1.2543010123878908\n",
            "step 1151 - loss 1.0877223014831543 - moving ave loss 1.2376431412974171\n",
            "step 1152 - loss 1.2024364471435547 - moving ave loss 1.234122471882031\n",
            "step 1153 - loss 0.9254924058914185 - moving ave loss 1.2032594652829698\n",
            "step 1154 - loss 1.2748596668243408 - moving ave loss 1.210419485437107\n",
            "step 1155 - loss 1.0228228569030762 - moving ave loss 1.191659822583704\n",
            "step 1156 - loss 0.9120503664016724 - moving ave loss 1.163698876965501\n",
            "step 1157 - loss 0.9545040130615234 - moving ave loss 1.1427793905751034\n",
            "Finish 89 epoch(es)\n",
            "step 1158 - loss 1.0650298595428467 - moving ave loss 1.1350044374718777\n",
            "step 1159 - loss 1.4382225275039673 - moving ave loss 1.1653262464750866\n",
            "step 1160 - loss 1.6969635486602783 - moving ave loss 1.218489976693606\n",
            "step 1161 - loss 1.4165959358215332 - moving ave loss 1.2383005726063987\n",
            "step 1162 - loss 0.8967932462692261 - moving ave loss 1.2041498399726813\n",
            "step 1163 - loss 0.9089616537094116 - moving ave loss 1.1746310213463544\n",
            "step 1164 - loss 1.4866453409194946 - moving ave loss 1.2058324533036684\n",
            "step 1165 - loss 0.8753585815429688 - moving ave loss 1.1727850661275985\n",
            "step 1166 - loss 1.151646375656128 - moving ave loss 1.1706711970804515\n",
            "step 1167 - loss 1.3211784362792969 - moving ave loss 1.1857219210003362\n",
            "step 1168 - loss 1.105698585510254 - moving ave loss 1.177719587451328\n",
            "step 1169 - loss 0.7628798484802246 - moving ave loss 1.1362356135542178\n",
            "step 1170 - loss 0.8576391339302063 - moving ave loss 1.1083759655918166\n",
            "Finish 90 epoch(es)\n",
            "step 1171 - loss 1.4167019128799438 - moving ave loss 1.1392085603206292\n",
            "step 1172 - loss 1.0112330913543701 - moving ave loss 1.1264110134240035\n",
            "step 1173 - loss 1.7369787693023682 - moving ave loss 1.1874677890118401\n",
            "step 1174 - loss 1.3672758340835571 - moving ave loss 1.2054485935190118\n",
            "step 1175 - loss 1.102921485900879 - moving ave loss 1.1951958827571985\n",
            "step 1176 - loss 1.0801222324371338 - moving ave loss 1.183688517725192\n",
            "step 1177 - loss 1.2604718208312988 - moving ave loss 1.1913668480358026\n",
            "step 1178 - loss 0.938439130783081 - moving ave loss 1.1660740763105306\n",
            "step 1179 - loss 1.5845036506652832 - moving ave loss 1.207917033746006\n",
            "step 1180 - loss 1.5987739562988281 - moving ave loss 1.2470027260012881\n",
            "step 1181 - loss 1.2199482917785645 - moving ave loss 1.244297282579016\n",
            "step 1182 - loss 0.9037618041038513 - moving ave loss 1.2102437347314994\n",
            "step 1183 - loss 0.9843364953994751 - moving ave loss 1.187653010798297\n",
            "Finish 91 epoch(es)\n",
            "step 1184 - loss 1.667581558227539 - moving ave loss 1.2356458655412212\n",
            "step 1185 - loss 1.4096952676773071 - moving ave loss 1.2530508057548297\n",
            "step 1186 - loss 1.4192848205566406 - moving ave loss 1.269674207235011\n",
            "step 1187 - loss 1.633338451385498 - moving ave loss 1.3060406316500597\n",
            "step 1188 - loss 1.131271243095398 - moving ave loss 1.2885636927945936\n",
            "step 1189 - loss 1.2467433214187622 - moving ave loss 1.2843816556570105\n",
            "step 1190 - loss 1.305572271347046 - moving ave loss 1.2865007172260141\n",
            "step 1191 - loss 0.9247791767120361 - moving ave loss 1.2503285631746164\n",
            "step 1192 - loss 1.3281712532043457 - moving ave loss 1.2581128321775894\n",
            "step 1193 - loss 0.8439612984657288 - moving ave loss 1.2166976788064034\n",
            "step 1194 - loss 1.2355475425720215 - moving ave loss 1.2185826651829654\n",
            "step 1195 - loss 1.0939031839370728 - moving ave loss 1.2061147170583761\n",
            "step 1196 - loss 0.8607192039489746 - moving ave loss 1.171575165747436\n",
            "Finish 92 epoch(es)\n",
            "step 1197 - loss 1.1630562543869019 - moving ave loss 1.1707232746113827\n",
            "step 1198 - loss 1.263271450996399 - moving ave loss 1.1799780922498844\n",
            "step 1199 - loss 0.776627779006958 - moving ave loss 1.1396430609255916\n",
            "step 1200 - loss 0.8864474296569824 - moving ave loss 1.1143234977987309\n",
            "step 1201 - loss 1.2718807458877563 - moving ave loss 1.1300792226076335\n",
            "step 1202 - loss 1.511913776397705 - moving ave loss 1.1682626779866405\n",
            "step 1203 - loss 1.2287298440933228 - moving ave loss 1.1743093945973089\n",
            "step 1204 - loss 1.0844972133636475 - moving ave loss 1.1653281764739427\n",
            "step 1205 - loss 1.0995063781738281 - moving ave loss 1.1587459966439313\n",
            "step 1206 - loss 0.8692055344581604 - moving ave loss 1.1297919504253542\n",
            "step 1207 - loss 1.38289213180542 - moving ave loss 1.1551019685633608\n",
            "step 1208 - loss 1.164077877998352 - moving ave loss 1.15599955950686\n",
            "step 1209 - loss 0.9317389726638794 - moving ave loss 1.133573500822562\n",
            "Finish 93 epoch(es)\n",
            "step 1210 - loss 0.9050313234329224 - moving ave loss 1.1107192830835981\n",
            "step 1211 - loss 1.1906657218933105 - moving ave loss 1.1187139269645694\n",
            "step 1212 - loss 0.8657135963439941 - moving ave loss 1.0934138939025118\n",
            "step 1213 - loss 1.4526772499084473 - moving ave loss 1.1293402295031054\n",
            "step 1214 - loss 0.8915137052536011 - moving ave loss 1.1055575770781552\n",
            "step 1215 - loss 1.2743356227874756 - moving ave loss 1.1224353816490873\n",
            "step 1216 - loss 1.471583366394043 - moving ave loss 1.1573501801235828\n",
            "step 1217 - loss 1.2412149906158447 - moving ave loss 1.165736661172809\n",
            "step 1218 - loss 0.8226564526557922 - moving ave loss 1.1314286403211073\n",
            "step 1219 - loss 1.1895229816436768 - moving ave loss 1.1372380744533643\n",
            "step 1220 - loss 0.8920587301254272 - moving ave loss 1.1127201400205706\n",
            "step 1221 - loss 1.3912732601165771 - moving ave loss 1.1405754520301712\n",
            "step 1222 - loss 0.9991680383682251 - moving ave loss 1.1264347106639767\n",
            "Finish 94 epoch(es)\n",
            "step 1223 - loss 1.085283637046814 - moving ave loss 1.1223196033022604\n",
            "step 1224 - loss 1.3788225650787354 - moving ave loss 1.147969899479908\n",
            "step 1225 - loss 1.141676902770996 - moving ave loss 1.1473405998090167\n",
            "step 1226 - loss 1.193295955657959 - moving ave loss 1.1519361353939108\n",
            "step 1227 - loss 1.0612285137176514 - moving ave loss 1.142865373226285\n",
            "step 1228 - loss 1.1524815559387207 - moving ave loss 1.1438269914975285\n",
            "step 1229 - loss 1.2861627340316772 - moving ave loss 1.1580605657509435\n",
            "step 1230 - loss 0.941572904586792 - moving ave loss 1.1364117996345284\n",
            "step 1231 - loss 0.6708314418792725 - moving ave loss 1.0898537638590027\n",
            "step 1232 - loss 1.2585245370864868 - moving ave loss 1.106720841181751\n",
            "step 1233 - loss 1.175880789756775 - moving ave loss 1.1136368360392535\n",
            "step 1234 - loss 1.2543703317642212 - moving ave loss 1.1277101856117502\n",
            "step 1235 - loss 1.1521213054656982 - moving ave loss 1.130151297597145\n",
            "Finish 95 epoch(es)\n",
            "step 1236 - loss 0.9588746428489685 - moving ave loss 1.1130236321223275\n",
            "step 1237 - loss 1.1350754499435425 - moving ave loss 1.115228813904449\n",
            "step 1238 - loss 0.9458975791931152 - moving ave loss 1.0982956904333157\n",
            "step 1239 - loss 0.9989317655563354 - moving ave loss 1.0883592979456176\n",
            "step 1240 - loss 1.0635002851486206 - moving ave loss 1.085873396665918\n",
            "step 1241 - loss 1.3390872478485107 - moving ave loss 1.1111947817841774\n",
            "step 1242 - loss 1.3126554489135742 - moving ave loss 1.131340848497117\n",
            "step 1243 - loss 1.0534635782241821 - moving ave loss 1.1235531214698236\n",
            "step 1244 - loss 1.1531989574432373 - moving ave loss 1.126517705067165\n",
            "step 1245 - loss 1.2821853160858154 - moving ave loss 1.1420844661690301\n",
            "step 1246 - loss 0.7809593677520752 - moving ave loss 1.1059719563273347\n",
            "step 1247 - loss 0.9952167868614197 - moving ave loss 1.0948964393807432\n",
            "step 1248 - loss 0.9230239391326904 - moving ave loss 1.077709189355938\n",
            "Finish 96 epoch(es)\n",
            "step 1249 - loss 0.864128053188324 - moving ave loss 1.0563510757391767\n",
            "step 1250 - loss 1.0511577129364014 - moving ave loss 1.0558317394588992\n",
            "Checkpoint at step 1250\n",
            "step 1251 - loss 1.052505373954773 - moving ave loss 1.0554991029084866\n",
            "step 1252 - loss 1.124243974685669 - moving ave loss 1.0623735900862048\n",
            "step 1253 - loss 1.4228317737579346 - moving ave loss 1.0984194084533778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-b9fb94a28d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/darkflow/darkflow/net/flow.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mloss_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         if not i: self.say(train_stats.format(\n\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/darkflow/darkflow/net/yolo/data.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mtrain_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffle_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This image's width or height are zeros: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_instance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/darkflow/darkflow/net/yolov2/data.py\u001b[0m in \u001b[0;36m_batch\u001b[0;34m(self, chunk)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mallobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallobj_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Calculate regression target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/darkflow/darkflow/net/yolo/predict.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, im, allobj)\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mobj_1_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimcv2_recolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/darkflow/darkflow/utils/im_transform.py\u001b[0m in \u001b[0;36mimcv2_recolor\u001b[0;34m(im, a)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#       im = np.power(im/mx, 1. + up * .5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mup\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnRpillVdMUA",
        "colab_type": "text"
      },
      "source": [
        "Tomado de https://github.com/deep-diver/Soccer-Ball-Detection-YOLOv2/blob/master/YOLOv2-Train.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBKYmox4207N",
        "colab_type": "text"
      },
      "source": [
        "Transformamos nuestros archivos en ProtobufFile, para poder convertirlos en .tflite posteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xo9A074PU-W",
        "colab_type": "code",
        "outputId": "20f26ef8-386f-4f70-d1ba-f922b473f79d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ./flow --model cfg/custom-voc.cfg --load bin/tiny-yolo-voc.weights --savepb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:15: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:16: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:17: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:18: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:19: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:20: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:21: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:22: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "\n",
            "Parsing ./cfg/tiny-yolo-voc.cfg\n",
            "Parsing cfg/custom-voc.cfg\n",
            "Loading bin/tiny-yolo-voc.weights ...\n",
            "Successfully identified 63471556 bytes\n",
            "Finished in 0.0040645599365234375s\n",
            "\n",
            "Building net ...\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:105: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/ops/baseop.py:70: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/ops/baseop.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/ops/baseop.py:84: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 16)\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/ops/simple.py:106: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 16)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 32)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 64)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 128)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 256)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_1                     | (?, 13, 13, 512)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 30)\n",
            "-------+--------+----------------------------------+---------------\n",
            "Running entirely on CPU\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:145: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:145: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2020-05-25 23:00:23.001315: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-05-25 23:00:23.006225: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-05-25 23:00:23.007467: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19532c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-25 23:00:23.007504: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-25 23:00:23.011902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-25 23:00:23.105086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-25 23:00:23.106019: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1953480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-25 23:00:23.106054: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-05-25 23:00:23.106152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-25 23:00:23.106166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:146: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "2020-05-25 23:00:23.122533: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 37748736 exceeds 10% of system memory.\n",
            "2020-05-25 23:00:23.134814: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.\n",
            "2020-05-25 23:00:23.168218: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.\n",
            "2020-05-25 23:00:23.192340: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 37748736 exceeds 10% of system memory.\n",
            "2020-05-25 23:00:23.204030: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:149: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:149: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Finished in 1.443159580230713s\n",
            "\n",
            "Rebuild a constant version ...\n",
            "2020-05-25 23:00:24.168633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-25 23:00:24.168682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n",
            "2020-05-25 23:00:24.192472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-25 23:00:24.192886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-25 23:00:24.193491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-25 23:00:24.196367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-05-25 23:00:24.198311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-05-25 23:00:24.199277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-05-25 23:00:24.202311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-05-25 23:00:24.204612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-05-25 23:00:24.210740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-25 23:00:24.210915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-25 23:00:24.211489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-25 23:00:24.211873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-05-25 23:00:24.212552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-25 23:00:24.212966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-25 23:00:24.213026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-25 23:00:24.213053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-05-25 23:00:24.213084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-05-25 23:00:24.213107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-05-25 23:00:24.213128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-05-25 23:00:24.213154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-05-25 23:00:24.213201: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-25 23:00:24.213317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-25 23:00:24.213972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-25 23:00:24.214432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-05-25 23:00:24.214500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-25 23:00:24.215636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-25 23:00:24.215662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-05-25 23:00:24.215679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-05-25 23:00:24.215855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-25 23:00:24.216344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-25 23:00:24.216722: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-25 23:00:24.216755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6886 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:177: The name tf.train.write_graph is deprecated. Please use tf.io.write_graph instead.\n",
            "\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnnsNjMK3KGT",
        "colab_type": "text"
      },
      "source": [
        "Probamos la precisión de nuestro .pb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6IfO_WPRIa1",
        "colab_type": "code",
        "outputId": "24a9f536-7ceb-4ae5-877f-4bd58b0f0648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "!python ./flow --pbLoad built_graph/custom-voc.pb --metaLoad built_graph/custom-voc.meta --imgdir sample_img/ "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:15: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:16: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:17: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:18: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:19: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:20: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:21: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:22: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "\n",
            "\n",
            "Loading from .pb and .meta\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:81: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:82: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:94: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "Running entirely on CPU\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:145: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:145: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2020-05-25 23:06:14.954644: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-05-25 23:06:14.959211: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-05-25 23:06:14.959781: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20bd2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-25 23:06:14.959819: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-25 23:06:14.961873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-25 23:06:15.039600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-25 23:06:15.040164: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20bd480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-25 23:06:15.040205: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-05-25 23:06:15.040311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-25 23:06:15.040326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:146: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "Forwarding 1 inputs ...\n",
            "Total time = 0.6382331848144531s / 1 inps = 1.5668254546975955 ips\n",
            "Post processing 1 inputs ...\n",
            "Total time = 0.030260086059570312s / 1 inps = 33.0468326504885 ips\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb4aQUGB8y6c",
        "colab_type": "code",
        "outputId": "5d5ecf92-87d3-4fd7-8d26-71a62bb216f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import cv2\n",
        "\n",
        "options = {\"pbLoad\": \"built_graph/custom-voc.pb\", \"metaLoad\": \"built_graph/custom-voc.meta\", \"threshold\": 0.1}\n",
        "\n",
        "tfnet = TFNet(options)\n",
        "\n",
        "imgcv = cv2.imread(\"./sample_img/Test_p.jpg\")\n",
        "result = tfnet.return_predict(imgcv)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading from .pb and .meta\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:81: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:82: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/darkflow/darkflow/net/build.py:94: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "Running entirely on CPU\n",
            "[{'label': 'pepsi', 'confidence': 0.53537476, 'topleft': {'x': 0, 'y': 0}, 'bottomright': {'x': 32, 'y': 36}}, {'label': 'pepsi', 'confidence': 0.53357965, 'topleft': {'x': 30, 'y': 0}, 'bottomright': {'x': 66, 'y': 37}}, {'label': 'pepsi', 'confidence': 0.5437849, 'topleft': {'x': 62, 'y': 0}, 'bottomright': {'x': 100, 'y': 38}}, {'label': 'pepsi', 'confidence': 0.5376336, 'topleft': {'x': 97, 'y': 0}, 'bottomright': {'x': 130, 'y': 40}}, {'label': 'pepsi', 'confidence': 0.53794366, 'topleft': {'x': 0, 'y': 0}, 'bottomright': {'x': 239, 'y': 99}}, {'label': 'pepsi', 'confidence': 0.5065218, 'topleft': {'x': 134, 'y': 0}, 'bottomright': {'x': 162, 'y': 47}}, {'label': 'pepsi', 'confidence': 0.49282748, 'topleft': {'x': 165, 'y': 0}, 'bottomright': {'x': 196, 'y': 51}}, {'label': 'pepsi', 'confidence': 0.5385651, 'topleft': {'x': 196, 'y': 0}, 'bottomright': {'x': 228, 'y': 47}}, {'label': 'pepsi', 'confidence': 0.5343601, 'topleft': {'x': 115, 'y': 0}, 'bottomright': {'x': 304, 'y': 207}}, {'label': 'pepsi', 'confidence': 0.5741174, 'topleft': {'x': 228, 'y': 0}, 'bottomright': {'x': 261, 'y': 45}}, {'label': 'pepsi', 'confidence': 0.5688808, 'topleft': {'x': 259, 'y': 0}, 'bottomright': {'x': 295, 'y': 42}}, {'label': 'pepsi', 'confidence': 0.5564562, 'topleft': {'x': 292, 'y': 0}, 'bottomright': {'x': 328, 'y': 38}}, {'label': 'pepsi', 'confidence': 0.5279714, 'topleft': {'x': 326, 'y': 0}, 'bottomright': {'x': 360, 'y': 37}}, {'label': 'pepsi', 'confidence': 0.5447271, 'topleft': {'x': 359, 'y': 0}, 'bottomright': {'x': 392, 'y': 37}}, {'label': 'pepsi', 'confidence': 0.53318167, 'topleft': {'x': 392, 'y': 0}, 'bottomright': {'x': 424, 'y': 36}}, {'label': 'pepsi', 'confidence': 0.5420297, 'topleft': {'x': 254, 'y': 0}, 'bottomright': {'x': 424, 'y': 107}}, {'label': 'pepsi', 'confidence': 0.5453628, 'topleft': {'x': 0, 'y': 27}, 'bottomright': {'x': 34, 'y': 68}}, {'label': 'pepsi', 'confidence': 0.53245926, 'topleft': {'x': 0, 'y': 0}, 'bottomright': {'x': 173, 'y': 122}}, {'label': 'pepsi', 'confidence': 0.54796875, 'topleft': {'x': 26, 'y': 29}, 'bottomright': {'x': 70, 'y': 69}}, {'label': 'pepsi', 'confidence': 0.528711, 'topleft': {'x': 57, 'y': 29}, 'bottomright': {'x': 106, 'y': 70}}, {'label': 'pepsi', 'confidence': 0.5043445, 'topleft': {'x': 92, 'y': 26}, 'bottomright': {'x': 136, 'y': 73}}, {'label': 'pepsi', 'confidence': 0.4606853, 'topleft': {'x': 128, 'y': 26}, 'bottomright': {'x': 167, 'y': 79}}, {'label': 'pepsi', 'confidence': 0.40549475, 'topleft': {'x': 162, 'y': 24}, 'bottomright': {'x': 197, 'y': 81}}, {'label': 'pepsi', 'confidence': 0.4563137, 'topleft': {'x': 192, 'y': 25}, 'bottomright': {'x': 227, 'y': 77}}, {'label': 'pepsi', 'confidence': 0.5194364, 'topleft': {'x': 222, 'y': 29}, 'bottomright': {'x': 262, 'y': 74}}, {'label': 'pepsi', 'confidence': 0.5714803, 'topleft': {'x': 175, 'y': 0}, 'bottomright': {'x': 318, 'y': 105}}, {'label': 'pepsi', 'confidence': 0.5456468, 'topleft': {'x': 255, 'y': 27}, 'bottomright': {'x': 298, 'y': 74}}, {'label': 'pepsi', 'confidence': 0.520964, 'topleft': {'x': 289, 'y': 29}, 'bottomright': {'x': 330, 'y': 72}}, {'label': 'pepsi', 'confidence': 0.52353776, 'topleft': {'x': 172, 'y': 0}, 'bottomright': {'x': 424, 'y': 129}}, {'label': 'pepsi', 'confidence': 0.5275757, 'topleft': {'x': 325, 'y': 28}, 'bottomright': {'x': 361, 'y': 70}}, {'label': 'pepsi', 'confidence': 0.5420121, 'topleft': {'x': 359, 'y': 25}, 'bottomright': {'x': 394, 'y': 72}}, {'label': 'pepsi', 'confidence': 0.5269269, 'topleft': {'x': 392, 'y': 28}, 'bottomright': {'x': 424, 'y': 69}}, {'label': 'pepsi', 'confidence': 0.4899343, 'topleft': {'x': 353, 'y': 0}, 'bottomright': {'x': 424, 'y': 127}}, {'label': 'pepsi', 'confidence': 0.5532815, 'topleft': {'x': 0, 'y': 59}, 'bottomright': {'x': 36, 'y': 103}}, {'label': 'pepsi', 'confidence': 0.46927878, 'topleft': {'x': 0, 'y': 0}, 'bottomright': {'x': 116, 'y': 291}}, {'label': 'pepsi', 'confidence': 0.55452466, 'topleft': {'x': 22, 'y': 60}, 'bottomright': {'x': 76, 'y': 103}}, {'label': 'pepsi', 'confidence': 0.5693632, 'topleft': {'x': 50, 'y': 61}, 'bottomright': {'x': 114, 'y': 102}}, {'label': 'pepsi', 'confidence': 0.5478766, 'topleft': {'x': 29, 'y': 9}, 'bottomright': {'x': 135, 'y': 159}}, {'label': 'pepsi', 'confidence': 0.5628957, 'topleft': {'x': 90, 'y': 61}, 'bottomright': {'x': 142, 'y': 101}}, {'label': 'pepsi', 'confidence': 0.5117889, 'topleft': {'x': 130, 'y': 62}, 'bottomright': {'x': 168, 'y': 104}}, {'label': 'pepsi', 'confidence': 0.4860872, 'topleft': {'x': 160, 'y': 60}, 'bottomright': {'x': 196, 'y': 104}}, {'label': 'pepsi', 'confidence': 0.48147795, 'topleft': {'x': 193, 'y': 62}, 'bottomright': {'x': 226, 'y': 100}}, {'label': 'pepsi', 'confidence': 0.4778775, 'topleft': {'x': 224, 'y': 63}, 'bottomright': {'x': 264, 'y': 98}}, {'label': 'pepsi', 'confidence': 0.49806267, 'topleft': {'x': 255, 'y': 58}, 'bottomright': {'x': 300, 'y': 103}}, {'label': 'pepsi', 'confidence': 0.49921197, 'topleft': {'x': 285, 'y': 58}, 'bottomright': {'x': 337, 'y': 107}}, {'label': 'pepsi', 'confidence': 0.52585196, 'topleft': {'x': 323, 'y': 58}, 'bottomright': {'x': 363, 'y': 108}}, {'label': 'pepsi', 'confidence': 0.5136957, 'topleft': {'x': 283, 'y': 1}, 'bottomright': {'x': 402, 'y': 166}}, {'label': 'pepsi', 'confidence': 0.5496046, 'topleft': {'x': 358, 'y': 57}, 'bottomright': {'x': 394, 'y': 105}}, {'label': 'pepsi', 'confidence': 0.5382325, 'topleft': {'x': 390, 'y': 59}, 'bottomright': {'x': 424, 'y': 102}}, {'label': 'pepsi', 'confidence': 0.5508357, 'topleft': {'x': 0, 'y': 95}, 'bottomright': {'x': 35, 'y': 133}}, {'label': 'pepsi', 'confidence': 0.48679298, 'topleft': {'x': 0, 'y': 46}, 'bottomright': {'x': 150, 'y': 178}}, {'label': 'pepsi', 'confidence': 0.5666811, 'topleft': {'x': 25, 'y': 95}, 'bottomright': {'x': 74, 'y': 132}}, {'label': 'pepsi', 'confidence': 0.5348627, 'topleft': {'x': 0, 'y': 16}, 'bottomright': {'x': 101, 'y': 213}}, {'label': 'pepsi', 'confidence': 0.6018297, 'topleft': {'x': 56, 'y': 94}, 'bottomright': {'x': 110, 'y': 131}}, {'label': 'pepsi', 'confidence': 0.5983435, 'topleft': {'x': 94, 'y': 95}, 'bottomright': {'x': 142, 'y': 131}}, {'label': 'pepsi', 'confidence': 0.5774165, 'topleft': {'x': 61, 'y': 42}, 'bottomright': {'x': 166, 'y': 193}}, {'label': 'pepsi', 'confidence': 0.59434193, 'topleft': {'x': 131, 'y': 94}, 'bottomright': {'x': 168, 'y': 138}}, {'label': 'pepsi', 'confidence': 0.6075569, 'topleft': {'x': 164, 'y': 95}, 'bottomright': {'x': 199, 'y': 134}}, {'label': 'pepsi', 'confidence': 0.58734757, 'topleft': {'x': 198, 'y': 95}, 'bottomright': {'x': 230, 'y': 130}}, {'label': 'pepsi', 'confidence': 0.54625446, 'topleft': {'x': 35, 'y': 57}, 'bottomright': {'x': 392, 'y': 176}}, {'label': 'pepsi', 'confidence': 0.5231435, 'topleft': {'x': 227, 'y': 92}, 'bottomright': {'x': 267, 'y': 132}}, {'label': 'pepsi', 'confidence': 0.53450245, 'topleft': {'x': 257, 'y': 85}, 'bottomright': {'x': 302, 'y': 141}}, {'label': 'pepsi', 'confidence': 0.53627133, 'topleft': {'x': 287, 'y': 89}, 'bottomright': {'x': 338, 'y': 143}}, {'label': 'pepsi', 'confidence': 0.5530826, 'topleft': {'x': 322, 'y': 93}, 'bottomright': {'x': 364, 'y': 138}}, {'label': 'pepsi', 'confidence': 0.54809105, 'topleft': {'x': 358, 'y': 93}, 'bottomright': {'x': 394, 'y': 135}}, {'label': 'pepsi', 'confidence': 0.54928136, 'topleft': {'x': 392, 'y': 94}, 'bottomright': {'x': 424, 'y': 133}}, {'label': 'pepsi', 'confidence': 0.55859095, 'topleft': {'x': 0, 'y': 129}, 'bottomright': {'x': 32, 'y': 165}}, {'label': 'pepsi', 'confidence': 0.57737994, 'topleft': {'x': 27, 'y': 129}, 'bottomright': {'x': 68, 'y': 164}}, {'label': 'pepsi', 'confidence': 0.61807805, 'topleft': {'x': 60, 'y': 128}, 'bottomright': {'x': 104, 'y': 163}}, {'label': 'pepsi', 'confidence': 0.54494995, 'topleft': {'x': 31, 'y': 66}, 'bottomright': {'x': 130, 'y': 230}}, {'label': 'pepsi', 'confidence': 0.6310543, 'topleft': {'x': 98, 'y': 129}, 'bottomright': {'x': 138, 'y': 164}}, {'label': 'pepsi', 'confidence': 0.6228531, 'topleft': {'x': 133, 'y': 126}, 'bottomright': {'x': 166, 'y': 169}}, {'label': 'pepsi', 'confidence': 0.60174537, 'topleft': {'x': 166, 'y': 126}, 'bottomright': {'x': 199, 'y': 163}}, {'label': 'pepsi', 'confidence': 0.5672653, 'topleft': {'x': 199, 'y': 128}, 'bottomright': {'x': 230, 'y': 160}}, {'label': 'pepsi', 'confidence': 0.5393235, 'topleft': {'x': 170, 'y': 61}, 'bottomright': {'x': 264, 'y': 238}}, {'label': 'pepsi', 'confidence': 0.5716022, 'topleft': {'x': 231, 'y': 122}, 'bottomright': {'x': 263, 'y': 168}}, {'label': 'pepsi', 'confidence': 0.5237639, 'topleft': {'x': 203, 'y': 82}, 'bottomright': {'x': 294, 'y': 215}}, {'label': 'pepsi', 'confidence': 0.6096739, 'topleft': {'x': 263, 'y': 120}, 'bottomright': {'x': 296, 'y': 174}}, {'label': 'pepsi', 'confidence': 0.6048336, 'topleft': {'x': 294, 'y': 123}, 'bottomright': {'x': 330, 'y': 175}}, {'label': 'pepsi', 'confidence': 0.55340713, 'topleft': {'x': 327, 'y': 127}, 'bottomright': {'x': 359, 'y': 171}}, {'label': 'pepsi', 'confidence': 0.53738195, 'topleft': {'x': 361, 'y': 127}, 'bottomright': {'x': 391, 'y': 167}}, {'label': 'pepsi', 'confidence': 0.5459787, 'topleft': {'x': 393, 'y': 127}, 'bottomright': {'x': 424, 'y': 165}}, {'label': 'pepsi', 'confidence': 0.54908216, 'topleft': {'x': 0, 'y': 160}, 'bottomright': {'x': 33, 'y': 198}}, {'label': 'pepsi', 'confidence': 0.5254891, 'topleft': {'x': 0, 'y': 98}, 'bottomright': {'x': 72, 'y': 259}}, {'label': 'pepsi', 'confidence': 0.55578655, 'topleft': {'x': 27, 'y': 161}, 'bottomright': {'x': 68, 'y': 198}}, {'label': 'pepsi', 'confidence': 0.6189803, 'topleft': {'x': 61, 'y': 160}, 'bottomright': {'x': 102, 'y': 197}}, {'label': 'pepsi', 'confidence': 0.6504527, 'topleft': {'x': 97, 'y': 157}, 'bottomright': {'x': 135, 'y': 198}}, {'label': 'pepsi', 'confidence': 0.6400199, 'topleft': {'x': 134, 'y': 158}, 'bottomright': {'x': 165, 'y': 199}}, {'label': 'pepsi', 'confidence': 0.5683575, 'topleft': {'x': 169, 'y': 159}, 'bottomright': {'x': 195, 'y': 196}}, {'label': 'pepsi', 'confidence': 0.5421721, 'topleft': {'x': 202, 'y': 161}, 'bottomright': {'x': 226, 'y': 196}}, {'label': 'pepsi', 'confidence': 0.49870217, 'topleft': {'x': 147, 'y': 0}, 'bottomright': {'x': 270, 'y': 376}}, {'label': 'pepsi', 'confidence': 0.5780237, 'topleft': {'x': 233, 'y': 156}, 'bottomright': {'x': 261, 'y': 203}}, {'label': 'pepsi', 'confidence': 0.6164597, 'topleft': {'x': 262, 'y': 155}, 'bottomright': {'x': 298, 'y': 208}}, {'label': 'pepsi', 'confidence': 0.5394162, 'topleft': {'x': 238, 'y': 122}, 'bottomright': {'x': 319, 'y': 239}}, {'label': 'pepsi', 'confidence': 0.5954913, 'topleft': {'x': 295, 'y': 154}, 'bottomright': {'x': 329, 'y': 210}}, {'label': 'pepsi', 'confidence': 0.47396073, 'topleft': {'x': 272, 'y': 112}, 'bottomright': {'x': 351, 'y': 253}}, {'label': 'pepsi', 'confidence': 0.5365887, 'topleft': {'x': 326, 'y': 158}, 'bottomright': {'x': 358, 'y': 206}}, {'label': 'pepsi', 'confidence': 0.53853816, 'topleft': {'x': 361, 'y': 159}, 'bottomright': {'x': 391, 'y': 200}}, {'label': 'pepsi', 'confidence': 0.54048204, 'topleft': {'x': 393, 'y': 160}, 'bottomright': {'x': 424, 'y': 198}}, {'label': 'pepsi', 'confidence': 0.5585467, 'topleft': {'x': 0, 'y': 192}, 'bottomright': {'x': 32, 'y': 232}}, {'label': 'pepsi', 'confidence': 0.56671256, 'topleft': {'x': 29, 'y': 193}, 'bottomright': {'x': 67, 'y': 231}}, {'label': 'pepsi', 'confidence': 0.62473863, 'topleft': {'x': 62, 'y': 193}, 'bottomright': {'x': 100, 'y': 230}}, {'label': 'pepsi', 'confidence': 0.53838605, 'topleft': {'x': 30, 'y': 135}, 'bottomright': {'x': 136, 'y': 293}}, {'label': 'pepsi', 'confidence': 0.627077, 'topleft': {'x': 94, 'y': 189}, 'bottomright': {'x': 134, 'y': 232}}, {'label': 'pepsi', 'confidence': 0.6296438, 'topleft': {'x': 128, 'y': 191}, 'bottomright': {'x': 164, 'y': 234}}, {'label': 'pepsi', 'confidence': 0.6131899, 'topleft': {'x': 165, 'y': 195}, 'bottomright': {'x': 192, 'y': 231}}, {'label': 'pepsi', 'confidence': 0.5804265, 'topleft': {'x': 199, 'y': 194}, 'bottomright': {'x': 225, 'y': 232}}, {'label': 'pepsi', 'confidence': 0.5441594, 'topleft': {'x': 148, 'y': 145}, 'bottomright': {'x': 287, 'y': 288}}, {'label': 'pepsi', 'confidence': 0.5644764, 'topleft': {'x': 229, 'y': 193}, 'bottomright': {'x': 261, 'y': 234}}, {'label': 'pepsi', 'confidence': 0.5852678, 'topleft': {'x': 259, 'y': 189}, 'bottomright': {'x': 295, 'y': 236}}, {'label': 'pepsi', 'confidence': 0.57930905, 'topleft': {'x': 293, 'y': 188}, 'bottomright': {'x': 325, 'y': 237}}, {'label': 'pepsi', 'confidence': 0.532081, 'topleft': {'x': 325, 'y': 190}, 'bottomright': {'x': 356, 'y': 237}}, {'label': 'pepsi', 'confidence': 0.5431568, 'topleft': {'x': 360, 'y': 192}, 'bottomright': {'x': 391, 'y': 232}}, {'label': 'pepsi', 'confidence': 0.5379137, 'topleft': {'x': 393, 'y': 193}, 'bottomright': {'x': 424, 'y': 230}}, {'label': 'pepsi', 'confidence': 0.5676198, 'topleft': {'x': 0, 'y': 225}, 'bottomright': {'x': 32, 'y': 264}}, {'label': 'pepsi', 'confidence': 0.58247536, 'topleft': {'x': 30, 'y': 226}, 'bottomright': {'x': 65, 'y': 263}}, {'label': 'pepsi', 'confidence': 0.5173654, 'topleft': {'x': 0, 'y': 155}, 'bottomright': {'x': 107, 'y': 336}}, {'label': 'pepsi', 'confidence': 0.62368625, 'topleft': {'x': 62, 'y': 227}, 'bottomright': {'x': 99, 'y': 261}}, {'label': 'pepsi', 'confidence': 0.61791116, 'topleft': {'x': 97, 'y': 224}, 'bottomright': {'x': 133, 'y': 264}}, {'label': 'pepsi', 'confidence': 0.5873874, 'topleft': {'x': 131, 'y': 226}, 'bottomright': {'x': 164, 'y': 266}}, {'label': 'pepsi', 'confidence': 0.5838506, 'topleft': {'x': 165, 'y': 229}, 'bottomright': {'x': 193, 'y': 264}}, {'label': 'pepsi', 'confidence': 0.55368423, 'topleft': {'x': 200, 'y': 232}, 'bottomright': {'x': 227, 'y': 264}}, {'label': 'pepsi', 'confidence': 0.55625945, 'topleft': {'x': 229, 'y': 228}, 'bottomright': {'x': 261, 'y': 264}}, {'label': 'pepsi', 'confidence': 0.58265716, 'topleft': {'x': 258, 'y': 224}, 'bottomright': {'x': 293, 'y': 264}}, {'label': 'pepsi', 'confidence': 0.5723228, 'topleft': {'x': 293, 'y': 222}, 'bottomright': {'x': 323, 'y': 266}}, {'label': 'pepsi', 'confidence': 0.5262524, 'topleft': {'x': 326, 'y': 223}, 'bottomright': {'x': 354, 'y': 268}}, {'label': 'pepsi', 'confidence': 0.54044336, 'topleft': {'x': 359, 'y': 226}, 'bottomright': {'x': 391, 'y': 265}}, {'label': 'pepsi', 'confidence': 0.5404323, 'topleft': {'x': 392, 'y': 226}, 'bottomright': {'x': 424, 'y': 263}}, {'label': 'pepsi', 'confidence': 0.57105863, 'topleft': {'x': 0, 'y': 259}, 'bottomright': {'x': 31, 'y': 295}}, {'label': 'pepsi', 'confidence': 0.5151955, 'topleft': {'x': 0, 'y': 197}, 'bottomright': {'x': 67, 'y': 354}}, {'label': 'pepsi', 'confidence': 0.49643445, 'topleft': {'x': 0, 'y': 208}, 'bottomright': {'x': 176, 'y': 344}}, {'label': 'pepsi', 'confidence': 0.60682875, 'topleft': {'x': 31, 'y': 261}, 'bottomright': {'x': 63, 'y': 293}}, {'label': 'pepsi', 'confidence': 0.65213126, 'topleft': {'x': 62, 'y': 261}, 'bottomright': {'x': 97, 'y': 291}}, {'label': 'pepsi', 'confidence': 0.65484285, 'topleft': {'x': 94, 'y': 258}, 'bottomright': {'x': 136, 'y': 294}}, {'label': 'pepsi', 'confidence': 0.61260813, 'topleft': {'x': 129, 'y': 257}, 'bottomright': {'x': 168, 'y': 296}}, {'label': 'pepsi', 'confidence': 0.58893824, 'topleft': {'x': 166, 'y': 260}, 'bottomright': {'x': 196, 'y': 296}}, {'label': 'pepsi', 'confidence': 0.57426214, 'topleft': {'x': 200, 'y': 265}, 'bottomright': {'x': 225, 'y': 297}}, {'label': 'pepsi', 'confidence': 0.6078885, 'topleft': {'x': 226, 'y': 262}, 'bottomright': {'x': 263, 'y': 299}}, {'label': 'pepsi', 'confidence': 0.6259776, 'topleft': {'x': 256, 'y': 259}, 'bottomright': {'x': 297, 'y': 295}}, {'label': 'pepsi', 'confidence': 0.58408546, 'topleft': {'x': 293, 'y': 256}, 'bottomright': {'x': 327, 'y': 298}}, {'label': 'pepsi', 'confidence': 0.564245, 'topleft': {'x': 327, 'y': 258}, 'bottomright': {'x': 355, 'y': 298}}, {'label': 'pepsi', 'confidence': 0.56311417, 'topleft': {'x': 360, 'y': 261}, 'bottomright': {'x': 390, 'y': 294}}, {'label': 'pepsi', 'confidence': 0.5473836, 'topleft': {'x': 393, 'y': 260}, 'bottomright': {'x': 424, 'y': 294}}, {'label': 'pepsi', 'confidence': 0.47065204, 'topleft': {'x': 251, 'y': 202}, 'bottomright': {'x': 424, 'y': 353}}, {'label': 'pepsi', 'confidence': 0.550912, 'topleft': {'x': 0, 'y': 293}, 'bottomright': {'x': 30, 'y': 326}}, {'label': 'pepsi', 'confidence': 0.58483785, 'topleft': {'x': 30, 'y': 295}, 'bottomright': {'x': 64, 'y': 325}}, {'label': 'pepsi', 'confidence': 0.6281732, 'topleft': {'x': 62, 'y': 295}, 'bottomright': {'x': 96, 'y': 324}}, {'label': 'pepsi', 'confidence': 0.51200855, 'topleft': {'x': 32, 'y': 228}, 'bottomright': {'x': 130, 'y': 394}}, {'label': 'pepsi', 'confidence': 0.6287521, 'topleft': {'x': 91, 'y': 294}, 'bottomright': {'x': 136, 'y': 327}}, {'label': 'pepsi', 'confidence': 0.630052, 'topleft': {'x': 127, 'y': 291}, 'bottomright': {'x': 168, 'y': 330}}, {'label': 'pepsi', 'confidence': 0.6761931, 'topleft': {'x': 0, 'y': 82}, 'bottomright': {'x': 424, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.61408174, 'topleft': {'x': 167, 'y': 293}, 'bottomright': {'x': 193, 'y': 329}}, {'label': 'pepsi', 'confidence': 0.49504995, 'topleft': {'x': 81, 'y': 163}, 'bottomright': {'x': 273, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.5709227, 'topleft': {'x': 201, 'y': 297}, 'bottomright': {'x': 221, 'y': 330}}, {'label': 'pepsi', 'confidence': 0.6172558, 'topleft': {'x': 229, 'y': 294}, 'bottomright': {'x': 259, 'y': 331}}, {'label': 'pepsi', 'confidence': 0.6055677, 'topleft': {'x': 258, 'y': 293}, 'bottomright': {'x': 295, 'y': 326}}, {'label': 'pepsi', 'confidence': 0.58679813, 'topleft': {'x': 292, 'y': 290}, 'bottomright': {'x': 328, 'y': 331}}, {'label': 'pepsi', 'confidence': 0.55209154, 'topleft': {'x': 327, 'y': 289}, 'bottomright': {'x': 357, 'y': 332}}, {'label': 'pepsi', 'confidence': 0.54537046, 'topleft': {'x': 361, 'y': 293}, 'bottomright': {'x': 389, 'y': 327}}, {'label': 'pepsi', 'confidence': 0.52957547, 'topleft': {'x': 313, 'y': 225}, 'bottomright': {'x': 424, 'y': 397}}, {'label': 'pepsi', 'confidence': 0.5507579, 'topleft': {'x': 393, 'y': 292}, 'bottomright': {'x': 424, 'y': 327}}, {'label': 'pepsi', 'confidence': 0.5501205, 'topleft': {'x': 0, 'y': 325}, 'bottomright': {'x': 32, 'y': 361}}, {'label': 'pepsi', 'confidence': 0.494556, 'topleft': {'x': 0, 'y': 271}, 'bottomright': {'x': 66, 'y': 415}}, {'label': 'pepsi', 'confidence': 0.5664225, 'topleft': {'x': 31, 'y': 327}, 'bottomright': {'x': 66, 'y': 361}}, {'label': 'pepsi', 'confidence': 0.5713575, 'topleft': {'x': 63, 'y': 330}, 'bottomright': {'x': 98, 'y': 358}}, {'label': 'pepsi', 'confidence': 0.5509482, 'topleft': {'x': 97, 'y': 329}, 'bottomright': {'x': 131, 'y': 360}}, {'label': 'pepsi', 'confidence': 0.5800321, 'topleft': {'x': 134, 'y': 327}, 'bottomright': {'x': 163, 'y': 363}}, {'label': 'pepsi', 'confidence': 0.57265645, 'topleft': {'x': 106, 'y': 276}, 'bottomright': {'x': 181, 'y': 415}}, {'label': 'pepsi', 'confidence': 0.5622174, 'topleft': {'x': 172, 'y': 327}, 'bottomright': {'x': 193, 'y': 362}}, {'label': 'pepsi', 'confidence': 0.59598345, 'topleft': {'x': 204, 'y': 330}, 'bottomright': {'x': 223, 'y': 362}}, {'label': 'pepsi', 'confidence': 0.52954733, 'topleft': {'x': 173, 'y': 287}, 'bottomright': {'x': 251, 'y': 400}}, {'label': 'pepsi', 'confidence': 0.6179721, 'topleft': {'x': 232, 'y': 328}, 'bottomright': {'x': 258, 'y': 362}}, {'label': 'pepsi', 'confidence': 0.6620419, 'topleft': {'x': 261, 'y': 325}, 'bottomright': {'x': 293, 'y': 358}}, {'label': 'pepsi', 'confidence': 0.5228264, 'topleft': {'x': 233, 'y': 270}, 'bottomright': {'x': 316, 'y': 416}}, {'label': 'pepsi', 'confidence': 0.64187473, 'topleft': {'x': 296, 'y': 321}, 'bottomright': {'x': 326, 'y': 364}}, {'label': 'pepsi', 'confidence': 0.571816, 'topleft': {'x': 328, 'y': 321}, 'bottomright': {'x': 358, 'y': 366}}, {'label': 'pepsi', 'confidence': 0.43116364, 'topleft': {'x': 296, 'y': 272}, 'bottomright': {'x': 390, 'y': 418}}, {'label': 'pepsi', 'confidence': 0.55388075, 'topleft': {'x': 362, 'y': 324}, 'bottomright': {'x': 389, 'y': 363}}, {'label': 'pepsi', 'confidence': 0.5637624, 'topleft': {'x': 393, 'y': 323}, 'bottomright': {'x': 424, 'y': 362}}, {'label': 'pepsi', 'confidence': 0.57535887, 'topleft': {'x': 0, 'y': 358}, 'bottomright': {'x': 32, 'y': 395}}, {'label': 'pepsi', 'confidence': 0.5414016, 'topleft': {'x': 35, 'y': 360}, 'bottomright': {'x': 65, 'y': 395}}, {'label': 'pepsi', 'confidence': 0.51133156, 'topleft': {'x': 65, 'y': 362}, 'bottomright': {'x': 99, 'y': 393}}, {'label': 'pepsi', 'confidence': 0.5252764, 'topleft': {'x': 99, 'y': 362}, 'bottomright': {'x': 130, 'y': 395}}, {'label': 'pepsi', 'confidence': 0.57094795, 'topleft': {'x': 135, 'y': 361}, 'bottomright': {'x': 163, 'y': 396}}, {'label': 'pepsi', 'confidence': 0.57817966, 'topleft': {'x': 171, 'y': 360}, 'bottomright': {'x': 195, 'y': 396}}, {'label': 'pepsi', 'confidence': 0.60866696, 'topleft': {'x': 148, 'y': 326}, 'bottomright': {'x': 212, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.58846235, 'topleft': {'x': 205, 'y': 361}, 'bottomright': {'x': 225, 'y': 394}}, {'label': 'pepsi', 'confidence': 0.57093996, 'topleft': {'x': 237, 'y': 360}, 'bottomright': {'x': 257, 'y': 394}}, {'label': 'pepsi', 'confidence': 0.5229352, 'topleft': {'x': 201, 'y': 322}, 'bottomright': {'x': 291, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.6169104, 'topleft': {'x': 267, 'y': 358}, 'bottomright': {'x': 290, 'y': 393}}, {'label': 'pepsi', 'confidence': 0.60306394, 'topleft': {'x': 298, 'y': 354}, 'bottomright': {'x': 323, 'y': 398}}, {'label': 'pepsi', 'confidence': 0.56527877, 'topleft': {'x': 330, 'y': 353}, 'bottomright': {'x': 357, 'y': 398}}, {'label': 'pepsi', 'confidence': 0.6494435, 'topleft': {'x': 130, 'y': 199}, 'bottomright': {'x': 424, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.54300815, 'topleft': {'x': 363, 'y': 355}, 'bottomright': {'x': 390, 'y': 396}}, {'label': 'pepsi', 'confidence': 0.5529534, 'topleft': {'x': 394, 'y': 355}, 'bottomright': {'x': 424, 'y': 397}}, {'label': 'pepsi', 'confidence': 0.5508274, 'topleft': {'x': 0, 'y': 394}, 'bottomright': {'x': 34, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.47993073, 'topleft': {'x': 0, 'y': 338}, 'bottomright': {'x': 70, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.5081956, 'topleft': {'x': 0, 'y': 229}, 'bottomright': {'x': 130, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.55104774, 'topleft': {'x': 33, 'y': 396}, 'bottomright': {'x': 66, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.54100823, 'topleft': {'x': 64, 'y': 397}, 'bottomright': {'x': 99, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.55323195, 'topleft': {'x': 98, 'y': 393}, 'bottomright': {'x': 130, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.45263267, 'topleft': {'x': 0, 'y': 170}, 'bottomright': {'x': 233, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.54695153, 'topleft': {'x': 0, 'y': 352}, 'bottomright': {'x': 350, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.56934184, 'topleft': {'x': 136, 'y': 390}, 'bottomright': {'x': 160, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.5883179, 'topleft': {'x': 169, 'y': 393}, 'bottomright': {'x': 191, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.50732994, 'topleft': {'x': 131, 'y': 363}, 'bottomright': {'x': 233, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.59982973, 'topleft': {'x': 200, 'y': 395}, 'bottomright': {'x': 223, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.38118172, 'topleft': {'x': 102, 'y': 242}, 'bottomright': {'x': 317, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.5700968, 'topleft': {'x': 233, 'y': 397}, 'bottomright': {'x': 256, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.5627674, 'topleft': {'x': 267, 'y': 392}, 'bottomright': {'x': 288, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.46338874, 'topleft': {'x': 221, 'y': 351}, 'bottomright': {'x': 340, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.55024236, 'topleft': {'x': 299, 'y': 391}, 'bottomright': {'x': 322, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.54301757, 'topleft': {'x': 330, 'y': 392}, 'bottomright': {'x': 358, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.45698032, 'topleft': {'x': 284, 'y': 339}, 'bottomright': {'x': 404, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.51278436, 'topleft': {'x': 360, 'y': 394}, 'bottomright': {'x': 391, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.54469687, 'topleft': {'x': 392, 'y': 391}, 'bottomright': {'x': 424, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.46466807, 'topleft': {'x': 361, 'y': 327}, 'bottomright': {'x': 424, 'y': 424}}, {'label': 'pepsi', 'confidence': 0.5195948, 'topleft': {'x': 238, 'y': 340}, 'bottomright': {'x': 424, 'y': 424}}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
